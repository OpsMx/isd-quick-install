---
apiVersion: v1
kind: Namespace
metadata:
  name: opsmx-isd
---
# Source: oes/charts/gitea/charts/memcached/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: isd-memcached
  namespace: opsmx-isd
  labels:
    app.kubernetes.io/name: memcached
    helm.sh/chart: memcached-5.9.0
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
---
# Source: oes/charts/minio/templates/post-install-prometheus-metrics-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: isd-minio-update-prometheus-secret
  labels:
    app: minio-update-prometheus-secret
    chart: minio-8.0.9
    release: isd
    heritage: Helm
---
# Source: oes/charts/minio/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: "isd-minio"
  namespace: "opsmx-isd"
  labels:
    app: minio
    chart: minio-8.0.9
    release: "isd"
---
# Source: oes/charts/spinnaker/templates/rbac/halyard-sa.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: isd-spinnaker-halyard
  namespace: opsmx-isd
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
---
# Source: oes/templates/forwarder/create-controller-secret.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: create-controller-secret
---
# Source: oes/charts/gitea/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.17
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
  namespace: opsmx-isd
type: Opaque
data:
  postgresql-postgres-password: "bWNRZTZHWG1rcQ=="
  postgresql-password: "Z2l0ZWE="
---
# Source: oes/charts/gitea/templates/gitea/config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-gitea-inline-config
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  _generals_: ""
  cache: |-
    ADAPTER=memcache
    ENABLED=true
    HOST=isd-memcached.opsmx-isd.svc.cluster.local:11211
  database: |-
    DB_TYPE=postgres
    HOST=isd-postgresql.opsmx-isd.svc.cluster.local:5432
    NAME=gitea
    PASSWD=gitea
    USER=gitea
  metrics: ENABLED=false
  repository: ROOT=/data/git/gitea-repositories
  security: INSTALL_LOCK=true
  server: |-
    APP_DATA_PATH=/data
    DOMAIN=git.example.com
    ENABLE_PPROF=false
    HTTP_PORT=3000
    PROTOCOL=http
    ROOT_URL=http://git.example.com
    SSH_DOMAIN=git.example.com
    SSH_LISTEN_PORT=22
    SSH_PORT=22
---
# Source: oes/charts/gitea/templates/gitea/config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-gitea
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  config_environment.sh: |-
    #!/usr/bin/env bash
    set -euo pipefail

    function env2ini::log() {
      printf "${1}\n"
    }

    function env2ini::read_config_to_env() {
      local section="${1}"
      local line="${2}"

      if [[ -z "${line}" ]]; then
        # skip empty line
        return
      fi
      
      # 'xargs echo -n' trims all leading/trailing whitespaces and a trailing new line
      local setting="$(awk -F '=' '{print $1}' <<< "${line}" | xargs echo -n)"

      if [[ -z "${setting}" ]]; then
        env2ini::log '  ! invalid setting'
        exit 1
      fi

      local value=''
      local regex="^${setting}(\s*)=(\s*)(.*)"
      if [[ $line =~ $regex ]]; then
        value="${BASH_REMATCH[3]}"
      else
        env2ini::log '  ! invalid setting'
        exit 1
      fi

      env2ini::log "    + '${setting}'"

      if [[ -z "${section}" ]]; then
        export "ENV_TO_INI____${setting^^}=${value}"                           # '^^' makes the variable content uppercase
        return
      fi

      local masked_section="${section//./_0X2E_}"                            # '//' instructs to replace all matches
      masked_section="${masked_section//-/_0X2D_}"

      export "ENV_TO_INI__${masked_section^^}__${setting^^}=${value}"        # '^^' makes the variable content uppercase
    }

    function env2ini::process_config_file() {
      local config_file="${1}"
      local section="$(basename "${config_file}")"

      if [[ $section == '_generals_' ]]; then
        env2ini::log "  [ini root]"
        section=''
      else
        env2ini::log "  ${section}"
      fi

      while read -r line; do
        env2ini::read_config_to_env "${section}" "${line}"
      done < <(awk 1 "${config_file}")                             # Helm .toYaml trims the trailing new line which breaks line processing; awk 1 ... adds it back while reading
    }

    function env2ini::load_config_sources() {
      local path="${1}"

      env2ini::log "Processing $(basename "${path}")..."

      while read -d '' configFile; do
        env2ini::process_config_file "${configFile}"
      done < <(find "${path}" -type l -not -name '..data' -print0)

      env2ini::log "\n"
    }

    function env2ini::generate_initial_secrets() {
      # These environment variables will either be
      #   - overwritten with user defined values,
      #   - initially used to set up Gitea
      # Anyway, they won't harm existing app.ini files

      export ENV_TO_INI__SECURITY__INTERNAL_TOKEN=$(gitea generate secret INTERNAL_TOKEN)
      export ENV_TO_INI__SECURITY__SECRET_KEY=$(gitea generate secret SECRET_KEY)
      export ENV_TO_INI__OAUTH2__JWT_SECRET=$(gitea generate secret JWT_SECRET)

      env2ini::log "...Initial secrets generated\n"
    }

    # MUST BE CALLED BEFORE OTHER CONFIGURATION
    env2ini::generate_initial_secrets

    env2ini::load_config_sources '/env-to-ini-mounts/inlines/'
    env2ini::load_config_sources '/env-to-ini-mounts/additionals/'

    env2ini::log "=== All configuration sources loaded ===\n"

    # safety to prevent rewrite of secret keys if an app.ini already exists
    if [ -f ${GITEA_APP_INI} ]; then
      env2ini::log 'An app.ini file already exists. To prevent overwriting secret keys, these settings are dropped and remain unchanged:'
      env2ini::log '  - security.INTERNAL_TOKEN'
      env2ini::log '  - security.SECRET_KEY'
      env2ini::log '  - oauth2.JWT_SECRET'

      unset ENV_TO_INI__SECURITY__INTERNAL_TOKEN
      unset ENV_TO_INI__SECURITY__SECRET_KEY
      unset ENV_TO_INI__OAUTH2__JWT_SECRET
    fi

    environment-to-ini -o $GITEA_APP_INI -p ENV_TO_INI
---
# Source: oes/charts/gitea/templates/gitea/init.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-gitea-init
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  init_directory_structure.sh: |-
    #!/usr/bin/env bash

    set -euo pipefail

    set -x
    chown 1000:1000 /data
    mkdir -p /data/git/.ssh
    chmod -R 700 /data/git/.ssh
    [ ! -d /data/gitea ] && mkdir -p /data/gitea/conf

    # prepare temp directory structure
    mkdir -p "${GITEA_TEMP}"
    chown 1000:1000 "${GITEA_TEMP}"
    chmod ug+rwx "${GITEA_TEMP}"

  configure_gitea.sh: |-
    #!/usr/bin/env bash

    set -euo pipefail
    # Connection retry inspired by https://gist.github.com/dublx/e99ea94858c07d2ca6de
    function test_db_connection() {
      local RETRY=0
      local MAX=30

      echo 'Wait for database to become avialable...'
      until [ "${RETRY}" -ge "${MAX}" ]; do
        nc -vz -w2 isd-postgresql 5432 && break
        RETRY=$[${RETRY}+1]
        echo "...not ready yet (${RETRY}/${MAX})"
      done

      if [ "${RETRY}" -ge "${MAX}" ]; then
        echo "Database not reachable after '${MAX}' attempts!"
        exit 1
      fi
    }

    test_db_connection

    echo '==== BEGIN GITEA CONFIGURATION ===='

    gitea migrate
    function configure_admin_user() {
      local ACCOUNT_ID=$(gitea admin user list --admin | grep -e "\s\+${GITEA_ADMIN_USERNAME}\s\+" | awk -F " " "{printf \$1}")
      if [[ -z "${ACCOUNT_ID}" ]]; then
        echo "No admin user '${GITEA_ADMIN_USERNAME}' found. Creating now..."
        gitea admin user create --admin --username "${GITEA_ADMIN_USERNAME}" --password "${GITEA_ADMIN_PASSWORD}" --email "support@opsmx.com" --must-change-password=false
        echo '...created.'
      else
        echo "Admin account '${GITEA_ADMIN_USERNAME}' already exist. Running update to sync password..."
        gitea admin user change-password --username "${GITEA_ADMIN_USERNAME}" --password "${GITEA_ADMIN_PASSWORD}"
        echo '...password sync done.'
      fi
    }

    configure_admin_user

    function configure_ldap() {
        echo 'no ldap configuration... skipping.'
    }

    configure_ldap

    function configure_oauth() {
        echo 'no oauth configuration... skipping.'
    }

    configure_oauth

    echo '==== END GITEA CONFIGURATION ===='
---
# Source: oes/charts/minio/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
type: Opaque
data:
  accesskey: "c3Bpbm5ha2VyYWRtaW4="
  secretkey: "c3Bpbm5ha2VyYWRtaW4="
---
# Source: oes/charts/openldap/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-openldap
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
type: Opaque
data:
  LDAP_ADMIN_PASSWORD: "b3BzbXhhZG1pbjEyMw=="
  LDAP_CONFIG_PASSWORD: "b3BzbXhjb25maWcxMjM="
---
# Source: oes/charts/redis/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-redis
  labels:
    app: redis
    chart: redis-10.5.3
    release: "isd"
    heritage: "Helm"
type: Opaque
data:
  redis-password: "cGFzc3dvcmQ="
---
# Source: oes/charts/spinnaker/templates/secrets/registry.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-spinnaker-registry
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
    component: clouddriver
type: Opaque
data:
  dockerhub: ""
---
# Source: oes/charts/spinnaker/templates/secrets/spin-config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: isd-spinnaker-spin-config
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
stringData:
  config: |
    auth:
      basic:
        password: saporadmin
        username: admin
      enabled: true
    gate:
      endpoint: http://sapor-gate:8084
---
# Source: oes/templates/customstages/ansible-secrets.yaml
apiVersion: v1
stringData:
  gitpassword: 4fmschdd3455
  gitusername: opsmxuser2
  nodeuser: ubuntu
  userpassword: ubuntupassword
kind: Secret
metadata:
  name: ansible-secrets
type: Opaque
---
# Source: oes/templates/customstages/customnotification-ssmtp-secrets.yaml
apiVersion: v1
stringData:
  emailpassword: passowrdmail
  ssmtpemail: opsmxuser@opsmx.io
kind: Secret
metadata:
  name: ssmtp-secrets
type: Opaque
---
# Source: oes/templates/customstages/terraspinbackendconfig.yaml
apiVersion: v1
stringData:
  artifactaccounts.json: |
         {
            "artifactaccounts": [
               {
                 "accountname": "OpsMx-artifact-Github-account",
                 "artifacttype": "Github",
                 "host": "https://github.com",
                 "username": "opsmx",
                 "password": "wtwetr4543534"
                }
               ]
         }
kind: Secret
metadata:
  name: terraspinbackendconfig
---
# Source: oes/templates/customstages/updatepr-secrets.yaml
apiVersion: v1
stringData:
  accesstoken: dfvjkbv346jsd93os0skw0
kind: Secret
metadata:
  name: updatepr-secrets
type: Opaque
---
# Source: oes/templates/pipeline-promotion/local-spin-cli-config-secret.yaml
apiVersion: v1
stringData:
  # Spin CLI config content used by syncToSpinnaker stage
  # It is placed under ~/.spin/config
  # endpoint should be the spinnaker gate where pipelines are created/updated
  config: |-
    auth:
      basic:
        password: saporadmin
        username: admin
      enabled: true
    gate:
      endpoint: http://sapor-gate:8084
kind: Secret
metadata:
  name: local-spin-cli-config
---
# Source: oes/templates/pipeline-promotion/spin-cli-config-secret.yaml
apiVersion: v1
stringData:
  # Spin CLI config content used by syncToGit stage
  # It is placed under ~/.spin/config
  # custom job stage runs a spin cli and fetches the application/pipeline data
  # gate endpoint should point to the spinnaker from where application/pipeline data is fetched
  config: |-
    auth:
      basic:
        password: saporadmin
        username: admin
      enabled: true
    gate:
      endpoint: http://sapor-gate:8084
kind: Secret
metadata:
  name: spin-cli-config
---
# Source: oes/templates/sapor-gate/sapor-gate-secret.yaml
apiVersion: v1
data:
  gate-local.yml:
    c2VydmVyOgogIHRvbWNhdDoKICAgIGh0dHBzU2VydmVyUG9ydDogWC1Gb3J3YXJkZWQtUG9ydAogICAgaW50ZXJuYWxQcm94aWVzOiAuKgogICAgcHJvdG9jb2xIZWFkZXI6IFgtRm9yd2FyZGVkLVByb3RvCiAgICByZW1vdGVJcEhlYWRlcjogWC1Gb3J3YXJkZWQtRm9yCnNlY3VyaXR5OgogIGJhc2ljZm9ybToKICAgIGVuYWJsZWQ6IHRydWUKICB1c2VyOgogICAgbmFtZTogYWRtaW4KICAgIHBhc3N3b3JkOiBzYXBvcmFkbWluCiAgICByb2xlczogYWRtaW4K
  gate-overrides.yml:
    IyMgV0FSTklORwojIyBUaGlzIGZpbGUgd2FzIGF1dG9nZW5lcmF0ZWQsIGFuZCBfd2lsbF8gYmUgb3ZlcndyaXR0ZW4gYnkgSGFseWFyZC4KIyMgQW55IGVkaXRzIHlvdSBtYWtlIGhlcmUgX3dpbGxfIGJlIGxvc3QuCgpzZXJ2aWNlczoKICBjbG91ZGRyaXZlcjoKICAgIGJhc2VVcmw6IGh0dHA6Ly9zcGluLWNsb3VkZHJpdmVyLXJvOjcwMDIKICAgIGVuYWJsZWQ6IHRydWUKICBlY2hvOgogICAgYmFzZVVybDogaHR0cDovL3NwaW4tZWNoby13b3JrZXI6ODA4OQogICAgZW5hYmxlZDogdHJ1ZQoKZ2xvYmFsLnNwaW5uYWtlci50aW1lem9uZTogQW1lcmljYS9Mb3NfQW5nZWxlcw==
  gate.yml:
    IyMgV0FSTklORwojIyBUaGlzIGZpbGUgd2FzIGF1dG9nZW5lcmF0ZWQsIGFuZCBfd2lsbF8gYmUgb3ZlcndyaXR0ZW4gYnkgSGFseWFyZC4KIyMgQW55IGVkaXRzIHlvdSBtYWtlIGhlcmUgX3dpbGxfIGJlIGxvc3QuCgpzcGVjdGF0b3I6CiAgYXBwbGljYXRpb25OYW1lOiAke3NwcmluZy5hcHBsaWNhdGlvbi5uYW1lfQogIHdlYkVuZHBvaW50OgogICAgZW5hYmxlZDogZmFsc2UKCnNwaW5uYWtlcjoKICBleHRlbnNpYmlsaXR5OgogICAgcGx1Z2luczoge30KICAgIHJlcG9zaXRvcmllczoge30KICAgIHBsdWdpbnMtcm9vdC1wYXRoOiAvb3B0L2dhdGUvcGx1Z2lucwogICAgc3RyaWN0LXBsdWdpbi1sb2FkaW5nOiBmYWxzZQoKc2VydmVyOgogIHNzbDoKICAgIGVuYWJsZWQ6IGZhbHNlCiAgcG9ydDogJzgwODQnCiAgYWRkcmVzczogMC4wLjAuMApzZWN1cml0eToKICBiYXNpYzoKICAgIGVuYWJsZWQ6IHRydWUKICB1c2VyOiB7fQpjb3JzOiB7fQpnb29nbGU6IHt9CgppbnRlZ3JhdGlvbnM6CiAgZ3JlbWxpbjoKICAgIGVuYWJsZWQ6IGZhbHNlCiAgICBiYXNlVXJsOiBodHRwczovL2FwaS5ncmVtbGluLmNvbS92MQoKIyBoYWxjb25maWcKCnNlcnZpY2VzOgogIGNsb3VkZHJpdmVyOgogICAgY29uZmlnOgogICAgICBkeW5hbWljRW5kcG9pbnRzOgogICAgICAgIGRlY2s6IGh0dHA6Ly9zcGluLWNsb3VkZHJpdmVyLXJvLWRlY2s6NzAwMgogIHBsYXRmb3JtOgogICAgYmFzZVVybDogaHR0cDovL29lcy1wbGF0Zm9ybTo4MDk1CiAgICB1c2VyR3JvdXBBcGlQYXRoOiAvcGxhdGZvcm1zZXJ2aWNlL3YxL3VzZXJzL3t1c2VybmFtZX0vdXNlcmdyb3Vwcy9pbXBvcnRBbmRDYWNoZQogICAgZW5hYmxlZDogdHJ1ZQo=
  spinnaker.yml:
    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
  spinnakerconfig.yml:
    I0VtcHR5IGZpbGUK
kind: Secret
metadata:
  labels:
    app: oes
    component: sapor-gate
  name: sapor-gate-files
type: Opaque
---
# Source: oes/templates/secrets/bootstrap-secret.yaml
apiVersion: v1
stringData:
  bootstrap.yml: |-
    spring:
      cloud:
        vault:
          enterprise: false
          namespace: admin/isd-platform
          uri: https://server.vaultint.opsmx.net
          token: 123132
          enabled: false
          kv:
            enabled: false
          generic:
            enabled: false
    jasypt:
      encryptor:
        password: Q7udUkHPuA3VnNlOtksSgQ
    datasource:
      secretManagement:
        source: db
kind: Secret
metadata:
  name: bootstrap
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
---
# Source: oes/templates/secrets/gitea-secret.yaml
apiVersion: v1
stringData:
  # Repo uri to fetch halyard configuration
  username: opsmx
  password: opsmxadmin123
kind: Secret
metadata:
  name: gitea-secret
type: Opaque
---
# Source: oes/templates/secrets/oes-audit-client-secret.yaml
apiVersion: v1
stringData:
  audit-local.yml: |
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/auditdb
        username: 'postgres'
        password: 'networks123'
    logging:
      level:
        com.opsmx.auditclientservice: INFO
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    oes:
      admin:
        user: admin
    feign:
      client:
        platformservice:
          name: platformservice
          url: http://oes-platform:8095
        visibilityservice:
          name: visibilityservice
          url: http://oes-visibility:8096
    
    fixedDelay:
      in:
        milliseconds: 120000
    initialDelay:
      in:
        milliseconds: 300000
    scheduler:
      threads: 16
    
kind: Secret
metadata:
  labels:
    app: oes
    component: auditclient
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-audit-client-config
---
# Source: oes/templates/secrets/oes-audit-service-secret.yaml
apiVersion: v1
stringData:
  audit-local.yml: |
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/auditdb
        username: 'postgres'
        password: 'networks123'
    logging:
        level:
          com.opsmx.auditservice: INFO
    message-broker:
      enabled: true
      username: 'rabbitmq'
      password: 'Networks123'
      host: rabbitmq-service
      port: 5672
      endpoint:
        name: rabbitmq
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    feign:
      client:
        platformservice:
          name: platformservice
          url: http://oes-platform:8095
        auditclientservice:
          name: auditclientservice
          url: http://oes-audit-client:8098
        oes:
          url: http://oes-sapor:8085
        autopilot:
          url: http://oes-autopilot:8090
        visibilityservice:
          url: http://oes-visibility:8096
        dashboard:
          url: http://oes-dashboard:8094
    
kind: Secret
metadata:
  labels:
    app: oes
    component: auditservice
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-audit-service-config
---
# Source: oes/templates/secrets/oes-autopilot-secret.yaml
apiVersion: v1
stringData:
  autopilot.properties: |
    # Enable Build Analysis
    build.analysis=false
    # DB configuration
    secret.datasource.username=postgres
    secret.datasource.password=networks123
    secret.datasource.url=jdbc:postgresql://oes-db:5432/opsmx
    secret.platform.url=http://oes-platform:8095
    secret.ds.protocol=http://
    secret.ds.url=localhost:5005
    
    server.host.dns.name=/ui
    
    gate.url=http://oes-gate:8084
    #gate.url=http://oes.example.ops.com/gate
    
    #datascience configuration
    oes.datascience.baseUrl=http://oes-datascience:5005
    #build.analysis=false
    ds.async.flow=true
    
    #audit services
    auditservice.enabled=true
    auditservice.name=auditservice
    auditservice.url=http://oes-audit-service:8097
    auditclientservice.name=auditclientservice
    auditclientservice.url=http://oes-audit-client:8098
    
    # Standard-error-path
    standardErrorCodes.filePath=/opsmx/conf/standard-error-code.csv
    
    #storage configuration
    storage.type =db_storage
    #storage.type =object_storage
    #storage.endpoint=http://isd-minio:9000
    #storage.accesskey = spinnakeradmin
    #storage.secretkey = spinnakeradmin
    #storage.region= us-east-1
    ds.seperate.service=true
    
    
    # Logging Level
    logging.level.com.opsmx.analytics=ERROR
    datasource.secretManagement.source = db
    
kind: Secret
metadata:
  name: oes-autopilot-config
  labels:
    app: oes
    component: autopilot
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
---
# Source: oes/templates/secrets/oes-datascience-secret.yaml
apiVersion: v1
stringData:
  app-config.yml: |
    # Enable Build Analysis
    APP:
       ENVIRONMENT: dev
       DEBUG: True
       # Only accept True or False
       BIND: 0.0.0.0:5005
       WORKERS: 1
       PROTOCOL: http://
       TIMEOUT: 3600
       CELERY_ENABLED: True
       # Only accept True or False
    
    OBJECT_STORAGE:
          ENDPOINT: http://isd-minio:9000
          BUCKET_NAME: autopilot
    POSTGRES:
          USERNAME: 'postgres'
          PASSWORD: 'networks123'
          HOST: oes-db
          PORT: 5432
          DB: autopilotqueue
    
    RABBITMQ:
          USERNAME: 'rabbitmq'
          PASSWORD: 'Networks123'
          HOST: rabbitmq-service
          PORT: 5672
    
  minio-credentials: |
    [default]
        aws_access_key_id = spinnakeradmin
        aws_secret_access_key = spinnakeradmin
    
    
kind: Secret
metadata:
  labels:
    app: oes
    component: datascience
  name: oes-datascience-config
---
# Source: oes/templates/secrets/oes-gate-configmap.yaml
apiVersion: v1
stringData:
  gate.yml: |
    retrofit:
      connectTimeout: 60000
      readTimeout: 60000
      callTimeout: 60000
      writeTimeout: 60000
      retryOnConnectionFailure: true
    services:
      opsmx:
        baseUrl: http://oes-sapor:8085
        enabled: true
      autopilot:
        baseUrl: http://oes-autopilot:8090
        enabled: true
      platform:
        baseUrl: http://oes-platform:8095
        userGroupApiPath: /platformservice/v1/users/{username}/usergroups/importAndCache
        enabled: true
      dashboard:
        baseUrl: http://oes-dashboard:8094
        enabled: true
      visibility:
        baseUrl: http://oes-visibility:8096
        enabled: true
      auditservice:
         baseUrl: "http://oes-audit-service:8097"
         enabled: true
      auditclient:
         baseUrl: "http://oes-audit-client:8098"
         enabled: true
      oesui:
        externalUrl: /ui/
      keel:
        enabled: false
      clouddriver:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-ro:7002
        enabled: true
      clouddriverCaching:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-caching:7002
        enabled: true
      clouddriverRo:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-ro:7002
        enabled: true
      clouddriverRoDeck:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-ro-deck:7002
        enabled: true
      clouddriverRw:
        host: 0.0.0.0
        port: 7002
        baseUrl: http://spin-clouddriver-rw:7002
        enabled: true
      deck:
        host: 0.0.0.0
        port: 9000
        baseUrl: http://oes.example.ops.com
        enabled: true
      echo:
        host: 0.0.0.0
        port: 8089
        baseUrl: http://spin-echo-worker:8089
        enabled: true
      echoScheduler:
        host: 0.0.0.0
        port: 8089
        baseUrl: http://spin-echo-scheduler:8089
        enabled: true
      echoWorker:
        host: 0.0.0.0
        port: 8089
        baseUrl: http://spin-echo-worker:8089
        enabled: true
      fiat:
        host: 0.0.0.0
        port: 7003
        baseUrl: http://spin-fiat:7003
        enabled: false
      front50:
        host: 0.0.0.0
        port: 8080
        baseUrl: http://spin-front50:8080
        enabled: true
      gate:
        host: 0.0.0.0
        port: 8084
        baseUrl: http://oes-gate.example.ops.com
        enabled: true
      igor:
        host: 0.0.0.0
        port: 8088
        baseUrl: http://spin-igor:8088
        enabled: true
      kayenta:
        host: 0.0.0.0
        port: 8090
        baseUrl: http://spin-kayenta:8090
        enabled: false
      orca:
        host: 0.0.0.0
        port: 8083
        baseUrl: http://spin-orca:8083
        enabled: true
      redis:
        host: 0.0.0.0
        port: 6379
        baseUrl: redis://:password@isd-redis-master:6379
        enabled: true
      rosco:
        host: 0.0.0.0
        port: 8087
        baseUrl: http://spin-rosco:8087
        enabled: true
      user: {}
    cors:
      allowed-origins-pattern: ^https?://(?:localhost|oes.example.ops.com|spin.example.ops.com|opsmx.com)(?::[1-9]\d*)?/?
      
    ldap:
      enabled: true
      url: ldap://isd-openldap:389
      managerDn: cn=admin,dc=example,dc=org
      managerPassword: opsmxadmin123
      groupSearchBase: ou=groups,dc=example,dc=org
      groupSearchFilter: member={0}
      groupRoleAttributes: cn
      userDnPattern: cn={0},dc=example,dc=org
    
    file:
      enabled: false
      url: /platformservice/v1/users/authenticate
    authn:
      mode: session
    google: {}
    redis:
      connection: redis://:password@isd-redis-master:6379
    server:
      session:
        timeoutInSeconds: 7200
      tomcat:
        httpsServerPort: X-Forwarded-Port
        internalProxies: .*
        protocolHeader: X-Forwarded-Proto
        remoteIpHeader: X-Forwarded-For
    gate:
      installation:
        mode: common    #Allowed values are --> oes,common
    rbac:
      feature:
        application:
          enabled: false
    security:
      contentSecurityPolicy: "object-src 'none'; script-src 'unsafe-eval' 'unsafe-inline' https: http:;"
    spinnaker:
      extensibility:
        plugins:
        deck-proxy:
          enabled: true
          plugins:
            Opsmx.VerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.TestVerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.PolicyGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.VisibilityApprovalPlugin:
              enabled: true
              version: 1.0.1
        repositories:
            opsmx-repo:
              url: file:///opt/spinnaker/plugins/plugins.json
              #url: https://raw.githubusercontent.com/OpsMx/spinnakerPluginRepository/v3.10.0/plugins.json
    
    allowUnauthenticatedAccess:
      agentAPI: false
      webhooks: true
    
    logging:
      level:
        com.netflix.spinnaker.gate.security: INFO
        org.springframework.security: INFO
        org.springframework.web: INFO
        #com.netflix.spinnaker.gate.security: DEBUG
        #org.springframework.security: DEBUG
        #org.springframework.web: DEBUG
    
kind: Secret
metadata:
  name: oes-gate-config
  labels:
    app: oes
    component: gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
---
# Source: oes/templates/secrets/oes-gate-secret.yaml
apiVersion: v1
stringData:
  GATEURL: http://sapor-gate:8084
  GATEUSER: admin
  GATEPASS: saporadmin
kind: Secret
metadata:
  name: oes-gate-secret
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
---
# Source: oes/templates/secrets/oes-platform-configmap.yaml
apiVersion: v1
stringData:
  platform-local.yml: |
    
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/platformdb
        username: 'postgres'
        password: 'networks123'
    ldap.managerPassword: 'opsmxadmin123'
    redis:
        connection: redis://:password@isd-redis-master:6379
    #datasource.url: jdbc:postgresql://oes-db:5432/visibilitydb
    #postgres.password: 'networks123'
    #postgres.username: 'postgres'
    
    datasource:
      secretManagement:
        source: db
    rbacEnabled: false
    supportedFeatures:
      - deployment_verification
      - sapor
      - visibility
    userGroup:
      superAdminGroups: admin
    user:
      source: ldap
    ldap:
      enabled: true
      url: ldap://isd-openldap:389
      managerDn: cn=admin,dc=example,dc=org
      groupSearchBase: ou=groups,dc=example,dc=org
      groupSearchFilter: member={0}
      groupRoleAttributes: cn
      userDnPattern: cn={0},dc=example,dc=org
    dashboard:
      scheduler:
        enable: false
        fixedDelay:
          in:
            milliseconds: 120000
        initialDelay:
          in:
            milliseconds: 300000
        workerThreads: 50
    database:
      cleanup:
        scheduler:
          enabled: false
          daysInterval: 180
          cron: 0 0 0 * * *
    oes:
      sapor:
        url: http://oes-sapor:8085
      autopilot:
        url: http://oes-autopilot:8090
      dashboard:
        url: http://oes-dashboard:8094
      visibility:
        url: http://oes-visibility:8096
      auditclient:
        url: http://oes-audit-client:8098
      policyGate:
        url: http://oes-gate:8084
        path: /v1/data/
      auditservice:
        url: "http://oes-audit-service:8097"
      ui:
      # Ex: "https://oes-poc.dev.opsmx.org/"
        url: "http://oes.example.ops.com/ui"
      gate:
        url: http://oes-gate:8084
      approvalGate:
        apiUrl: http://oes-gate:8084/visibilityservice/v5/approvalGates/{id}/trigger
    
      verificationGate:
        apiUrl: http://oes-gate:8084/autopilot/api/v3/registerCanary
    
    logging:
      level:
        com.opsmx.platformservice: INFO
        org.springframework.security: INFO
        org.springframework.web: INFO
    
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    
kind: Secret
metadata:
  name: oes-platform-config
  labels:
    app: oes
    component: platform
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
---
# Source: oes/templates/secrets/oes-sapor-configmap.yaml
apiVersion: v1
stringData:
  application.yml: |
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/oesdb
        username: 'postgres'
        password: 'networks123'
    
    message-broker:
      enabled: true
      username: 'rabbitmq'
      password: 'Networks123'
      host: rabbitmq-service
      port: 5672
      endpoint:
        name: rabbitmq
    
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    
    secretManagement:
      source:
        config: db
      encryption: true
    oes:
      rbac:
        enabled: true
      admin:
        user: admin
      platform:
        url: http://oes-platform:8095
      visibility:
        url: http://oes-visibility:8096
      auditservice:
        enabled: true
        url: "http://oes-audit-service:8097"
      dashboard:
        url: http://oes-dashboard:8094
      commongateurl: http://oes-gate:8084
    pipeline-promotion:
      github:
        
        enabled: true
        
        username:  opsmx
        token: opsmxadmin123
        branch: master
        cloneUrl: http://opsmx:opsmxadmin123@isd-gitea-http.opsmx-isd:3000/opsmx/gitea-standard-repo
      bitbucket:
        
        enabled: false
        
        username:  git/stash_username
        token: git/stash_token
        branch: master
        cloneUrl: https://git/stash_username:git/stash_token@github.com/OpsMx//standard-gitops-repo
      amazonS3:
        
        enabled: false
        
        accessKeyId: AWS_ACCESS_KEY_ID
        secretAccessKey: AWS_SECRET_ACCESS_KEY
        region: regionofbucket
        bucketName: bucket name.e.g-testbucket
    spinnaker:
      restart:
        endPoint: /webhooks/webhook/restartSpinnaker
      encrypt:
        enabled: false
      sync:
        permission:
          enabled: true
    
    datasources:
      platform: true
    
    ## Set the below field to true if agent for kubernetes
    kubernetes:
      kinds:
      omitKinds:
      - podPreset
      agent:
        enabled: true
        serverInternalHostName: opsmx-controller-controller1
        serverPort: 9003
        caCertfile: /opt/opsmx/controller/ca.crt
        certFile: /opt/opsmx/controller/cert/tls.crt
        keyFile: /opt/opsmx/controller/cert/tls.key
        image: quay.io/opsmxpublic/forwarder-agent:v3.5.7
      template:
        path: /opt/opsmx/controller
        kubectlTemplateFileName: kubeconfig.template
        manifestTemplateFileName: deploy-agent.template
    
  client.p12: |
    
kind: Secret
metadata:
  name: oes-sapor-config
  labels:
    app: oes
    component: sapor
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
---
# Source: oes/templates/secrets/oes-visibility-secret.yaml
apiVersion: v1
stringData:
  visibility-local.yml: |
    spring:
      datasource:
        url: jdbc:postgresql://oes-db:5432/visibilitydb
        username: 'postgres'
        password: 'networks123'
        #sslmode: require
      visiblity:
        connectors:
          configured: JIRA,GIT,AUTOPILOT,SONARQUBE,JENKINS,AQUAWAVE
      logging:
        level:
          io:
            swagger:
              models:
                parameters:
                  AbstractSerializableParameter: ERROR
    
    management:
      endpoints:
        web:
          base-path: /mgmt
          exposure:
            include: health,info,metrics,prometheus
      endpoint:
        health:
          show-details: always
          show-components: always
      health:
        elasticsearch:
          enabled: false
        ldap:
          enabled: false
    
    ui:
      approval:
        url: /ui/plugin-isd/approval/{applicationId}/{serviceId}/{approvalGateId}
    
    gate:
      url: http://oes-gate:8084
    
    jira:
      api:
        url: /rest/api/2/search
      navigate:
        url: hosturl/browse/{issue_Id}
    
    git:
      apiurl: /repos/{account}/{repo}/commits/{commitId}
      userurl: /user
      navigate.url: https://github.com/{account}/{repo_name}/commit/{commit_Id}
    
    jenkins:
      api:
        url: /job/{jobname}/{buildId}/api/json
      navigate:
        url: hosturl/job/{jobname}/{buildId}
    
    sonar:
      navigate:
        Url: hosturl/dashboard?id={projectKey}
    
    aquawave:
      api:
        url: https://api.aquasec.com/v2/images/{id}
      navigate:
        url: https://cloud.aquasec.com/vs/#/images/{id}
    
    autopilot:
      api:
        url: http://oes-autopilot:8090
    
    platform:
      service:
        url: http://oes-platform:8095
    auditservice:
      enabled: true
      name: auditservice
      url: "http://oes-audit-service:8097"
    auditclientservice:
      name: auditclientservice
      url: "http://oes-audit-client:8098"
    
    datasource:
      secretManagement:
        source: db
    
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    
    
kind: Secret
metadata:
  name: oes-visibility-config
  labels:
    app: oes
    component: visibility
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
---
# Source: oes/templates/secrets/opsmx-gitops-secret.yaml
apiVersion: v1
stringData:
  # Repo uri to fetch halyard configuration
  gitcloneparam: https://git/stash_username:git%2Fstash_token@github.com/OpsMx/standard-gitops-repo.git

  # Repo details to fetch dynamic configuration
  dynamicaccountsgituri: https://github.com/OpsMx/standard-gitops-repo.git
  gituser: git/stash_username
  gittoken: git/stash_token
  dynamicAccRepository: standard-gitops-repo

kind: Secret
metadata:
  name: opsmx-gitops-auth
type: Opaque
---
# Source: oes/templates/secrets/sapor-bootstrap-secret.yaml
apiVersion: v1
stringData:
  bootstrap.yml: |-
    spring:
      cloud:
        config:
          server:
            composite:
              - type: native
                search-locations: ${user.home}/config
        vault:
          enterprise: false
          namespace: admin/isd-platform
          uri: https://server.vaultint.opsmx.net
          token: 123132
          enabled: false
          kv:
            enabled: false
          generic:
            enabled: false
    jasypt:
      encryptor:
        password: Q7udUkHPuA3VnNlOtksSgQ
kind: Secret
metadata:
  name: sapor-bootstrap
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
---
# Source: oes/charts/minio/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
data:
  initialize: |-
    #!/bin/sh
    set -e ; # Have script exit in the event of a failed command.
    MC_CONFIG_DIR="/etc/minio/mc/"
    MC="/usr/bin/mc --insecure --config-dir ${MC_CONFIG_DIR}"
    
    # connectToMinio
    # Use a check-sleep-check loop to wait for Minio service to be available
    connectToMinio() {
      SCHEME=$1
      ATTEMPTS=0 ; LIMIT=29 ; # Allow 30 attempts
      set -e ; # fail if we can't read the keys.
      ACCESS=$(cat /config/accesskey) ; SECRET=$(cat /config/secretkey) ;
      set +e ; # The connections to minio are allowed to fail.
      echo "Connecting to Minio server: $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT" ;
      MC_COMMAND="${MC} config host add myminio $SCHEME://$MINIO_ENDPOINT:$MINIO_PORT $ACCESS $SECRET" ;
      $MC_COMMAND ;
      STATUS=$? ;
      until [ $STATUS = 0 ]
      do
        ATTEMPTS=`expr $ATTEMPTS + 1` ;
        echo \"Failed attempts: $ATTEMPTS\" ;
        if [ $ATTEMPTS -gt $LIMIT ]; then
          exit 1 ;
        fi ;
        sleep 2 ; # 1 second intervals between attempts
        $MC_COMMAND ;
        STATUS=$? ;
      done ;
      set -e ; # reset `e` as active
      return 0
    }
    
    # checkBucketExists ($bucket)
    # Check if the bucket exists, by using the exit code of `mc ls`
    checkBucketExists() {
      BUCKET=$1
      CMD=$(${MC} ls myminio/$BUCKET > /dev/null 2>&1)
      return $?
    }
    
    # createBucket ($bucket, $policy, $purge)
    # Ensure bucket exists, purging if asked to
    createBucket() {
      BUCKET=$1
      POLICY=$2
      PURGE=$3
      VERSIONING=$4
    
      # Purge the bucket, if set & exists
      # Since PURGE is user input, check explicitly for `true`
      if [ $PURGE = true ]; then
        if checkBucketExists $BUCKET ; then
          echo "Purging bucket '$BUCKET'."
          set +e ; # don't exit if this fails
          ${MC} rm -r --force myminio/$BUCKET
          set -e ; # reset `e` as active
        else
          echo "Bucket '$BUCKET' does not exist, skipping purge."
        fi
      fi
    
      # Create the bucket if it does not exist
      if ! checkBucketExists $BUCKET ; then
        echo "Creating bucket '$BUCKET'"
        ${MC} mb myminio/$BUCKET
      else
        echo "Bucket '$BUCKET' already exists."
      fi
    
    
      # set versioning for bucket
      if [ ! -z $VERSIONING ] ; then
        if [ $VERSIONING = true ] ; then
            echo "Enabling versioning for '$BUCKET'"
            ${MC} version enable myminio/$BUCKET
        elif [ $VERSIONING = false ] ; then
            echo "Suspending versioning for '$BUCKET'"
            ${MC} version suspend myminio/$BUCKET
        fi
      else
          echo "Bucket '$BUCKET' versioning unchanged."
      fi
    
      # At this point, the bucket should exist, skip checking for existence
      # Set policy on the bucket
      echo "Setting policy of bucket '$BUCKET' to '$POLICY'."
      ${MC} policy set $POLICY myminio/$BUCKET
    }
    
    # Try connecting to Minio instance
    scheme=http
    connectToMinio $scheme
    # Create the bucket
    
    # Create the buckets
    createBucket spinnaker none false 
    createBucket autopilot none false
---
# Source: oes/charts/openldap/templates/configmap-customldif.yaml
#
# A ConfigMap spec for openldap slapd that map directly to files under
# /container/service/slapd/assets/config/bootstrap/ldif/custom
#
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-openldap-customldif
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
data:
  01-memberof.ldif: |-
    dn: cn=module,cn=config
    cn: module
    objectClass: olcModuleList
    olcModuleLoad: memberof.la
    olcModulePath: /usr/lib/ldap
    
    dn: olcOverlay={0}memberof,olcDatabase={1}hdb,cn=config
    objectClass: olcConfig
    objectClass: olcMemberOf
    objectClass: olcOverlayConfig
    objectClass: top
    olcOverlay: memberof
    olcMemberOfDangling: ignore
    olcMemberOfRefInt: TRUE
    olcMemberOfGroupOC: groupOfNames
    olcMemberOfMemberAD: member
    olcMemberOfMemberOfAD: memberOf
  02-refint1.ldif: |-
    dn: cn=module{1},cn=config
    changetype: modify
    add: olcmoduleload
    olcmoduleload: refint.la
  03-refint2.ldif: |-
    dn: olcOverlay={1}refint,olcDatabase={1}hdb,cn=config
    objectClass: olcConfig
    objectClass: olcOverlayConfig
    objectClass: olcRefintConfig
    objectClass: top
    olcOverlay: {1}refint
    olcRefintAttribute: memberof member manager owner
  04-add_ou.ldif: |-
    dn: ou=groups,dc=example,dc=org
    objectClass: organizationalUnit
    ou: Groups
  05-admin.ldif: |-
    dn: cn=admin,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: admin
    description: read write and execute group
    member: cn=admin,dc=example,dc=org
  06-developer.ldif: |-
    dn: cn=developers,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: developers
    description: read only users
    member: cn=admin,dc=example,dc=org
    member: cn=developer,dc=example,dc=org
  07-qa.ldif: |-
    dn: cn=QA,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: QA
    description: read only users
    member: cn=admin,dc=example,dc=org
    member: cn=qa,dc=example,dc=org
  08-manager.ldif: |-
    dn: cn=managers,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: managers
    description: read and execute group
    member: cn=admin,dc=example,dc=org
    member: cn=manager,dc=example,dc=org
  09-IT-manager.ldif: |-
    dn: cn=ITManagers,ou=groups,dc=example,dc=org
    objectClass: groupofnames
    cn: ITManagers
    description: read and execute group
    member: cn=admin,dc=example,dc=org
    member: cn=ITManager,dc=example,dc=org
  10-users.ldif: |-
    dn: cn=user1,dc=example,dc=org
    objectClass: simpleSecurityObject
    objectClass: organizationalRole
    cn: user1
    userpassword: {SSHA}Y9L4AsYL16WLK10qDZ62pTScFnaWb0nz
    
    dn: cn=user2,dc=example,dc=org
    objectClass: simpleSecurityObject
    objectClass: organizationalRole
    cn: user2
    userpassword: {SSHA}DasTBI0eut1F83Bh1F1HXmDT8juJj3pY
    
    dn: cn=user3,dc=example,dc=org
    objectClass: simpleSecurityObject
    objectClass: organizationalRole
    cn: user3
    userpassword: {SSHA}Qu1FW7BdLMndwM/Gf+zc3a8VIMAymbuv
    
    dn: cn=developers,ou=groups,dc=example,dc=org
    changetype: modify
    add: member
    member: cn=user1,dc=example,dc=org
    member: cn=user3,dc=example,dc=org
    
    dn: cn=QA,ou=groups,dc=example,dc=org
    changetype: modify
    add: member
    member: cn=user2,dc=example,dc=org
    member: cn=user3,dc=example,dc=org
---
# Source: oes/charts/openldap/templates/configmap-env.yaml
#
# A ConfigMap spec for openldap slapd that map directly to env variables in the Pod.
# List of environment variables supported is from the docker image:
# https://github.com/osixia/docker-openldap#beginner-guide
# Note that passwords are defined as secrets
#
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-openldap-env
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
data:
  LDAP_BACKEND: hdb
  LDAP_DOMAIN: example.org
  LDAP_ORGANISATION: Example Inc.
  LDAP_REMOVE_CONFIG_AFTER_SETUP: "false"
  LDAP_TLS: "true"
  LDAP_TLS_ENFORCE: "false"
---
# Source: oes/charts/redis/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-redis
  labels:
    app: redis
    chart: redis-10.5.3
    heritage: Helm
    release: isd
data:
  redis.conf: |-
    # User-supplied configuration:
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly no
    # Disable RDB persistence, AOF persistence already enabled.
    save 60 1000
  master.conf: |-
    dir /data
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
  replica.conf: |-
    dir /data
    slave-read-only yes
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
---
# Source: oes/charts/redis/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-redis-health
  labels:
    app: redis
    chart: redis-10.5.3
    heritage: Helm
    release: isd
data:
  ping_readiness_local.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_PASSWORD --no-auth-warning \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_PASSWORD --no-auth-warning \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$response" != "PONG" ] && [ "$response" != "LOADING Redis is loading the dataset in memory" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_MASTER_PASSWORD --no-auth-warning \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    response=$(
      timeout -s 9 $1 \
      redis-cli \
        -a $REDIS_MASTER_PASSWORD --no-auth-warning \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$response" != "PONG" ] && [ "$response" != "LOADING Redis is loading the dataset in memory" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status
---
# Source: oes/charts/spinnaker/templates/configmap/additional-profile-configmaps.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-additional-profile-config-maps
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  echo-local.yml: |-
    microsoftteams:
      enabled: true
    rest:
      enabled: true
      endpoints:
      - url: http://oes-audit-service:8097/auditservice/v1/echo/events/data
        wrap: false
      - url: http://oes-sapor:8085/oes/echo
        wrap: false
  fiat-local.yml: |-
    auth:
      groupMembership:
        ldap:
          groupRoleAttributes: cn
          groupSearchBase: ou=groups,dc=example,dc=org
          groupSearchFilter: member={0}
          managerDn: cn=admin,dc=example,dc=org
          managerPassword: opsmxadmin123
          url: ldap://RELEASE_NAME-openldap:389
          userDnPattern: cn={0},dc=example,dc=org
        service: ldap
  front50-local.yml: |-
    policy:
      opa:
        enabled: true
        url: http://oes-sapor.opsmx-isd:8085
    spinnaker:
      s3:
        versioning: false
  gate-local.yml: |-
    server:
      tomcat:
        httpsServerPort: X-Forwarded-Port
        internalProxies: .*
        protocolHeader: X-Forwarded-Proto
        remoteIpHeader: X-Forwarded-For
    spinnaker:
      extensibility:
        deck-proxy:
          enabled: true
          plugins:
            Opsmx.CustomStagePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.PolicyGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.TestVerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.VerificationGatePlugin:
              enabled: true
              version: 1.0.1
            Opsmx.VisibilityApprovalPlugin:
              enabled: true
              version: 1.0.1
        plugins: null
        repositories:
          opsmx-repo:
            url: https://raw.githubusercontent.com/opsmx/spinnakerPluginRepository/v3.9.0/plugins.json
  # Custom stage for pipeline promotion;
  # same configuration can be put in a repo for gitops style
  orca-local.yml: |-
    
    policy:
      opa:
        enabled: true
        url: http://oes-sapor:8085
    pollers:
      oldPipelineCleanup:
        enabled: true                  # This enables old pipeline execution cleanup (default: false)
        intervalMs: 3600000            # How many milliseconds between pipeline cleanup runs (default: 1hr or 3600000)
        thresholdDays: 30              # How old a pipeline execution must be to be deleted (default: 30)
        minimumPipelineExecutions: 5   # How many executions to keep around (default: 5)
    
    tasks:
      daysOfExecutionHistory: 180      # How many days to keep old task executions around.
    
    job:
      preconfigured:
        kubernetes:
          - label: pipelineSyncToGit
            cloudProvider: kubernetes
            credentials: default
            description: Update git with pipelines in Spinnaker
            account: default
            application: sampleapp
            type: pipelineSyncToGit
            waitForCompletion: true
            parameters:
              - defaultValue: "app1,app2,..."
                description: "Please enter spinnaker applications separated by comma"
                label: spinnaker applications
                mapping: 'manifest.spec.template.spec.containers[0].env[0].value'
                name: spinnaker_applications
              - defaultValue: "pipeline1,pipeline2..."
                description: "Please enter spinnaker pipelines separated by comma"
                label: pipieline names
                mapping: 'manifest.spec.template.spec.containers[0].env[1].value'
                name: spinnaker_pipelines
            manifest:
                apiVersion: batch/v1
                kind: Job
                metadata:
                  generateName: pipepromot-
                  namespace: SPINNAKER_NAMESPACE
                  labels:
                     stage: opsmx-custom
                     stagetype: pipelinepromotion
                spec:
                  backoffLimit: 0
                  template:
                    spec:
                      containers:
                      - command: ["bash", "scripts/deployer.sh"]
                        image: 'opsmxdev/pipepromot:1.0'
                        imagePullPolicy: IfNotPresent
                        name: pipepromot
                        volumeMounts:
                        - mountPath: /home/opsmx/scripts
                          name: pipe-promot-scripts
                        - mountPath: /home/opsmx/config
                          name: pipe-promot-config
                        - mountPath: /home/opsmx/.spin
                          name: spin-cli-config
                        env:
                          - name: spinnaker_applications
                            value: 'will be replaced'
                          - name: spinnaker_pipelines
                            value: 'will be replaced'
                          - name: command
                            value: 'upload'
                          - name: git_secret_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_secret_token
                          - name: git_pr_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_pr_token
                      volumes:
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-config
                        name: pipe-promot-config
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-scripts
                        name: pipe-promot-scripts
                      - name: spin-cli-config
                        secret:
                          defaultMode: 420
                          secretName: spin-cli-config
                      restartPolicy: Never
                      serviceAccountName: default
          - label: pipelineSyncToSpinnaker
            cloudProvider: kubernetes
            credentials: default
            description: Sync Spinnaker pipelines from git
            account: default
            application: sampleapp
            type: pipelineSyncToSpinnaker
            waitForCompletion: true
            parameters:
              - defaultValue: "app1,app2,..."
                description: "Please enter spinnaker applications separated by comma"
                label: spinnaker applications
                mapping: 'manifest.spec.template.spec.containers[0].env[0].value'
                name: spinnaker_applications
              - defaultValue: "pipeline1,pipeline2..."
                description: "Please enter spinnaker pipelines separated by comma"
                label: pipieline names
                mapping: 'manifest.spec.template.spec.containers[0].env[1].value'
                name: spinnaker_pipelines
            manifest:
                apiVersion: batch/v1
                kind: Job
                metadata:
                  generateName: pipepromot-
                  namespace: SPINNAKER_NAMESPACE
                  labels:
                     stage: opsmx-custom
                     stagetype: pipelinepromotion
                spec:
                  backoffLimit: 0
                  template:
                    spec:
                      containers:
                      - command: ["bash", "scripts/deployer.sh"]
                        image: 'opsmxdev/pipepromot:1.0'
                        imagePullPolicy: IfNotPresent
                        name: pipepromot
                        volumeMounts:
                        - mountPath: /home/opsmx/scripts
                          name: pipe-promot-scripts
                        - mountPath: /home/opsmx/config
                          name: pipe-promot-config
                        - mountPath: /home/opsmx/.spin
                          name: spin-cli-config
                        env:
                          - name: spinnaker_applications
                            value: 'will be replaced'
                          - name: spinnaker_pipelines
                            value: 'will be replaced'
                          - name: command
                            value: 'download'
                          - name: git_secret_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_secret_token
                          - name: git_pr_token
                            valueFrom:
                              secretKeyRef:
                                name: git-token
                                key: git_pr_token
                      volumes:
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-config
                        name: pipe-promot-config
                      - configMap:
                          defaultMode: 420
                          name: pipe-promot-scripts
                        name: pipe-promot-scripts
                      - name: spin-cli-config
                        secret:
                          defaultMode: 420
                          secretName: local-spin-cli-config
                      restartPolicy: Never
                      serviceAccountName: default
    webhook:
      preconfigured:
      - label: "JIRA: Wait for state"
        type: waitJiraState
        enabled: true
        description: Custom stage that waits for a specific state on a Jira Issue
        method: GET
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        failPipeline: true
        progressJsonPath: "fields.status.name"
        payload: ""
        retryStatusCodes:
          - 200
        statusJsonPath: "fields.status.name"
        statusUrlResolution: "getMethod"
        successStatuses: ${parameterValues['success']}
        retryStatuses: ${parameterValue['retry']}
        terminalStatuses: ${parameterValues['terminate']}
        canceledStatuses: ${parameterValues['cancel']}
        waitBeforeMonitor: "1"
        waitForCompletion: true
        parameters:
        - label: JIRA Issue ID
          name: issue
          description: "The JIRA issue, the default relies on JIRA issue ID extraction"
          type: string
          defaultValue: ${jira_issue}
        - label: JIRA Retry States
          name: retry
          description: "JIRA issue states that Retry the stage e.g,: To Do, In Progress, etc."
          type: string
          defaultValue: To Do, In Progress
        - label: JIRA Success States
          name: success
          description: "JIRA issue States that progress the pipeline, e.g,: In Verificaiton etc."
          type: string
          defaultValue: In Verification
        - label: JIRA Temination States
          name: terminate
          description: "JIRA issue states that terminates the pipeline, e.g,: PR Raised etc."
          type: string
          defaultValue: PR Raised
        - label: JIRA Canceled States
          name: cancel
          description: "JIRA issue states that cancel the pipeline e.g,: Done, etc."
          type: string
          defaultValue: Done
      - label: "JIRA: Create Issue"
        type: addJiraIss
        enabled: true
        description: Custom stage that add an Issue in Jira
        method: POST
        url: https://<DOMAIN>/rest/api/2/issue/
        customHeaders:
         ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
         Authorization: Basic base64{<<USER>>:<<Jira-token>>}
         Content-Type: application/json
        payload: |-
          {
            "fields": {
               "project":
                {
                  "key": "${parameterValues['projectid']}"
                },
                "summary": "${parameterValues['summary']}",
                "description": "${parameterValues['description']}",
                "issuetype": {
                  "name": "${parameterValues['issuetype']}"
                },
                "components": [
                    {
                  "id": "${parameterValues['components']}"
                }
                ],
                "priority": {
                  "name": "${parameterValues['priority']}"
                }
            }
          }
        parameters:
        - label: Project ID ("ENG" or "DOCS")
          name: projectid
          description: Which JIRA project do you want to create an item in?
          type: string
        - label: Issue Type ("Improvement", "Task", "New Feature", or "Bug")
          name: issuetype
          description: issuetype
          type: string
        - label: Priority ("Low", "Medium", or "High")
          name: priority
          description: priority
          type: string
        - label: Components ("10103")
          name: components
          description: component of the project
        - label: Issue Summary
          name: summary
          description: summary
          type: string
        - label: Description
          name: description
          description: description
          type: string
      - label: "JIRA: Comment on Issue"
        type: comJiraIss
        enabled: true
        description: Custom stage that posts a comment in a Jira Issue
        method: POST
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}/comment
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        payload: |-
          {
            "body": "${parameterValues['message']}"
          }
        parameters:
        - label: Issue ID
          name: issue
          description: Issue
          type: string
        - label: Message
          name: message
          description: message
          type: string
      - label: "JIRA: Update Issue"
        type: updJiraIss
        enabled: true
        description: Custom stage that updates an Issue in Jira
        method: PUT
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        payload: |-
          {
            "update": {
                "summary": [
                    {
                        "set": "${parameterValues['summary']}"
                    }
                ],
                "description": [
                    {
                       "set": "${parameterValues['description']}"
                    }
                ]
            }
          }
        parameters:
        - label: Issue ID
          name: issue
          description: Issue
          type: string
        - label: Summary
          name: summary
          description: summary
          type: string
        - label: Description
          name: description
          description: description
      - label: "JIRA: Transition Issue"
        type: transJiraIss
        enabled: true
        description: Custom stage that transitions an Issue in Jira
        method: POST
        url: https://<DOMAIN>/rest/api/latest/issue/${parameterValues['issue']}/transitions
        customHeaders:
          ## Provide the JIRA credentails that are in base64 encoded USER:PASSWORD/TOKEN
          Authorization: Basic base64{<<USER>>:<<Jira-token>>}
          Content-Type: application/json
        payload: |-
          {
            "transition": {
              "id": "${parameterValues['targetStageID']}"
            }
          }
        parameters:
        - label: Issue ID
          name: issue
          description: Issue
          type: string
        - label: Target Stage ID
          name: targetStageID
          description: Target Stage ID (11 is "To Do", 21 is "In Progress", 31 is "In Review", 41 is "Done")
          type: string
    spinnaker:
      extensibility:
        plugins-root-path: /tmp/plugins
        plugins:
          Opsmx.VerificationGatePlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.VisibilityApprovalPlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.TestVerificationGatePlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.PolicyGatePlugin:
            enabled: true
            version: 1.0.1
            config:
          Opsmx.RbacPlugin:
            enabled: true
            version: 1.0.1
            config:
        repositories:
          opsmx-repo:
            id: opsmx-repo
            url: file:///opt/spinnaker/plugins/plugins.json
            #url: https://raw.githubusercontent.com/opsmx/spinnakerPluginRepository/v3.10.0/plugins.json
    

  echo-local.yml: |-
    rest:
      enabled: true
      endpoints:
       -
        wrap: false
        url: http://oes-sapor.opsmx-isd:8085/oes/echo
---
# Source: oes/charts/spinnaker/templates/configmap/halyard-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-halyard-config
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  install.sh: |
    #!/bin/bash

    # Wait for the Hal daemon to be ready
    export DAEMON_ENDPOINT='curl http://isd-spinnaker-halyard:8064/health'
    export HAL_COMMAND="$DAEMON_ENDPOINT"
    until $HAL_COMMAND ; do sleep 10 ; done # end of if not gitops

    # This is performed by post-start script in halyard pod
    # in case gitopsHalyard is enabled
  clean.sh: |
    export HAL_COMMAND='hal --daemon-endpoint http://isd-spinnaker-halyard:8064'
    if $HAL_COMMAND --ready; then
      $HAL_COMMAND deploy clean -q
    fi
  config.sh: |
    # Spinnaker version
    
    $HAL_COMMAND config version edit --version 1.26.6
    

    # Storage
    
    echo spinnakeradmin | $HAL_COMMAND config storage s3 edit \
        --endpoint http://isd-minio:9000 \
        --access-key-id spinnakeradmin \
        --secret-access-key --bucket spinnaker \
        --path-style-access true
    $HAL_COMMAND config storage edit --type s3
    
    
    
    

    # Docker Registry
    $HAL_COMMAND config provider docker-registry enable

    if $HAL_COMMAND config provider docker-registry account get dockerhub; then
      PROVIDER_COMMAND='edit'
    else
      PROVIDER_COMMAND='add'
    fi

    $HAL_COMMAND config provider docker-registry account $PROVIDER_COMMAND dockerhub --address index.docker.io \
       \
      --repositories library/alpine,library/ubuntu,library/centos,library/nginx

    $HAL_COMMAND config provider kubernetes enable

    if $HAL_COMMAND config provider kubernetes account get default; then
      PROVIDER_COMMAND='edit'
    else
      PROVIDER_COMMAND='add'
    fi

    $HAL_COMMAND config provider kubernetes account $PROVIDER_COMMAND default --docker-registries dockerhub \
                --context default --service-account true \
                 \
                --only-spinnaker-managed true \
                 \
                 \
                --omit-namespaces=kube-system,kube-public \
                 \
                 \
                 \
                --provider-version v2
    $HAL_COMMAND config deploy edit --account-name default --type distributed \
                           --location opsmx-isd
    $HAL_COMMAND config deploy ha clouddriver enable
    $HAL_COMMAND config deploy ha echo enable

    # Enable Authentication by default
    $HAL_COMMAND config security authn ldap edit --url ldap://isd-openldap:389 --user-dn-pattern  'cn={0},dc=example,dc=org'
    $HAL_COMMAND config security authn ldap enable

    # Enable Authorization
    $HAL_COMMAND config security authz disable


    # Use Deck to route to Gate
---
# Source: oes/charts/spinnaker/templates/configmap/halyard-init-script.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-halyard-init-script
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  init.sh: |

    echo \"Checking for Gitea services\"
    wait_period=0
    while true
    do
    kubectl get po -n opsmx-isd -o jsonpath='{range .items[*]}{..metadata.name}{"\t"}{..containerStatuses..ready}{"\n"}{end}' > /tmp/inst.status
    GITEA=$(grep gitea-0 /tmp/inst.status |grep -v deck | awk '{print $2}')

    wait_period=$(($wait_period+10))
    if [ "$GITEA" == "true" ];
    then
        echo \"Gitea Pod is ready\"
        break
    else
        if [ $wait_period -gt 1800 ];
        then
            echo \"Script is timed out as the Gitea is not ready in 30 min.......\"
            break
        else
            echo \"Waiting for Gitea to be ready\"
            sleep 1m
        fi
    fi
    done
    rm -rf /tmp/spinnaker/repo.json
    gitea_user=`echo $GITEA_USER | sed 's/ *$//g'`
    gitea_pass=`echo $GITEA_PASS | sed 's/ *$//g'`
    basic_auth=$(echo -n $gitea_user:$gitea_pass |base64)
    DYNAMIC_ACCOUNTS_REPO=http://isd-gitea-http.$SPINNAKER_NAMESPACE:3000/$gitea_user/gitea-standard-repo.git
    GIT_USER=$gitea_user
    GIT_TOKEN=$gitea_pass

    echo "Checking if the local gitea repo exists....."
    curl -k -X GET "http://isd-gitea-http.$SPINNAKER_NAMESPACE:3000/api/v1/users/$gitea_user/repos" >/tmp/spinnaker/repo.json
    checkrepo=$(cat /tmp/spinnaker/repo.json | jq '.[] | select(.name=="gitea-standard-repo")')

        if [ -z "$checkrepo" ]
        then
                echo "Creating a New Local Gitea Repo gitea-standard-repo......."
                curl -k -X POST "http://isd-gitea-http.$SPINNAKER_NAMESPACE:3000/api/v1/user/repos" -H "content-type: application/json" -H "Authorization: Basic $basic_auth" --data '{"name":"'gitea-standard-repo'"}'
                git clone https://github.com/OpsMx/standard-gitops-repo.git -b v4.0.3.1 /tmp/spinnaker/test/standard-gitops-repo/
                git clone http://$gitea_user:$gitea_pass@isd-gitea-http.$SPINNAKER_NAMESPACE:3000/$gitea_user/gitea-standard-repo.git /tmp/spinnaker/test/gitea-standard-repo/
                cp -pr /tmp/spinnaker/test/standard-gitops-repo/* /tmp/spinnaker/test/gitea-standard-repo/
                cd /tmp/spinnaker/test/gitea-standard-repo/
                git status
                git add .
                git config user.email support@opsmx.com
                git config user.name $gitea_user
                git commit -m "cloned standard-gitops-repo content"
                git push
                cd
                rm -rf /tmp/spinnaker/test/gitea-standard-repo
                rm -rf /tmp/spinnaker/test/standard-gitops-repo
                rm -rf /tmp/spinnaker/test
                git clone http://$gitea_user:$gitea_pass@isd-gitea-http.$SPINNAKER_NAMESPACE:3000/$gitea_user/gitea-standard-repo.git /tmp/spinnaker/test/

        else
                echo "Local Repo exits...."
                rm -rf /tmp/spinnaker/test/gitea-standard-repo
                git clone http://$gitea_user:$gitea_pass@isd-gitea-http.$SPINNAKER_NAMESPACE:3000/$gitea_user/gitea-standard-repo.git /tmp/spinnaker/test
        fi
        #override the repotye to gitea in order to support pipelin-promotion
        sed -i  s/repo_type=git/repo_type=gitea/ /tmp/spinnaker/test/pipeline-promotion/pipe-promot-config-cm.yaml
        sed -i  s/git_user=/git_user=${GIT_USER}/ /tmp/spinnaker/test/pipeline-promotion/pipe-promot-config-cm.yaml
        sed -i  s/root_folder=/root_folder=pipeline-promotion/ /tmp/spinnaker/test/pipeline-promotion/pipe-promot-config-cm.yaml
    #!/bin/bash -x
    rm -rf /tmp/spinnaker/.hal
    cp -r /tmp/spinnaker/test// /tmp/spinnaker/.hal
    if [ -d "/tmp/spinnaker/test/pipeline-promotion/" ]
    then
       cp -r /tmp/spinnaker/test/pipeline-promotion /tmp/spinnaker/pipeline-promotion
    fi
    if [ -d "/tmp/spinnaker/test/clusterconfig/" ]
    then
       cp -r /tmp/spinnaker/test/clusterconfig /tmp/spinnaker/clusterconfig
    fi
    ## If BOM file present in gitops repo consider bom file and replace images in the service-setting folder to the respective services
    if [ -r "/tmp/spinnaker/test/bom" ]
    then
      cp -r /tmp/spinnaker/test/bom /tmp/spinnaker/bom
      rm -rf /tmp/spinnaker/.hal/bom
      ## Updated the halyard config version
      crthalversion=$(yq e '.deploymentConfigurations.[].version' /tmp/spinnaker/.hal/config)
      halversion=$(yq e '.version' /tmp/spinnaker/bom)
      echo "INFO: Updating the halyard version from VERSION $crthalversion to VERSION $halversion"
      yq -i e '.deploymentConfigurations.[].version = "'$halversion'"' /tmp/spinnaker/.hal/config
      ## Read service  as asingle line comma saperated
      echo "INFO: Updating the spinnaker images of service-settings folder using bom file in gitops"
      halservices=$(yq e '(.services | keys)[]' /tmp/spinnaker/bom | xargs | sed -e 's/ /,/g')
      IFS=","
      for i in $halservices
      do
        svcimg=$(yq e '.services.'$i'.image' /tmp/spinnaker/bom)
        svcn=$(find /tmp/spinnaker/.hal/default/service-settings/ -name "$i"* | awk -F"/" '{print $NF}' | xargs | sed -e 's/ /,/g')
        if [[ "$svcn" != "" ]];
        then
          IFS=","
          for svcfile in $svcn
          do
            yq -i e '.artifactId = "'$svcimg'"' /tmp/spinnaker/.hal/default/service-settings/$svcfile
          done
        else
          echo "WARNING: Service file $i is not located in default/service-settings/ to override the artifact image from bom"
        fi
      done
    else
      echo "WARNING: Not specified bom in gitops repo overidden images will be  taken from default/service-settings"
    fi
    rm -rf /tmp/spinnaker/test
    DYNAMIC_ACCOUNTS_REPO=`echo $DYNAMIC_ACCOUNTS_REPO | sed 's/ *$//g'`
    sed -i  s/SPINNAKER_NAMESPACE/${SPINNAKER_NAMESPACE}/ /tmp/spinnaker/.hal/config
    sed -i  s/RELEASE_NAME/isd/g /tmp/spinnaker/.hal/config
    BRANCH=master
    sed -i s/BRANCH/${BRANCH}/ /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    KEY=Q7udUkHPuA3VnNlOtksSgQ
    sed -i s/KEY/${KEY}/ /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  s/GIT_USER/${GIT_USER}/g /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  s/GIT_TOKEN/${GIT_TOKEN}/g /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  's|DYNAMIC_ACCOUNTS_REPO|'"${DYNAMIC_ACCOUNTS_REPO}"'|' /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  s%DYN_ACCNT_CONFG_PATH%/%g /tmp/spinnaker/.hal/default/profiles/spinnakerconfig.yml
    sed -i  s/RELEASE_NAME/isd/g /tmp/spinnaker/.hal/default/profiles/rosco-local.yml
    sed -i  s/RELEASE_NAME/isd/g /tmp/spinnaker/.hal/default/service-settings/redis.yml
    yq -i e '.deploymentConfigurations.[].security.authz.enabled = "false"' /tmp/spinnaker/.hal/config
    if [ -f /tmp/spinnaker/.hal/default/profiles/fiat-local.yml ]; then
    sed -i  s/RELEASE_NAME/isd/g /tmp/spinnaker/.hal/default/profiles/fiat-local.yml
    fi
    sed -i  s/SPINNAKER_NAMESPACE/${SPINNAKER_NAMESPACE}/ /tmp/spinnaker/.hal/default/profiles/orca-local.yml
    printf 'server.address: 0.0.0.0\n' > /tmp/config/halyard-local.yml
    if [ -f /tmp/spinnaker/.hal/halyard.yaml ]; then
    cp /tmp/spinnaker/.hal/halyard.yaml /tmp/config
    fi
    yq -i e '.deploymentConfigurations.[].security.authn.saml.enabled = "false"' /tmp/spinnaker/.hal/config
    rm -rf /tmp/spinnaker/.hal/default/profiles/orca-overrides.yml
    rm -rf /tmp/spinnaker/.hal/default/profiles/fiat-overrides.yml
    rm -rf /tmp/spinnaker/.hal/default/profiles/gate-overrides.yml
    rm -rf /tmp/spinnaker/.hal/default/profiles/spinnaker.yml  # git or stash  # Enabled  # End of S3

    # The decrypt token extract
    kubectl get secret bootstrap -o jsonpath='{.data.bootstrap\.yml}' -n ${SPINNAKER_NAMESPACE} | base64 -d > /tmp/decryptkry.txt
    decrypt_key=$(yq e '.jasypt.encryptor.password' /tmp/decryptkry.txt)

    # pipeline promotion configuration setup
    #
    ls -lart /home/spinnaker/java-lib/
    if [ -d "/tmp/spinnaker/pipeline-promotion/" ]
    then
      if [[ $decrypt_key != "" ]];
      then
        for filename in /tmp/spinnaker/pipeline-promotion/*; do
          java -cp "Decryptor.jar:/home/spinnaker/java-lib/*" Decryptor $decrypt_key "$filename"
        done
      mkdir /tmp/spinnaker/pipeline-decrypted/
      mv /tmp/spinnaker/pipeline-promotion/*decrypted.yaml /tmp/spinnaker/pipeline-decrypted/
      kubectl apply -f /tmp/spinnaker/pipeline-promotion/pipe-promot-config-cm.yaml -n ${SPINNAKER_NAMESPACE}
      kubectl apply -f /tmp/spinnaker/pipeline-decrypted/ -n ${SPINNAKER_NAMESPACE}
     fi
    fi
    # decrypt json files for integrations

    ls /tmp/spinnaker/.hal -1 | grep .enc > /tmp/jsonfiles
    if [ -s /tmp/jsonfiles ];
    then
      if [[ $decrypt_key != "" ]];
      then
        echo "Data is available in jsonfiles"
        while read -r line;
        do
         echo "$line" ;
         java -cp "Decryptor.jar:/home/spinnaker/java-lib/*" Decryptor $decrypt_key "/tmp/spinnaker/.hal/$line" json
        done < /tmp/jsonfiles
        rm -rf /tmp/spinnaker/.hal/*.enc
        cp /tmp/spinnaker/.hal/decrypted/* /tmp/spinnaker/.hal/
        rm -rf /tmp/spinnaker/.hal/decrypted/
      fi
    fi
    ############# Auto Configuration for Custom Stages in ORCA #############

    if [ -d "/tmp/spinnaker/clusterconfig/" ]
    then
      if [[ $decrypt_key != "" ]];
      then
        for filename in /tmp/spinnaker/clusterconfig/*; do
          java -cp "Decryptor.jar:/home/spinnaker/java-lib/*" Decryptor $decrypt_key "$filename"
        done
      mkdir /tmp/spinnaker/clusterconfig-decrypted/
      mv /tmp/spinnaker/clusterconfig/*decrypted.yaml /tmp/spinnaker/clusterconfig-decrypted/
      kubectl apply -f /tmp/spinnaker/clusterconfig-decrypted/ -n ${SPINNAKER_NAMESPACE}
        if [ -r "/tmp/spinnaker/clusterconfig/servicenow-secret.yaml" ]
        then
           #### Extracting the Service NOW information from secret ####
           SERVICENOW_USER=$(kubectl get secret servicenow-secret -o jsonpath='{.data.SERVICENOW_USERNAME}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           SERVICENOW_DNS=$(kubectl get secret servicenow-secret -o jsonpath='{.data.SERVICENOW_URL}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           SERVICENOW_PASSWD=$(kubectl get secret servicenow-secret -o jsonpath='{.data.SERVICENOW_PASSWORD}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           SERVICENOW_BASE64_USR_PASSWD=$(echo -n "$SERVICENOW_USER:$SERVICENOW_PASSWD" | base64)
           sed -i s%SERVICENOW_URL%${SERVICENOW_DNS}%g /tmp/spinnaker/.hal/default/profiles/orca-local.yml
           sed -i  s/SERVICENOW_BASE64_USR_PASSWD/${SERVICENOW_BASE64_USR_PASSWD}/g /tmp/spinnaker/.hal/default/profiles/orca-local.yml
        else
           echo "Not able to find the ServiceNow secret file"
        fi
        if [ -r "/tmp/spinnaker/clusterconfig/jira-secret.yaml" ]
        then
           #### Extracting the JIRA information from secret ####
           JIRA_USER=$(kubectl get secret jira-secret -o jsonpath='{.data.JIRA_USERNAME}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           JIRA_DNS=$(kubectl get secret jira-secret -o jsonpath='{.data.JIRA_URL}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           JIRA_TOKN=$(kubectl get secret jira-secret -o jsonpath='{.data.JIRA_TOKEN}' -n ${SPINNAKER_NAMESPACE} | base64 -d)
           JIRA_BASE64_USR_PASSWD=$(echo -n "$JIRA_USER:$JIRA_TOKN" | base64)
           sed -i s%JIRA_URL%${JIRA_DNS}%g /tmp/spinnaker/.hal/default/profiles/orca-local.yml
           sed -i  s/JIRA_BASE64_USR_PASSWD/${JIRA_BASE64_USR_PASSWD}/g /tmp/spinnaker/.hal/default/profiles/orca-local.yml
        else
           echo "Not able to find the ServiceNow secret file"
        fi
     fi
    fi
---
# Source: oes/charts/spinnaker/templates/configmap/halyard-overrideurl.yaml
apiVersion: v1
data:
  call_overrides.sh: |
    echo $SPINNAKER_NAMESPACE
    sh /tmp/autoconfig/config_overrideurl.sh spin-gate-overrideurl-gitops
    sh /tmp/autoconfig/config_overrideurl.sh spin-deck-overrideurl-gitops
  config_overrideurl.sh: |
    #!/bin/bash -x

    if [ $# -gt 1 ]
    then
       echo "Invalid input, only one argument expected"
       exit
    fi

    COMPONENT=$1
    EXTERNAL_IP_CHECK_DELAY=1

    check_for_loadBalancer()
    {
        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        iter=0
        lapsedTime=0
        while [ $iter -lt 100 ]
        do
          ENDPOINT_IP=$(kubectl get svc $1 -o jsonpath="{.status.loadBalancer.ingress[].ip}")
          if [ ! -z "$ENDPOINT_IP" ];
          then
            echo "Found LoadBalancer IP for" $1
            break
          fi
          sleep 5
          lapsedTime=`expr $lapsedTime + 5`
          if [ $lapsedTime -gt $EXTERNAL_IP_CHECK_DELAY ];
          then
    	echo "Time Lapsed" $lapsedTime
            echo "Timeout! Fetching nodeport IP alternatively"
            break
          fi
          echo "Time Lapsed" $lapsedTime
          iter=`expr $iter + 1`
        done
    }

    case "$COMPONENT" in
      spin-gate)
        ENDPOINT_IP=""
        PORT=8084

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-gate-lb

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort IP and replace in spinnaker.yaml
          #ENDPOINT_IP=$(kubectl get ep kubernetes -n default -o jsonpath="{.subsets[].addresses[].ip}")
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-gate-np -o jsonpath="{.spec.ports[].nodePort}")
          sed -i  s/OVERRIDE_API_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        else
          ## Substitute spin-gate external IP in hal config
          sed -i  s/OVERRIDE_API_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        fi
        ;;

      spin-deck)
        ENDPOINT_IP=""
        PORT=9000

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-deck-lb

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort & nodeport and replace in app-config.js
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-deck-np -o jsonpath="{.spec.ports[].nodePort}")
          sed -i  s/OVERRIDE_DECK_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        else
          ## Substitute spin-deck external IP in hal config
          sed -i  s/OVERRIDE_DECK_URL/$ENDPOINT_IP:$PORT/g /tmp/spinnaker/.hal/config
        fi
        ;;
      override-gate-url)
        ENDPOINT_IP=""
        PORT=8084

        export DAEMON_ENDPOINT=http://isd-spinnaker-halyard:8064
        export HAL_COMMAND="hal --daemon-endpoint $DAEMON_ENDPOINT"

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-gate-np

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort IP and replace in spinnaker.yaml
          #ENDPOINT_IP=$(kubectl get ep kubernetes -n default -o jsonpath="{.subsets[].addresses[].ip}")
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-gate-np -o jsonpath="{.spec.ports[].nodePort}")
          $HAL_COMMAND config security api edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        else
          ## Run hal config edit command to override gate url
          $HAL_COMMAND config security api edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        fi
        ;;
      override-deck-url)
        ENDPOINT_IP=""
        PORT=9000

        export DAEMON_ENDPOINT=http://isd-spinnaker-halyard:8064
        export HAL_COMMAND="hal --daemon-endpoint $DAEMON_ENDPOINT"

        ## Wait for $EXTERNAL_IP_CHECK_DELAY till K8s assins a load Balancer IP to oes-gate
        check_for_loadBalancer spin-deck-np

        ## If external IP is not available
        if [ -z "$ENDPOINT_IP" ]; then
          ## Fetch the nodePort & nodeport and replace in app-config.js
          ENDPOINT_IP=$NODE_IP
          PORT=$(kubectl get svc spin-deck-np -o jsonpath="{.spec.ports[].nodePort}")
          $HAL_COMMAND config security ui edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        else
          ## Run hal config edit command to override deck url
          $HAL_COMMAND config security ui edit --no-validate --override-base-url http://$ENDPOINT_IP:$PORT
        fi
        ;;
      spin-gate-overrideurl-gitops)
        ## Configured ingress host url as override url
          echo "Substituting gate url"
          sed -i 's,PROTOCOL,http,g' /tmp/spinnaker/.hal/config
          sed -i 's,OVERRIDE_API_URL,oes.example.ops.com/gate,g' /tmp/spinnaker/.hal/config
        ;;
      spin-deck-overrideurl-gitops)
        ## Configured ingress host url as override url
          echo "Substituting deck url"
          sed -i 's,OVERRIDE_DECK_URL,oes.example.ops.com/deck,g' /tmp/spinnaker/.hal/config
        ;;
      *)
        echo  COMP=$COMPONENT
        echo "Invalid input:$COMPONENT"
        ;;
    esac

kind: ConfigMap
metadata:
  name: isd-spinnaker-halyard-overrideurl
---
# Source: oes/charts/spinnaker/templates/configmap/secret-decoder.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-spin-secret-decoder
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  run.sh: |-
    #!/bin/bash
    echo "##########Replacing Secret#########"
    grep -ir encrypted: /tmp/spinnaker/.hal | sort -t: -u -k1,1 |cut -d : -f1 > tmp.list
    while IFS= read -r file; do
    grep encrypted: $file > tmp1.list
    while read line ; do
    echo ${line#*encrypted:} ;
    done < tmp1.list > secret-strings.list
    while read secret ; do
    secretName=${secret%%:*}
    echo "---------$secretName---"
    keyName=${secret#*:}
    keyName=${keyName%%\"*}
    keyName=${keyName%% *}
    echo "----------$keyName--"
    #echo "secret Name= $secretName and key is = $keyName"
    #kubectl get secret -o jis
    #echo kubectl --kubeconfig /home/srini/ibm-cloud/staging/ibmstaging.config -n ninja-srini get secret $secretName -o json  jq -r ".data.$keyName"
    jqParam=".data.\"$keyName\""
    value=$(kubectl get secret $secretName -o json | jq -r $jqParam | base64 -d)
    value=$(echo $value | sed -e 's`[][\\/.*^$]`\\&`g')
    #echo "-----------$value---"
    #echo "secret Name= $secretName and key is = $keyName and value is $value"
    sed -i s/encrypted:$secretName:$keyName/$value/g $file
    done < secret-strings.list
    done < tmp.list

    echo "########### Replacing Kubeconfigs ############"
    grep encryptedFile /tmp/spinnaker/.hal/config > tmp.list
    while read line ; do
    echo ${line#*encryptedFile:} ;
    done < tmp.list  > secret-files.list

    while read secret ; do
    secretName=${secret%%:*}
    keyName=${secret#*:}
    keyName=${keyName%%\"*}
    keyName=${keyName%% *}
    echo "secret Name= $secretName and key is = $keyName"
    jqParam=".data.\"$keyName\""
    mkdir -p /tmp/spinnaker/kubeconfigdir
    kubectl get secret $secretName -o json | jq -r $jqParam | base64 -d > /tmp/spinnaker/kubeconfigdir/$keyName
    #echo "secret Name= $secretName and key is = $keyName and value is in $keyName"
    old_value="encryptedFile:$secretName:$keyName"
    new_value="/home/spinnaker/kubeconfigdir/$keyName"
    #echo $old_value
    #echo $new_value
    sed -i "s/${old_value}/$(echo $new_value | sed 's_/_\\/_g')/g" /tmp/spinnaker/.hal/config
    done < secret-files.list
    rm -rf secret-files.list secret-strings.list tmp.list
---
# Source: oes/charts/spinnaker/templates/configmap/service-settings.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-service-settings
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"

data:
  clouddriver-caching.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver-ro-deck.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver-ro.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver-rw.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  clouddriver.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-clouddriver:8.0.4-1'
  deck.yml: |-
    artifactId: quay.io/opsmxpublic/ubi8-oes-deck:3.5.1
    env:
      API_HOST: http://spin-gate:8084
  echo-scheduler.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-echo:2.17.1'
  echo-worker.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-echo:2.17.1'
  echo.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-echo:2.17.1'
  fiat.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-fiat:1.16.0'
  front50.yml: 'artifactId: quay.io/opsmxpublic/ubi8-oes-front50:0.27.1-opa'
  gate.yml: |-
    artifactId: quay.io/opsmxpublic/ubi8-oes-spin-gate:1.22.1
    healthEndpoint: /health
    kubernetes:
      useExecHealthCheck: false
  igor.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-igor:1.16.0'
  kayenta.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-kayenta:0.21.0'
  orca.yml: 'artifactId: quay.io/opsmxpublic/ubi8-oes-orca:2.20.4'
  redis.yml: |-
    overrideBaseUrl: redis://<EXTERNAL-REDIS-HOST-NAME>:6379
    skipLifeCycleManagement: true
  rosco.yml: 'artifactId: quay.io/opsmxpublic/ubi8-spin-rosco:0.25.0'
---
# Source: oes/charts/spinnaker/templates/configmap/spin-pipeline-import.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-spinnaker-spin-pipeline-import
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
data:
  spin-pipeline-import.sh: |-
    #!/bin/bash
    echo "Waiting for all Spinnaker Services to come-up"
    wait_period=0
    while true
    do
    kubectl get po -n opsmx-isd -o jsonpath='{range .items[*]}{..metadata.name}{"\t"}{..containerStatuses..ready}{"\n"}{end}' > /tmp/inst.status
    ## NON-HA
    CLOUDDRIVER=$(grep spin-clouddriver /tmp/inst.status |grep -v deck | awk '{print $2}')
    ECHO=$(grep spin-echo /tmp/inst.status | awk '{print $2}')
    ## HA
    CLOUDRO=$(grep spin-clouddriver-ro /tmp/inst.status |grep -v deck | awk '{print $2}')
    CLOUDRODECK=$(grep spin-clouddriver-ro-deck /tmp/inst.status | awk '{print $2}')
    CLOUDRW=$(grep spin-clouddriver-rw /tmp/inst.status | awk '{print $2}')
    CLOUDCACHING=$(grep spin-clouddriver-caching /tmp/inst.status | awk '{print $2}')
    DECK=$(grep spin-deck /tmp/inst.status | awk '{print $2}')
    ECHOWORKER=$(grep spin-echo-worker /tmp/inst.status | awk '{print $2}')
    ECHOSCHEDULER=$(grep spin-echo-scheduler  /tmp/inst.status | awk '{print $2}')
    FRONT=$(grep spin-front /tmp/inst.status  | awk '{print $2}')
    #GATE=$(grep spin-gate /tmp/inst.status | awk '{print $2}')
    IGOR=$(grep spin-igor /tmp/inst.status | awk '{print $2}')
    ORCA=$(grep spin-orca /tmp/inst.status | awk '{print $2}')
    FIAT=$(grep spin-fiat /tmp/inst.status | awk '{print $2}')
    #ROSCO=$(grep spin-rosco /tmp/inst.status | awk '{print $2}')
    ## AUTOPILOT
    SAPORGATE=$(grep sapor-gate /tmp/inst.status | awk '{print $2}')
    OESGATE=$(grep oes-gate /tmp/inst.status | awk '{print $2}')
    wait_period=$(($wait_period+10))
    READYBASIC=$( [ "$DECK" == "true" ] && [ "$CLOUDCACHING" == "true" ] && [ "$CLOUDRO" == "true" ] && [ "$CLOUDRW" == "true" ] && [ "$CLOUDRODECK" == "true" ] && [ "$FRONT" == "true" ] && [ "$ORCA" == "true" ] && [ "$ECHOWORKER" == "true" ] && [ "$ECHOSCHEDULER" == "true" ] && [ "$SAPORGATE" == "true" ] && [ "$OESGATE" == "true" ];  echo $(($? == 0)) )
    READY=$READYBASIC
    if [ $READY == 1 ];
    then
        echo "Spinnaker and OES is Installed and ready"
        mkdir -p /tmp/config/git/
        git -c http.sslVerify=false clone https://github.com/OpsMx/sample-pipelines.git /tmp/config/git/
        if [[ $? != 0 ]]; then
        echo "ERROR: Failed while cloning the repo https://github.com/OpsMx/sample-pipelines.git"
          exit 1
        fi
        echo "processing.........."
        sleep 100
        cd /tmp/config/git
        cp -p /tmp/config/spin/config .
        ### remove commected line in file
        grep -v "#" create-app.sh > removecomment.sh
        sed 's/$/ --config config/' removecomment.sh > create-app1.sh
        #### Loop begins to save the json if fails it tries for 3 times
        INPUT=$(sed -n '$=' create-app1.sh)
        for i in $(seq 1 $INPUT); do
        command=$(sed -n "$i"p create-app1.sh);
        $command > /dev/null 2>&1
        if [[ $? != 0 ]]; then
          n=0
          until [ "$n" -ge 3 ]
          do
           echo Retrying.....
           $command > /dev/null 2>&1
            if [[ $? != 0 ]]; then
              echo "ERROR: Failed to save the Application/Pipeline using the spincli. Please check the spincli configuration in isd-spinnaker-spin-config  secret or check the pipelinejson"
              echo "$command"
              #exit 1
              if [[ "$i" == 3 ]]; then
              echo "ERROR: Failed to save the Application/Pipeline using the spincli. Please check the spincli configuration in isd-spinnaker-spin-config  secret or check the pipelinejson"
              echo "$command"
              exit 1
              fi
            else
              echo "$command"
              echo "Saved successfully"
            fi
           n=$((n+1))
           sleep 5
         done
        else
          echo "$command"
          echo "Saved successfully"
        fi
        done
        break
    else
        if [ $wait_period -gt 1800 ];
        then
            echo "Script is timed out as the Spinnaker is not ready in 30 min......."
            break
        else
            echo "Waiting for Spinnaker services to be ready"
            sleep 1m
        fi
    fi
    done
---
# Source: oes/templates/clouddriver-sidecar/k8sconfig-sync.yaml
apiVersion: v1
data:
  k8config-sync.sh: |
    #!/bin/bash
    export GIT_CLONE_PARAM=$(cat /tmp/secret/gitcloneparam)
    export GIT_URL=$(cat /tmp/secret/dynamicaccountsgituri)
    export DYNAMIC_ACCOUNTS_REPO=$(cat /tmp/secret/dynamicAccRepository)
    rm -rf $DYNAMIC_ACCOUNTS_REPO
    mkdir -p /opsmx
    echo " ####### Cloning the Dynamic Account Repo #################"
    git clone -c http.sslVerify=false $GIT_CLONE_PARAM
    #cd $DYNAMIC_ACCOUNTS_REPO/
    cat $DYNAMIC_ACCOUNTS_REPO///clouddriver-local.yml |grep -i opsmx |awk '{print $2}' |tr -d '"' | awk 'BEGIN{FS="/opsmx/"}{print $2}' > /opsmx/config_files.txt
    for config in $(cat /opsmx/config_files.txt)
    do
    kubectl get secrets $config -o=jsonpath='{.data.*}'|base64 -d > /opsmx/$config
    done
kind: ConfigMap
metadata:
  name: k8config-sync
---
# Source: oes/templates/configmaps/datasource-creation.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: isd-oes-datasource-creation
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
data:
  datasource-api.sh: |-
    #!/bin/bash
    set -x
    echo \"Waiting for all Spinnaker and OES Services to come-up\"
    wait_period=0
    while true
    do
    kubectl get po -n opsmx-isd -o jsonpath='{range .items[*]}{..metadata.name}{"\t"}{..containerStatuses..ready}{"\n"}{end}' > /tmp/inst.status
    ## NON-HA
    CLOUDDRIVER=$(grep spin-clouddriver /tmp/inst.status |grep -v deck | awk '{print $2}')
    ECHO=$(grep spin-echo /tmp/inst.status | awk '{print $2}')
    ## HA
    CLOUDRO=$(grep spin-clouddriver-ro /tmp/inst.status |grep -v deck | awk '{print $2}')
    CLOUDRODECK=$(grep spin-clouddriver-ro-deck /tmp/inst.status | awk '{print $2}')
    CLOUDRW=$(grep spin-clouddriver-rw /tmp/inst.status | awk '{print $2}')
    CLOUDCACHING=$(grep spin-clouddriver-caching /tmp/inst.status | awk '{print $2}')
    DECK=$(grep spin-deck /tmp/inst.status | awk '{print $2}')
    ECHOWORKER=$(grep spin-echo-worker /tmp/inst.status | awk '{print $2}')
    ECHOSCHEDULER=$(grep spin-echo-scheduler  /tmp/inst.status | awk '{print $2}')
    FRONT=$(grep spin-front /tmp/inst.status  | awk '{print $2}')
    #GATE=$(grep spin-gate /tmp/inst.status | awk '{print $2}')
    IGOR=$(grep spin-igor /tmp/inst.status | awk '{print $2}')
    ORCA=$(grep spin-orca /tmp/inst.status | awk '{print $2}')
    FIAT=$(grep spin-fiat /tmp/inst.status | awk '{print $2}')
    #ROSCO=$(grep spin-rosco /tmp/inst.status | awk '{print $2}')
    ## AUTOPILOT
    SAPOR=$(grep oes-sapor /tmp/inst.status | awk '{print $2}')
    PLATFORM=$(grep oes-platform /tmp/inst.status | awk '{print $2}')
    AUTOPILOT=$(grep oes-autopilot /tmp/inst.status | awk '{print $2}')


    wait_period=$(($wait_period+10))
    READYBASIC=$([ "$DECK" == "true" ] && [ "$CLOUDCACHING" == "true" ] && [ "$CLOUDRO" == "true" ] && [ "$CLOUDRW" == "true" ] && [ "$CLOUDRODECK" == "true" ] && [ "$FRONT" == "true" ] && [ "$ORCA" == "true" ]  && [ "$ECHOWORKER" == "true" ] && [ "$ECHOSCHEDULER" == "true" ] && [ "$SAPOR" == "true" ] && [ "$PLATFORM" == "true" ] && [ "$AUTOPILOT" == "true" ] && [ "$IGOR" == "true" ]; echo $(($? == 0)) )
    READY=$READYBASIC


    if [ $READY == 1 ] ;
        then
            echo \"Spinnaker and OES services are Up and Ready..\"
            sleep 5
            curl -X POST "http://sapor-gate:8084/login?username=admin&password=saporadmin&submit=Login"
            curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "OPA", "name": "OPA", "configurationFields": {"endPoint": "http://opa:8181"}}'   http://oes-platform:8095/platformservice/v2/datasources
            curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "AUTOPILOT", "name": "Autopilot", "configurationFields": {"username": "admin"} }'   http://oes-platform:8095/platformservice/v2/datasources
            #curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "ELASTICSEARCH", "name": "elastic-default", "configurationFields": {"endPoint": "https://newoeselastic.opsmx.com", "username": "opsmxuser", "password": "OpsMx@123", "kibanaEndPoint": "https://newoeskibana.opsmx.com", "kibanaPassword": "OpsMx@123", "kibanaUsername": "opsmxuser" }}'   http://oes-platform:8095/platformservice/v2/datasources
            #curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST  --data '{"datasourceType": "PROMETHEUS", "name": "prometheus-default", "configurationFields": {"endPoint": "http://prometheus:9090"} }'   http://oes-platform:8095/platformservice/v2/datasources
            echo "Creating OPA Policies"
            curl --header 'Content-Type: application/json' --header 'x-spinnaker-user: admin' --request POST http://oes-sapor:8085/oes/v2/policy/save --data '{"name":"AppMustHaveRbac","type":"Static","accountType":"OPA","accountName":"OPA","description":"Enforce Application in Spinnakr to have Roles defined.","status":"INACTIVE","rego":"# Static Policy to enforce assigning roles when creating an application\n# Once enforced, it is not possible to create an application that is visible to all\n# by mistake\n\npackage opsmx.spinnaker.authorization\n\ndeny[\"Permissions must be specified\"] {\n   not(appHasWritePermissions)\n   input.new.job[_].type==\"updateApp\"\n }{\n   not(appHasWritePermissions)\n   input.new.job[_].type==\"createApp\"\n}\nappHasWritePermissions {\n  count(input.new.job[0].application.permissions.WRITE) > 0\n}"}'
            curl --header 'Content-Type: application/json' --header 'x-spinnaker-user: admin' --request POST http://oes-sapor:8085/oes/v2/policy/save --data '{"name":"StageLevelRBAC","type":"Static","accountType":"OPA","accountName":"OPA","description":"Restrict a group of users from modifying certain stages","status":"INACTIVE","rego":"package opsmx.spinnaker.stage_rbac\nimport future.keywords.in\n\n# The permissions json is to be defined to restrict some users from making changes to a specific stage\n# in the pipeline. The parameters for each stage are \"name\" of the pipeline, \"type\" of the pipeline and \"grant\" privilege\n# which can hold 2 values: allow and deny\npermissions = {\n  \"role_grants\": {\n    \"demo-users\": [\n      {\n        \"name\": \"Build\",\n        \"type\": \"jenkins\",\n        \"grant\": \"deny\"\n      },\n      { \n        \"name\": \"Deploy \",\n        \"type\": \"deployManifest\",\n        \"grant\": \"deny\"\n      },\n      { \n        \"name\": \"Manual Judgment \",\n        \"type\": \"manualJudgment\",\n        \"grant\": \"deny\"\n      },\n      {\n        \"name\": \"Wait\",\n        \"type\": \"wait\",\n        \"grant\": \"deny\"\n      }\n    ]\n  }\n}\n\n\n# modified_stages is the set of stages which carry \"modified\", \"new\" and \"deleted\" stageStatus. \n# only the stages with stageStatus = unmodified are excluded.\n\nmodified_stages = [input.pipeline.stages[idx] | input.pipeline.stages[idx].stageStatus != \"unmodified\"]\n#modified_stage_name = [input.pipeline.stages[idx].name | input.pipeline.stages[idx].stageStatus != \"unmodified\"]\n\n\n# The operation is denied if there is no modified/new/deleted stage in the pipeline\ndeny[\"No modified stages found\"]{\n  count(input.pipeline.stages) > 0         # only because we still have fron50 plugin; this will be removed in 3.12.x release\n  count(modified_stages) <= 0\n}\n\n# If there are modifications in the pipeline, the privileges of users to operate on a set of stages\n# is evaluated on the basis of\n\n# 1. If the user is admin, allow the user to do anything\n# 2. If the permissions json does not carry definition of privileges for any group assigned to the user,\n# then the user is to be allowed to make any changes\n# 3. If there are no denials in the permissions definition, then the user is to be allowed to make any changes\n# 4. If there are denials for some stages in any of the role assigned to user, then\n#\t4a. Checking if the same stages is allowed for any other role assigned to user\n#   4b. If a respective allow privilege is available, then allow.\n#   4c. If not then deny\n# 5. If there are any denials w.r.t. modified stages, simply deny the user from saving.\n# Rule 4 and 5 are contradicting, one of them is to be enabled. Comment line 92-100 to disable rule 4.\n\ndeny[msg]{\n  #not user_is_admin\n  \n  some i\n  role_def = permissions.role_grants[i]\n  role_def_flag = i in input.pipeline.user.groups\n  role_def_flag == true\n  \n  denial_set = user_is_denied\n  denial_size = count(denial_set) \n  to_number(denial_size) > 0\n\n# Comment rest of the statements in this rule if rule 4 is to be enabled\n  acceptance_set = user_is_allowed\n\n  some j\n  accepted_stages = [acceptance_set[j].name | acceptance_set[j].grant == \"allow\"]\n  \n  some k\n  denied_stages = [denial_set[k].name | denial_set[k].grant == \"deny\"; not denial_set[k].name in accepted_stages]\n  denial_size_after_acceptance = count(denied_stages)\n  denial_size_after_acceptance > 0\n  \n  denial_stage_msg = concat(\",\" , denied_stages)\n  msg = sprintf(\"Denied for stages: %v\", [denial_stage_msg])\n}\n\n\n# Check if user is admin\n#user_is_admin {\n # \"admin\" in input.pipeline.user.groups\n#}\n\n# Obtain list of denied and allowed stages for the groups assigned to user\nmake_grant_decision{  \n  some grant_idx\n  user_is_denied[grant_idx]\n\n  some grant_idx2\n  user_is_allowed[grant_idx2]\n}\n\nuser_is_denied[grant_idx] {\n  some stage in modified_stages\n  some role in input.pipeline.user.groups\n  some grant_idx in permissions.role_grants[role]\n  \n  grant_idx.name == stage.name\n  grant_idx.type == stage.type\n  grant_idx.grant == \"deny\" \n}\n\nuser_is_allowed[grant_idx2] {\n  some stage in modified_stages\n  some role in input.pipeline.user.groups\n  some grant_idx2 in permissions.role_grants[role]\n  \n  grant_idx2.name == stage.name\n  grant_idx2.type == stage.type\n  grant_idx2.grant == \"allow\" \n}"}'
            curl --header 'Content-Type: application/json' --header 'x-spinnaker-user: admin' --request POST http://oes-sapor:8085/oes/v2/policy/save --data '{"name":"BlackOutWindow","type":"Runtime","accountType":"OPA","accountName":"OPA","description":"Policy to Prevent deployment during a specified date/time range.","status":"INACTIVE","rego":"# Sample Runtime policy\n  # This policy blocks deployments in the blackout window period\n  \n  package opsmx.blackoutwindow\n  \n  deny[\"No deploys between 25th - 31st Dec 2020\"] {\n    [year, month, day] := time.date([time.now_ns(), \"America/Los_Angeles\"])\n    year == 2020\n    month == 12\n    day >= 25\n    day <= 31\n  }"}'

            STORAGE_TYPE=gitea
            GITEA_USERNAME=opsmx
            GITEA_PASSWORD=opsmxadmin123
            USERNAME=admin
            PASSWORD=saporadmin
            response=$(curl -s http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker)
            name=$(echo $response | jq '.[].name')
            if [ -z "$name" ];
            then
              if [[ "$STORAGE_TYPE"  ==  "gitea" ]];
              then

              curl -X POST -H "Content-Type: application/json"  -k -d '{"name":"'"$GITEA_USERNAME"'"}' -u $GITEA_USERNAME:$GITEA_PASSWORD http://isd-gitea-http.opsmx-isd:3000/api/v1/users/$GITEA_USERNAME/tokens >token.json
              TOKEN=$(cat token.json | jq '.sha1' -r)

              response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v6/datasource --data '{"datasourceType": "GITHUB", "name": "gitops", "spinEnabled": "false", "configurationFields": {"token": "'$TOKEN'", "username": "", "hostUrl": "http://isd-gitea-http:3000", "url": "http://isd-gitea-http:3000/api/v1/users/opsmx" } }')

              id=$(echo $response | jq '.id')
              curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v4/spinnaker --data '{"name":"preview-saas","url":"http://sapor-gate:8084","authenticationType":"LDAP","externalAccountFlag":true,"pipelinePromotionFlag":true,"syncAccountFlag":false,"externalAccountConfiguration":{"accountId": "'"${id}"'","accountName":"gitops","provider":"GITHUB","config":{"bucketName":"","region":"","endPoint":"http://isd-gitea-http:3000/'$GITEA_USERNAME'/gitea-standard-repo.git","sourcePath":""}},"pipelinePromotionConfiguration":{"accountId": "'"${id}"'","accountName":"gitops","provider":"GITHUB","config":{"bucketName":"","region":"","endPoint":"http://isd-gitea-http:3000/'$GITEA_USERNAME'/gitea-standard-repo.git","sourcePath":""}},"password":"'"${PASSWORD}"'","userName":"'"${USERNAME}"'"}'

              sleep 5
              kubectl delete po isd-spinnaker-halyard-0 -n opsmx-isd
              #curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v4/spinnaker --data '{"name":"preview-saas","url":"http://sapor-gate:8084","authenticationType":"LDAP","externalAccountFlag":true,"pipelinePromotionFlag":false,"syncAccountFlag":false,"externalAccountConfiguration":{"accountId": "'"${id}"'","accountName":"gitops","provider":"GITHUB","config":{"bucketName":"","region":"","endPoint":"http://isd-gitea-http:3000/'$GITEA_USERNAME'/gitea-standard-repo.git","sourcePath":""}},"pipelinePromotionConfiguration":null,"password":"'"${PASSWORD}"'","userName":"'"${USERNAME}"'"}'
                 break
              fi
            fi

            STORAGE_TYPE=git
            BASEURL_HOST=github.com
            USERNAME=admin
            PASSWORD=saporadmin
            TOKEN=$(echo -n "$USERNAME":"$PASSWORD" | base64)
            response=$(curl -s http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker)
            name=$(echo $response | jq '.[].name')
            if [ -z "$name" ];
            then
              if [[ "$STORAGE_TYPE"  ==  "git" && "$BASEURL_HOST" == "github.com" ]];
              then
              response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v6/datasource --data '{"datasourceType": "GITHUB", "name": "gitops", "spinEnabled": "false", "configurationFields": {"token": "git/stash_token", "username": "git/stash_username", "hostUrl": "https://github.com/", "url": "https://api.github.com" } }')
              id=$(echo $response | jq '.id')
              curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v4/spinnaker --data '{"name":"preview-saas","url":"http://sapor-gate:8084","authenticationType":"LDAP","externalAccountFlag":true,"pipelinePromotionFlag":false,"syncAccountFlag":false,"externalAccountConfiguration":{"accountId": "'"${id}"'","accountName":"gitops","provider":"GITHUB","config":{"bucketName":"","region":"","endPoint":"https://github.com/OpsMx/standard-gitops-repo.git","sourcePath":""}},"pipelinePromotionConfiguration":null,"password":"'"${PASSWORD}"'","userName":"'"${USERNAME}"'"}'
              #curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "http://oes-gate.example.ops.com", "authenticationType": "LDAP", "token": "'"${TOKEN}"'", "externalAccountFlag": "true","pipelinePromotionFlag": "false","syncAccountFlag": "false", "externalAccountConfiguration": {"accountId": "'"${id}"'","accountName": "gitops", "provider": "GITHUB", "config": {"bucketName": "", "region": "","endPoint": "https://github.com/OpsMx/standard-gitops-repo.git", "sourcePath": "" }}}'
                  break
              fi
              if [[ "$STORAGE_TYPE"  ==  "git" && "$BASEURL_HOST" == "gitlab.com" ]];
              then
              response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v6/datasource --data '{"datasourceType": "GITLAB", "name": "gitops", "spinEnabled": "false", "configurationFields": {"token": "git/stash_token", "hostUrl": "https://gitlab.com/" } }')
              id=$(echo $response | jq '.id')
              curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v4/spinnaker --data '{"name":"preview-saas","url":"http://sapor-gate:8084","authenticationType":"LDAP","externalAccountFlag":true,"pipelinePromotionFlag":false,"syncAccountFlag":false,"externalAccountConfiguration":{"accountId": "'"${id}"'","accountName":"gitops","provider":"GITLAB","config":{"bucketName":"","region":"","endPoint":"https://gitlab.com/OpsMx/standard-gitops-repo.git","sourcePath":""}},"pipelinePromotionConfiguration":null,"password":"'"${PASSWORD}"'","userName":"'"${USERNAME}"'"}'
                  break
              fi
              if [[ "$STORAGE_TYPE"  ==  "stash" ]];
              then
                if [[ "" ]]
                then
                  response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v2/datasources --data '{"datasourceType": "BITBUCKET", "name": "gitops-bitbucket", "spinEnabled": "false", "configurationFields": {"authType":"bearer","username": "git/stash_username","token": "git/stash_token","read":"","write":"",  "hostUrl": "https://github.com/OpsMx//standard-gitops-repo.git", "url": "https://api.bitbucket.org/2.0/" } }')
                  id=$(echo $response | jq '.id')
                   curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "http://sapor-gate:8084", "authenticationType": "LDAP", "token": "'"${TOKEN}"'", "externalAccountFlag": "true", "pipelinePromotionFlag": "false","syncAccountFlag": "false", externalAccountConfiguration": {"accountId": "'"${id}"'","accountName": "gitops-bitbucket", "provider": "BITBUCKET", "config": {"bucketName": "", "region": "","endPoint": "https://github.com/OpsMx//standard-gitops-repo.git", "sourcePath": " " }}}'

                  break
                else
                  response=$(curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v2/datasources --data '{"datasourceType": "BITBUCKET", "name": "gitops-bitbucket", "spinEnabled": "false", "configurationFields": {"authType":"bearer","username": "git/stash_username","token": "git/stash_token","read":"","write":"", "hostUrl": "https://github.com/OpsMx//standard-gitops-repo.git", "url": "https://api.bitbucket.org/2.0/" } }')
                  id=$(echo $response | jq '.id')
                  curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "http://sapor-gate:8084", "authenticationType": "LDAP", "token": "'"${TOKEN}"'", "externalAccountFlag": "true", "pipelinePromotionFlag":"false","syncAccountFlag":"false", externalAccountConfiguration": {"accountId": "'"${id}"'","accountName": "gitops-bitbucket", "provider": "BITBUCKET", "config": {"bucketName": "", "region": "","endPoint": "https://github.com/OpsMx//standard-gitops-repo.git", "sourcePath": "" }}}'
                  break
                fi
              fi
              if [[ "$STORAGE_TYPE"  ==  "s3" ]];
              then
                 curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-platform:8095/platformservice/v2/datasources --data '{"datasourceType":"AMAZONS3","name":"gitops-s3","configurationFields":{"access_id":"AWS_ACCESS_KEY_ID","secret_key":"AWS_SECRET_ACCESS_KEY"},"spinnakerNames":[""],"spinEnabled": "false"} }'
                 curl --header "Content-Type: application/json"  --header "x-spinnaker-user: admin" --request POST http://oes-sapor:8085/oes/accountsConfig/v3/spinnaker --data '{"name": "preview-saas", "url": "http://sapor-gate:8084", "authenticationType": "LDAP", "token": "'"${TOKEN}"'" , "externalAccountFlag": "true", "pipelinePromotionFlag":"false", "syncAccountFlag":"false", externalAccountConfiguration": {"accountName": "gitops-s3","config":{"bucketName":"bucket name.e.g-testbucket","region":"regionofbucket","endPoint":""},"provider": "AMAZONS3"}}'
              fi
            else
              echo "Spinnaker is already Integrated"
              break
            fi
        

    else
        if [ $wait_period -gt 2000 ];
        then
            echo \"Script is timed out as the Spinnaker is not ready yet.......\"
            break
        else
            echo \"Waiting for Spinnaker services to be ready\"
            sleep 1m
        fi
    fi
    done
---
# Source: oes/templates/configmaps/isd-feature-flag-config.yml
apiVersion: v1
data:
  feature.yml: |
     feature:
       auth-provider:
         flag: true
         jira: OP-18050
       db-cleanup:
         flag: true
         jira: OP-19921         
kind: ConfigMap
metadata:
  labels:
    app: oes
  name: isd-feature-flag-config
---
# Source: oes/templates/configmaps/oes-dashboard-configmap.yaml
apiVersion: v1
data:
  dashboard-local.yml: |
    opsmx:
      dashboard:
        installation:
          mode: OES-AP
    standardErrorCodes:
      filePath: /opsmx/conf/standard-error-code.csv
    platformservice.url: http://oes-platform:8095
    autopilot.url: http://oes-autopilot:8090
    oes.sapor.url: http://oes-sapor:8085
    visibilityservice.url: http://oes-visibility:8096
    auditclientservice:
      url: "http://oes-audit-client:8098"
    gateservice:
      url: "http://oes-gate:8084"
    app:
      sync:
        enabled: true
    spinnakerLink: /deck/
    
kind: ConfigMap
metadata:
  name: oes-dashboard-config
  labels:
    app: oes
    component: dashboard
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
---
# Source: oes/templates/configmaps/oes-ui-configmap.yaml
apiVersion: v1
data:
  app-config.json: |
    {
        "endPointUrl": "/gate/",
        "setApplicationInterval": 300000,
        "triggerPipeline": false
    }
  help-text.json: |
    {
      "POLICY_LISTING": {
        "HEADER": "Policies not found!",
        "BODY": "<div><p>Policy Management feature allows you to create policies to set guardrails for safe and fine grained controls in CI/CD pipelines.</p> <p>Static Policy lets users validate the conditions when creating a pipeline, whereas Runtime Policy enables users for automated decision making during pipeline execution.</p> <p>A policy defines a set of conditions that must be met.</p> <p>As an example, a policy could be created to define a blackout window period (or a moratorium period) for performing production deployments. A moratorium period defines the time period within which no production deployments should be performed. Any deployment to the production environment during this period will automatically be rejected/stopped.</p> <p>ISD uses Open Policy Engine(OPA) for policy definition & execution. OPA is a open source, general-purpose policy engine that unifies policy enforcement across the stack. It uses a high-level declarative language called Rego that lets you specify policy as code.</p> <p>Click on <b>New Policy</b> button to create a new policy.</p></div>"
      },
      "AGENT_LISTING": {
        "HEADER": "No Agents found!",
        "BODY": "<div><p>The Agent allows ISD to reach through firewalls in a secure manner, allowing access to private Kubernetes clusters as well as reach internal services such as Jenkins and Artifactory. The agent is typically used with OpsMx's SaaS ISD offering, where OpsMx hosts the ISD Platform, but services used by the platform are within a secure area owned by the customer. One of the core advantages of using an agent is that the credentials do not need to be disclosed to anyone i.e. credentials remain with-in the cluster where deployment is done.</p> <p>The Agent is a two part system: a <b>Controller</b> runs near ISD, and the <b>Agent</b> runs in the target secure cluster. The Agent is configured to communicate with specific services (Kubernetes, Jenkins etc) within a customer's security domain, while the Controller is in ISD's domain.</p> <p>The Agent is deployed using a manifest generated by ISD. This manifest has per-installation credentials to authenticate to the controller, controller address etc. Services are configured in the Agent by the customer. URL endpoints, CD account names and credentials are provided to the agent using a service configuration. The credentials never leave the agent's security domain.</p> <p>Click on <b>New Agent</b> to create the Agent for your environment. This button is enabled when CD Instance is configured in <b>Setup->CD Integration</b>."
      },
      "AGENT_CREATION": {
        "HEADER": "Agent",
        "BODY": "<div><p>Adding an agent involves the following steps:</p><ul class='helpTextUI'><li>Enter the details (name, cluster and description) and click save</li> <li>Click <b>Download Manifest</b> which appears after save</li><li>In the remote Kubernetes cluster, create service configmap in the default namespace. Examples are available here: https://github.com/OpsMx/standard-gitops-repo/tree/master/SAMPLES/agent-config</li> <li>Apply the downloaded manifest in the default namespace using <b>kubectl apply -f <downloaded file></b> ; Note that the agent should be able to reach the Load Balancer configured for the agent-grpc service,</li><li>Check the Setup->Agents screen for the agent connection status</li></ul></div>",
        "AGENT_NAME": {
          "TOOLTIP": "Name of the agent with which it will referred to",
          "VALIDATION_MESSAGE": {
            "required": "Agent Name cannot be empty",
            "cannotContainSpace": "Agent Name cannot contain space",
            "noSpecialCharacters": "Allowed special character is '-'",
            "startingFromNumber": "Agent Name should not start with number",
            "agentNameExist": "Agent Name already exists"
          }
        },
        "CLUSTER_NAME": {
          "TOOLTIP": "Name of the remote cluster on which agent will be installed on",
          "VALIDATION_MESSAGE": {
            "required": "Cluster Name cannot be empty",
            "cannotContainSpace": "Cluster Name cannot contain space",
            "noSpecialCharacters": "Allowed special character is '-'",
            "startingFromNumber": "Cluster Name should not start with number"
          }
        },
        "DESCRIPTION": {
          "TOOLTIP": "Short description about the agent",
          "VALIDATION_MESSAGE": {}
        },
        "CONNECT_TO_SPINNAKER": {
          "TOOLTIP": "The spinnaker instance you want to associate this account to",
          "VALIDATION_MESSAGE": {
            "required": "Please select Spinnaker"
          }
        }
      },
      "CLOUDPROVIDER_LISTING": {
      "HEADER": "No Cloud Targets found!",
      "BODY": "<div><p>Cloud Targets are integrations to Cloud platforms you deploy your applications to.</p> <p>In this section, you’ll register credentials for your Cloud platforms. Those credentials are known as Accounts. ISD allows you to create & manage Accounts for different Cloud Providers such as AWS, GCP, Kubernetes, etc.</p> <p>When CD instance (Spinnaker) is configured for <b>Direct Sync</b>, <b>New Accounts</b> button will not be visible.</p> <p><b>New Accounts</b> button will be enabled when CD instance (Spinnaker) is configured to use External Accounts in <b>Setup->CD Integration</b>.Click on <b>New Accounts</b> button to create an account for your cloud provider. You can create multiple accounts for the same provider.</p> <p>Click on <b>Sync Accounts</b> button to sync Cloud target accounts with CD Tool</p></div>"
      },
        "CLOUDPROVIDER_CREATION": {
          "HEADER": "Cloud Target",
          "BODY": "<p>In this page, you can create & manage Cloud Target Accounts</p>",
          "AGENT_NAME": {
            "TOOLTIP": "",
            "VALIDATION_MESSAGE": {
              "required": "Agent name cannot be empty",
              "cannotContainSpace": "Agent name cannot contain space",
              "noSpecialCharacters": "Allowed special character are ',-'"
            }
          },
          "CLOUD_PROVIDER": {
            "TOOLTIP": "The Cloud Target type for which you want to add the account",
            "VALIDATION_MESSAGE": {
              "required": "Please select Cloud Target"
            }
          },
          "SPINNAKER": {
            "TOOLTIP": "The Spinnaker instance with which this account would be tied to",
            "VALIDATION_MESSAGE": {
              "required": "Please select Spinnaker"
            }
          },
          "ENVIRONMENT": {
            "TOOLTIP": "The environment name for the account. Many accounts can share the same environment (e.g. dev, test, prod)",
            "VALIDATION_MESSAGE": {
              "required": "Please select Environment"
            }
          },
          "CUSTOM_ENVIRONMENT": {
            "TOOLTIP": "",
            "VALIDATION_MESSAGE": {
              "noSpecialCharacters": "Environment Name cannot contain special characters",
              "cannotContainSpace": "Environment Name cannot contain space",
              "required": "Environment Name cannot be empty",
              "startingFromNumber": "Environment Name cannot start with number",
              "maxlength": "Environment name should not have more than 63 characters!",
              "exists": "Environment name already exists"
            }
          },
          "ACCOUNT_NAME": {
            "TOOLTIP": "Name of the account to operate on",
            "VALIDATION_MESSAGE": {
              "required": "Account name cannot be empty",
              "cannotContainSpace": "Account name cannot contain space",
              "noSpecialCharacters": "Allowed special character is '-'",
              "startingFromNumber": "Account Name cannot start with numbers"
            }
          },
          "NAMESPACE": {
            "TOOLTIP": "A list of namespaces this Spinnaker account can deploy to and will cache (namespaces should be 'coma' separated ex: default,dev",
            "VALIDATION_MESSAGE": {
              "required": "Namespace cannot be empty",
              "cannotContainSpace": "Namespace cannot contain space",
              "noSpecialCharacters": "Special characters not allowed except ',-'"
            }
          },
          "OMIT_NAMESPACE": {
            "TOOLTIP": "A list of namespaces this Spinnaker account cannot deploy to or cache",
            "VALIDATION_MESSAGE": {
              "required": "",
              "noSpecialCharacters": "Special characters not allowed except ',-'"
            }
          },
          "UPLOAD_KUBECONFIG_FILE": {
            "TOOLTIP": "The path to your kubeconfig file. By default, it will be under the Spinnaker user’s home directory in the typical .kube/config location.",
            "VALIDATION_MESSAGE": {
              "required": "File cannot be empty"
            }
          },
          "EXECUTE": {
            "TOOLTIP": "",
            "VALIDATION_MESSAGE": {
              "cannotContainSpace": "Execute Permissions cannot contain space"
            }
          },
          "ACCOUNT_ID": {
            "TOOLTIP": "Your AWS account ID to manage. Refer http://docs.aws.amazon.com/IAM/latest/UserGuide/console_account-alias.html for more information",
            "VALIDATION_MESSAGE": {
              "required": "Account Id cannot be empty",
              "cannotContainSpace": "Account Id cannot contain space"
            }
          },
          "ROLE": {
            "TOOLTIP": "If set, Halyard will configure a credentials provider that uses AWS Security Token Service to assume the specified role",
            "VALIDATION_MESSAGE": {
              "required": "Role cannot be empty",
              "cannotContainSpace": "Role cannot contain space"
            }
          },
          "REGIONS": {
            "TOOLTIP": "The AWS regions this Spinnaker account will manage",
            "VALIDATION_MESSAGE": {
              "required": "Region cannot be empty",
              "cannotContainSpace": "Region cannot contain space"
            }
          },
          "PRIMARY_ACCOUNT": {
            "TOOLTIP": "Whether this account is the primary account? If yes then provide the access & secret key details.",
            "VALIDATION_MESSAGE": {}
          },
          "DYNAMIC_ACCOUNT": {
            "TOOLTIP": "If Enabled, this account will be added to the spinnaker using External Account Configuration, which allows you to load the configurations dynamically without requiring redeployment of Clouddriver.",
            "VALIDATION_MESSAGE": {}
            },
          "ACCESS_KEY": {
            "TOOLTIP": "The default access key used to communicate with AWS",
            "VALIDATION_MESSAGE": {
              "required": "Access key cannot be empty"
            }
          },
          "ACCESS_KEY_BAKERY": {
            "TOOLTIP": "The default access key used for AWS bakery configuration",
            "VALIDATION_MESSAGE": {
              "required": "Access Key (Bakery) cannot be empty"
            }
          },
          "SECRET_KEY": {
            "TOOLTIP": "The secret key used to communicate with AWS",
            "VALIDATION_MESSAGE": {
              "required": "Secret key cannot be empty"
            }
          },
          "SECRET_KEY_BAKERY": {
            "TOOLTIP": "The default secret key used for AWS baskery configuration",
            "VALIDATION_MESSAGE": {
              "required": "Secret Key (Bakery) cannot be empty"
            }
          },
          "APP_KEY": {
            "TOOLTIP": "The App Key (password) of your service principal",
            "VALIDATION_MESSAGE": {
              "required": "App key cannot be empty",
              "cannotContainSpace": "App key cannot contain space"
            }
          },
          "CLIENT_ID": {
            "TOOLTIP": "The Client Id (also called appId) of your service principal",
            "VALIDATION_MESSAGE": {
              "required": "Client Id cannot be empty",
              "cannotContainSpace": "Client Id cannot contain space"
            }
          },
          "AZURE_REGIONS": {
            "TOOLTIP": "The Azure regions this Spinnaker account will manage",
            "VALIDATION_MESSAGE": {
              "required": "Region cannot be empty",
              "cannotContainSpace": "Region cannot contain space"
            }
          },
          "DEFAULT_KEYVALUT": {
            "TOOLTIP": "The name of a Key Vault that contains the user name, password, and ssh public key used to create VMs",
            "VALIDATION_MESSAGE": {
              "required": "Default Keyvault cannot be empty",
              "cannotContainSpace": "Default Keyvault cannot contain space"
            }
          },
          "SUBSCRIPTION_ID": {
            "TOOLTIP": "The subscriptionId that your service principal is assigned to",
            "VALIDATION_MESSAGE": {
              "required": "Subscription Id cannot be empty",
              "cannotContainSpace": "Subscription Id cannot contain space"
            }
          },
          "TENANT_ID": {
            "TOOLTIP": "The tenantId that your service principal is assigned to",
            "VALIDATION_MESSAGE": {
              "required": "Tenant Id cannot be empty",
              "cannotContainSpace": "Tenant Id cannot contain space"
            }
          },
          "DEFAULT_RESOURCE_GROUP": {
            "TOOLTIP": "The default resource group to contain any non-application specific resources.",
            "VALIDATION_MESSAGE": {
              "required": "Default Resouce Group cannot be empty",
              "cannotContainSpace": "Default Resouce Group cannot contain space"
            }
          },
          "OBJECT_ID": {
            "TOOLTIP": "The objectId of your service principal. This is only required if using Packer to bake Windows images.",
            "VALIDATION_MESSAGE": {
              "required": "Object Id cannot be empty",
              "cannotContainSpace": "Object Id cannot contain space"
            }
          },
          "PACKER_RESOURCE_GROUP": {
            "TOOLTIP": "The resource group to use if baking images with Packer",
            "VALIDATION_MESSAGE": {
              "required": "Packer Resouce Group cannot be empty",
              "cannotContainSpace": "Packer Resouce Group cannot contain space"
            }
          },
          "PACKER_STORAGE_ACCOUNT": {
            "TOOLTIP": "The storage account to use if baking images with Packer.",
            "VALIDATION_MESSAGE": {
              "required": "Packer Storage Account cannot be empty",
              "cannotContainSpace": "Packer Storage Account cannot contain space"
            }
          },
          "SSH_PUBLIC_KEY": {
            "TOOLTIP": "Whether to use SSH public key to provision the linux vm. The default value is true which means using the ssh public key.",
            "VALIDATION_MESSAGE": {
            }
          },
          "GCP_FILE": {
            "TOOLTIP": "The path to a JSON service account that Spinnaker will use as credentials. This is only needed if Spinnaker is not deployed on a Google Compute Engine VM, or needs permissions not afforded to the VM it is running on. Refer https://cloud.google.com/compute/docs/access/service-accounts for more information",
            "VALIDATION_MESSAGE": {
              "required": "File cannot be empty"
            }
          },
          "AWS_ACCOUNT_NAME": {
            "TOOLTIP": "",
            "VALIDATION_MESSAGE": {
              "required": "Please Select AWS Account"
            }
          }
        },
      "SPINNAKER_LISTING": {
        "HEADER": "No Spinnaker Configured!",
        "BODY": "<div><p>CD Integration page allows you to connect to a CD instance. This enables ML based verification, Policy enforcement, Informed Approvals, etc.</p><p>Click on the <b>New CD Integration</b> button to connect to a CD instance. Only one instance is supported.</p></div>"
      },
      "SPINNAKER_SETUP": {
        "HEADER": "Spinnaker",
        "BODY": "<p>In this page you can add / update information about your CD instance.</p> <p><strong>Fields:</strong></p> <ul class='helpTextUI'> <li><strong>CD Name</strong>: User defined name for CD instance.<br><span> Example: opsmx-spinnaker</span></li> <li><strong>CD URL</strong>: Gate URL of the CD instance.<br> <span>Example: https://spinnaker-gate.xyz.com or http://oes-gate:8084</span></li> <li><strong>Authentication Type:</strong>: Can be LDAP or X509; for AD, use LDAP</li> <li><strong>Token: </strong> This is used when Authentication Type is LDAP; username & password to LDAP server separated by <b>:</b> in base64 format; Output of 'echo -ne 'username:password' | base64 -w0'</li> <li><strong>Password: </strong>This is used when Authentication Type is X509; Password for P12 File</li> <li><strong>P12 File:</strong> This is used when Authentication Type is X509; P12 File needed for X509 Authentication</li></ul><p>GitOps style Spinnaker is suported where in all configuration is maintained in a repository such as git. These optional sections help configure gitOps style Spinnaker:</p><ul class='helpTextUI'><li><strong>Source Control for Accounts: </strong>You can specify the repository for External configuration in Spinnaker</li> <li><strong>Source Control for Pipeline: </strong>You can specify the repository for pipeline gitOps that allows you to save and restore pipelines from a git repository</li></ul>",
        "ACCOUNT_CREATION_INFO": "The CD name should be the same as the Spinnaker name configured in echo-local.yml",
        "ACCOUNT_CREATION_ADDITIONAL_INFO": "<p></p><p>Adding a Spinnaker instance with CD Name different than the Spinnaker name configured in <i>echo-local.yml</i> will require a manual update to the <i>echo-local.yml</i> and a <i>hal deploy apply</i>. This change is required to allow publishing Spinnaker events to RabbitMQ.</p>",
        "SPINNAKER_NAME": {
          "TOOLTIP": "Name of the Spinnaker instance",
          "VALIDATION_MESSAGE": {
            "required": "CD Name cannot be empty",
            "cannotContainSpace": "CD Name cannot contain space",
            "noSpecialCharacters": "Allowed special character is '-'",
            "startingFromNumber": "CD Name should not start with number"
          }
        },
        "SPINNAKER_GATE_URL": {
          "TOOLTIP": "Gate Url of the Spinnaker instance",
          "VALIDATION_MESSAGE": {
            "required": "CD Gate URL cannot be empty",
            "cannotContainSpace": "CD Gate URL cannot contain space",
            "invalidUrl": "CD Gate URL is invalid"
          }
        },
        "AUTHENTICATION_TYPE": {
          "TOOLTIP": "Select the type of authentication for the spinnaker being added",
          "VALIDATION_MESSAGE": {
            "required": "Please select Authentication Type"
          }
        },
        "LDAP_USERNAME": {
          "TOOLTIP": "User Name",
          "VALIDATION_MESSAGE": {
            "required": "User Name cannot be empty",
            "minlength": "User Name should be more than 4 characters"
          }
        },
        "LDAP_PASSWORD": {
          "TOOLTIP": "Password",
          "VALIDATION_MESSAGE": {
            "required": "Password cannot be empty",
            "minlength": "Password should be more than 8 characters"
          }
        },
        "TOKEN": {
          "TOOLTIP": "Token for Spinnaker authentication",
          "VALIDATION_MESSAGE": {
            "required": "Token cannot be empty",
            "minlength": "Token should be more than 8 characters"
          }
        },
        "PASSWORD": {
          "TOOLTIP": "Password",
          "VALIDATION_MESSAGE": {
            "required": "Password cannot be empty",
            "minlength": "Password should be more than 8 characters"
          }
        },
        "P12_FILE": {
          "TOOLTIP": "P12 File",
          "VALIDATION_MESSAGE": {
            "required": "P12 File cannot be empty"
          }
        },
        "SYNC_ACCOUNTS": {
          "TOOLTIP": "Select Mode of synchronisation of Cloud Targets between Autopilot & Spinnaker",
          "VALIDATION_MESSAGE": {
            "required": "Please select Sync Accounts type"
          }
        },
        "ACCOUNTS_PROVIDER": {
          "TOOLTIP": "Source Control for Halyard Configuration and / or External Account Configuration",
          "VALIDATION_MESSAGE": {
            "required": "Please select provider"
          }
        },
        "ACCOUNTS_ACCOUNT_NAME": {
          "TOOLTIP": "Account name of the Source Control",
          "VALIDATION_MESSAGE": {
            "required": "Please select Account Name"
          }
        },
        "ACCOUNTS_REPOSITORY": {
          "TOOLTIP": "Repository name with full path in the selected Source Control Eg., https://github.com/OpsMx/Opsmx-Saas.git",
          "VALIDATION_MESSAGE": {
            "required": "Repository cannot be empty",
            "cannotContainSpace": "Repository cannot contain space",
            "invalidUrl": "Repository is invalid"
          }
        },
        "ACCOUNTS_SOURCE_PATH": {
          "TOOLTIP": "Existing path in the repository",
          "VALIDATION_MESSAGE": {}
        },
        "ACCOUNTS_REGION": {
          "TOOLTIP": "The AWS regions this Spinnaker account will manage",
          "VALIDATION_MESSAGE": {
            "required": "Region cannot be empty",
            "cannotContainSpace": "Region cannot contain space",
            "startingFromNumber": "Region should not start with number"
          }
        },
        "ACCOUNTS_BUCKET_NAME": {
          "TOOLTIP": "Bucket Name",
          "VALIDATION_MESSAGE": {
            "required": "Bucket Name cannot be empty",
            "cannotContainSpace": "Bucket Name cannot contain space",
            "startingFromNumber": "Bucket Name should not start with number"
          }
        },
        "PIPELINE_PROVIDER": {
          "TOOLTIP": "Use this Spinnaker for pipeline promotion.",
          "VALIDATION_MESSAGE": {
            "required": "Please select provider"
          }
        },
        "PIPELINE_ACCOUNT_NAME": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": {
            "required": "Please select Account Name"
          }
        },
        "PIPELINE_REPOSITORY": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": {
            "required": "Repository cannot be empty",
            "cannotContainSpace": "Repository cannot contain space",
            "invalidUrl": "Repository is invalid"
          }
        },
        "PIPELINE_SOURCE_PATH": {
          "TOOLTIP": "Existing path in the repository",
          "VALIDATION_MESSAGE": {}
        },
        "PIPELINE_REGION": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": {
            "required": "Region cannot be empty",
            "cannotContainSpace": "Region cannot contain space",
            "startingFromNumber": "Region should not start with number"
          }
        },
        "PIPELINE_BUCKET_NAME": {
          "TOOLTIP": "Bucket Name",
          "VALIDATION_MESSAGE": {
            "required": "Bucket Name cannot be empty",
            "cannotContainSpace": "Bucket Name cannot contain space",
            "startingFromNumber": "Bucket Name should not start with number"
          }
        }
      },
      "INTEGRATOR_LISTING": {
        "HEADER": "No Integrator found!",
        "BODY": "<div><p>ISD offers integration with many CI/CD Tools. Integrations are grouped under the following categories - Artifact, CI, Governance, Monitoring Tools, Notifications, Policy and SAST/DAST.</p> <p>Integrations are used to</p> <ul><li>pull logs & metrics for Continuous Verification</li><li>pull meta data from CI/CD Tools for Informed Approvals</li><li>enforce organizational policies at the time of creation or execution of a pipeline</li><li>configure Artifacts, Cloud Providers etc.</li><p>Click on the <b<New Integration</b> button to start integrating your tools </p></div>",
        "SYNC_SPINNAKER_ACCOUNTS": {
          "TOOLTIP": "Push Integration changes to Spinnaker",
          "VALIDATION_MESSAGE": ""
        }
      },
      "PIPELINE_EXECUTION_AUDIT_LISTING": {
        "HEADER": "Pipeline executions not found!",
        "BODY": "<div>This page shows pipeline executions coming from a CD Tool such as Spinnaker in a list view. It also contains the summary view showing the total number of Pipeline Runs, Successful Runs, Failed Runs, Cancelled Runs.</p> <p> Only important fields including Application, Service, Pipeline, Status, Start Time and End Time are shown by default. Additional fields can be enabled using the Hamburger menu towards the right corner.</p></div>",
        "TOOLTIP": {
          "EXECUTION_DATA": "Pipeline is in Running State",
          "CONNECTOR_DATA": "Pipeline is in Running State",
          "STAGE_DURATION": "Pipeline is in Running State"
        },
        "VALIDATION_MESSAGE": {
          "STAGE_DURATION": "No Data available to view Stage Duration",
          "PIPELINE_NOT_EXISTS" : "Execution details not found."
        }
      },
      "PIPELINE_AUDIT_LISTING": {
        "HEADER": "Pipeline updates not found!",
        "BODY": "<div>This page shows pipeline updates coming from a CD Tool such as Spinnaker in a list view.</div>"
      },
      "POLICY_AUDIT_LISTING": {
        "HEADER": "Policy updates / executions not found!",
        "BODY": "<div><p>This page shows policy updates and policy executions, along with allowed/denied information, in a list view. Possible uses, apart from audit and compliance, includes helping users understand the policies that they might be inadvertently trying to break.</p><p>For policy updates, ensure that a policy is created/updated under <strong><a routerLink='/policymanagement'>Setup -> Policies</a></strong>. For policy execution events, please add a policy stage in a pipeline and execute it.</div>"
      },
      "POLICY_CREATION": {
        "HEADER": "Policy",
        "BODY": "<p>In this page, you can define & manage policies.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li> <strong>Name:</strong> User defined name for the policy</li><li><strong>Policy Type:</strong> Static Policy lets users validate the conditions when creating a pipeline, whereas Runtime Policy enables users for automated decision making during pipeline execution.</li><li> <strong>Policy Engine:</strong> Policy Engine to be used; currently, only OPA is supported</li> <li><strong>Policy Engine Account:</strong> Policy Engine Account for the Credentials. You can manage accounts from Setup -> Integrations -> Policy </li> <li><strong>Policy File:</strong> File containing the Policy You can upload the file by clicking on <strong>Choose File</strong> button. This is optional. If not present, you can enter the policy directly in the <strong>Policy Details</strong> field</li><li> <strong>Policy Details:</strong> Policy definition</li> <li><strong>Policy Permissions:</strong>Enable/disable access to the policy in Autopilot to specific usergroups</li></ul>",
        "NAME": {
          "TOOLTIP": "Policy Name",
          "VALIDATION_MESSAGE": {
            "required": "Name cannot be empty",
            "cannotContainSpace": "Name cannot contain space",
            "exists": "Name already exists"
          }
        },
        "POLICY_DETAILS": {
          "TOOLTIP": "Define your policy using the rego language",
          "VALIDATION_MESSAGE": {
            "required": "Policy Details cannot be empty"
          }
        },
        "POLICY_ENGINE": {
          "TOOLTIP": "Supported Policy Account Types",
          "VALIDATION_MESSAGE": {
            "required": "Please select Policy Account Type"
          }
        },
        "POLICY_ENGINE_ACCOUNT": {
          "TOOLTIP": "Policy Account Names",
          "VALIDATION_MESSAGE": {
            "required": "Please select Policy Engine Account"
          }
        },
        "POLICY_TYPE": {
          "TOOLTIP": "A static policy lets users validate conditions before the start of execution, whereas a Runtime policy enables users for automated decision making during execution.",
          "VALIDATION_MESSAGE": {
            "required": "Please select Policy Engine Type"
          }
        },
        "POLICY_DESCRIPTION": {
          "TOOLTIP": "Optional Description for the policy"
        },
        "POLICY_FILE": {
          "TOOLTIP": "File containing the Policy. You can upload the file by clicking on 'Choose File' button. This is optional. If not present, you can enter the policy directly in the 'Policy Details' field"
        }
      },
      "VERIFICATION": {
        "HEADER": "Verification Gate executions not found!",
        "BODY": "<div><p>This page shows Verification Gate executions in a list view.</p> <p>The Continuous Verification performs automated log and metrics analysis for new releases with built-in unsupervised and supervised machine learning algorithms for risk analysis and canary deployments.</p><p>Continuous Verification is a release verification process that provides Dev and Ops engineers an intelligent automated real-time actionable risk assessment of a new release deployed. The Continuous Verification verifies the latest version of the service comparing to the baseline or prior release after production rollout. The baseline can be a deployment done prior or the current deployment during rollout using canary or blue/green or rolling update strategies.</p> <p>It leverages unsupervised and supervised machine learning techniques to analyze 100s of metrics and logs data to perform in-depth analysis of architectural regressions, performance, scalability and security violations of new releases in a scalable way for enterprises.</p> <p>ISD provides a Verification Gate to analyze logs from your Target Application and this can be inserted as a Stage in your CI/CD Pipeline. Note that one must configure the metric and log datasources, such as Prometheus and Elastic before using this functionality.</p> <p>Insert Verification Gate to a pipeline in your application using <b>Pipeline Builder -> Add Stage</b>. When the pipeline is run, the Gate executions will start appearing in this page.</p></div>",
        "LOG_ANALYSIS": {
          "BODY": "",
          "SENSITIVITY": {
            "TOOLTIP": "Impact of Unexpected Issues on the log scoring",
            "VALIDATION_MESSAGE": {}
          },
          "PERCEIVED_RISK": {
            "TOOLTIP": "The overall risk associated with changes made in this verification run",
            "VALIDATION_MESSAGE": {}
          }
        },
        "ANALYSIS_SUMMARY": {
          "LOG_TEMPLATE": {
            "TOOLTIP": "Log template for the verification run",
            "VALIDATION_MESSAGE": {}
          },
          "METRIC_TEMPLATE": {
            "TOOLTIP": "Metric template for the verification run",
            "VALIDATION_MESSAGE": {}
          },
          "LOG_BASELINE_START_TIME": {
            "TOOLTIP": "Start time of the canary analysis for Baseline",
            "VALIDATION_MESSAGE": {}
          },
          "LOG_BASELINE_END_TIME": {
            "TOOLTIP": "End  time of the canary analysis for Baseline",
            "VALIDATION_MESSAGE": {}
          },
          "LOG_NEW_RELEASE_START_TIME": {
            "TOOLTIP": "Start time of the canary analysis for New Release",
            "VALIDATION_MESSAGE": {}
          },
          "LOG_NEW_RELEASE_END_TIME": {
            "TOOLTIP": "End  time of the canary analysis for New Release",
            "VALIDATION_MESSAGE": {}
          },
          "ANALYSIS_TYPE": {
            "TOOLTIP": "The type of verification analysis done, can be metric, log or both metric and log analysis",
            "VALIDATION_MESSAGE": {}
          },
          "LOG_STATUS": {
            "TOOLTIP": "The current status of the log analysis",
            "VALIDATION_MESSAGE": {}
          },
          "LOG_SCORE": {
            "TOOLTIP": "The overall score of the current log analysis report",
            "VALIDATION_MESSAGE": {}
          },
          "METRIC_STATUS": {
            "TOOLTIP": "The current status of the metric analysis",
            "VALIDATION_MESSAGE": {}
          },
          "METRIC_SCORE": {
            "TOOLTIP": "The overall score of the current metric analysis report",
            "VALIDATION_MESSAGE": {}
          },
          "BASELINE_SIZE": {
            "TOOLTIP": "The size of the file with the Baseline logs",
            "VALIDATION_MESSAGE": {}
          },
          "NEW_RELEASE_SIZE": {
            "TOOLTIP": "The size of the file with the New Release logs",
            "VALIDATION_MESSAGE": {}
          },
          "BASELINE_LINES": {
            "TOOLTIP": "The number of log lines for the Baseline",
            "VALIDATION_MESSAGE": {}
          },
          "NEW_RELEASE_LINES": {
            "TOOLTIP": "The number of log lines for the New Release",
            "VALIDATION_MESSAGE": {}
          },
          "ANALYSIS_DURATION": {
            "TOOLTIP": "The time taken to perform the current verification run",
            "VALIDATION_MESSAGE": {}
          },
          "LIFETIME_HOURS": {
            "TOOLTIP": "The duration for which the canary analysis was performed, 1 lifetime hour is equal to 1 hour.",
            "VALIDATION_MESSAGE": {}
          },
          "RECLASSIFICATION_DURATION": {
            "TOOLTIP": "The time taken to perform reclassification",
            "VALIDATION_MESSAGE": {}
          },
          "INTERVAL_MINUTES": {
            "TOOLTIP": "The Lifetime hours in minutes",
            "VALIDATION_MESSAGE": {}
          },
          "REGULAR_EXPRESSION": {
            "TOOLTIP": "A sequence of characters to specify the search pattern",
            "VALIDATION_MESSAGE": {}
          },
          "RESPONSE_KEY": {
            "TOOLTIP": "Field name in the index where the regular expression is to be searched",
            "VALIDATION_MESSAGE": {}
          },
          "SCORING_ALGORITHM": {
            "TOOLTIP": "Scoring Algorithm for the risk analysis",
            "VALIDATION_MESSAGE": {}
          },
          "BASELINE_LOGS": {
            "TOOLTIP": "View the Baseline logs",
            "VALIDATION_MESSAGE": {}
          },
          "NEW_RELEASE_LOGS": {
            "TOOLTIP": "View the New Release logs",
            "VALIDATION_MESSAGE": {}
          }
        },
        "METRIC_ANALYSIS": {
          "BODY": ""
        },
        "CORRELATION": {
          "BODY": ""
        }
      },
      "MANUAL_TRIGGER": {
        "BODY": "<p>Continuous Verification is a REST service that can be deployed on premise or use managed cloud service for analysis. Continuous Verification interfaces with monitoring systems for logs and metrics and uses the metadata provided in start analysis phase to retrieve the logs and metrics for deployment verification. Continuous Verification does not interface with the services deployed directly for its analysis.            Deployment Pipeline can be based on Spinnaker or Jenkins for Enterprise Continuous Delivery. Verification can also be triggered manually by providing the required parameters in this dialog box.</p>",
        "APPLICATION": {
          "TOOLTIP": "Name of the application",
          "VALIDATION_MESSAGE": ""
        },
        "BASELINE_START_TIME": {
          "TOOLTIP": "Time to enable warming up of the container",
          "VALIDATION_MESSAGE": ""
        },
        "NEW_RELEASE_START_TIME": {
          "TOOLTIP": "Intervals in which metric-data is fetched and analysed",
          "VALIDATION_MESSAGE": ""
        },
        "SUCCESSFUL_SCORE": {
          "TOOLTIP": "The score under which the Analysis should fail",
          "VALIDATION_MESSAGE": ""
        },
        "UNHEALTHY_SCORE": {
          "TOOLTIP": "The score above which the Analysis should be a pass",
          "VALIDATION_MESSAGE": ""
        },
        "ANALYSIS_LIFETIME": {
          "TOOLTIP": "The time in hours for which the Canary Analysis should be run",
          "VALIDATION_MESSAGE": ""
        },
        "RUN_INFO": {
          "TOOLTIP": {
            "Build Info": "http://jenkins.opsmx.net:8181/jenkins/job/Dev-visibilityservice-build-branch/770/",
            "Code Repository": "https://github.com/OpsMx/visibility-service",
            "Version": "v1.09"
          },
          "VALIDATION_MESSAGE": ""
        },
        "SERVICE": {
          "TOOLTIP": "Service",
          "VALIDATION_MESSAGE": ""
        },
        "TEMPLATE_NAME": {
          "TOOLTIP": "Template Name",
          "VALIDATION_MESSAGE": ""
        },
        "GATE": {
          "TOOLTIP": "Gate",
          "VALIDATION_MESSAGE": ""
        },
        "FILTER_KEY": {
          "TOOLTIP": "Filter Key",
          "VALIDATION_MESSAGE": ""
        },
        "BASELINE": {
          "TOOLTIP": "Baseline",
          "VALIDATION_MESSAGE": ""
        },
        "NEW_RELEASE": {
          "TOOLTIP": "New Release",
          "VALIDATION_MESSAGE": ""
        }
      },
      "TEST_VERIFICATON": {
        "HEADER": "Test Verification Gate executions not found!",
        "BODY": "<div> <p>The Continuous Verification performs automated log and metric analysis for new releases with built-in unsupervised and supervised machine learning algorithms for risk analysis. Autopilot provides a Test Verification Gate to analyse logs from your Test Harness and this can be inserted as a Stage in your CI/CD Pipeline. </p>     <p>This page shows Test Verification Gate executions in a list view. </p> <p>Insert Test Verification Gate to a pipeline in your application using <a [routerLink]='['/setup/applications']'><strong>Setup -> Applications</strong></a>.When the pipeline is run, the Gate executions will start appearing in this page.</p> </div>"
      },
      "TEST_CASE": {
        "HEADER": "Test Cases not found!",
        "BODY": "<div> <p>The Continuous Verification performs automated log and metric analysis for new releases with built-in unsupervised and supervised machine learning algorithms for risk analysis. Autopilot provides a Test Verification Gate to analyse logs from your Test Harness and this can be inserted as a Stage in your CI/CD Pipeline. </p>     <p>This page shows Test Cases in a list view. </p> <p>Insert Test Verification Gate to a pipeline in your application using <a [routerLink]='['/setup/applications']'><strong>Setup -> Applications</strong></a>.When the pipeline is run, the Gate executions will start appearing in this page.</p> </div>"
      },
      "VISIBILITY_LISTING": {
        "HEADER": " <div><span style='font-size: 16px; font-weight: bold;'>Approval Gate executions not found!</span></div>",
        "BODY": "<div><p>This page shows Approval Gate executions in a list view.</p> <p>ISD provides <b>approval</b> mechanism for deployments. To make an informed decision regarding pipeline execution, an approver may need to check the data from multiple data sources, such as CI Systems, Repositories, SAST/DAST Tools etc. ISD provides Approval Gate feature which fetches relevant information from multiple CI/CD Tools and presents the data in one place, to enable the user to make an quick and informed decision on pipeline execution. This Gate can be inserted as a Stage in your CI/CD Pipeline.</p> <p>Note that appropriate data sources must be configured in the <b>Setup -> Integration</b> view before Approval stage can be used.</p> <p>Insert Approval Gate to a pipeline in your application using <b>Pipeline Builder -> Add Stage</b>. When the pipeline is run, the Gate executions will start appearing in this page.</p></div>"
      },
      "VISIBILITY_DETAILS": {
        "APPLICATION_NAME": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": ""
        },
        "SERVICE_NAME": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": ""
        },
        "APPROVAL_BTN_TITLE": {
          "TOOLTIP": "Insufficient Permission to execute",
          "VALIDATION_MESSAGE": ""
        },
        "GATE_NAME": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": ""
        },
        "STATUS": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": ""
        },
        "COMMENT": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": ""
        },
        "TRIGGER_URL": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": ""
        },
        "APPROVAL_GROUP": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": ""
        },
        "CONNECTORS": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": ""
        },
        "ACTIVATED_TIME": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": ""
        },
        "REVIEWED_AT": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": ""
        },
        "REVIEWER": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": ""
        },
        "COMMENTS": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": ""
        }
      },
      "FORM_GRID": {
        "ADD_NEW_ROW": {
          "TOOLTIP": "Add New Row",
          "VALIDATION_MESSAGE": ""
        },
        "DELETE_ROW": {
          "TOOLTIP": "Delete row",
          "VALIDATION_MESSAGE": ""
        }
      },
      "APPLICATION_DASHBOARD": {
        "VERIFICATION_FAILURES": {
          "TOOLTIP": "Total number of Verification Failures including Test Verification Failures",
          "VALIDATION_MESSAGE": ""
        }
      },
      "APPLICATION_LISTING": {
        "HEADER": "No applications were found to match your filter!",
        "BODY": "",
        "PLACEHOLDER": "You don't have access to this Page. Please contact your Administrator",
        "SYNC_SPINNAKER": {
          "TOOLTIP": "To be able to work on applications created in Spinnaker, you need to import them here",
          "VALIDATION_MESSAGE": ""
        },
        "SYNC_SPINNAKER_NOT_CONFIGURED": {
          "TOOLTIP": "Configure Spinnaker to Sync Spinnaker Applications from here",
          "VALIDATION_MESSAGE": ""
        },
        "SYNC_SPINNAKER_ERROR": {
          "TOOLTIP": "Could not fetch Spinnaker Details. Please contact Administrator",
          "VALIDATION_MESSAGE": ""
        },
        "DISABLE_CREATE_APPLICATION_BTN": {
          "TOOLTIP": "You do not have permission to create Application",
          "VALIDATION_MESSAGE": ""
        }
      },
      "START_DEPLOYMENT": {
        "APPLICATION_NAME": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": {
            "required": "Application Name is required",
            "empty": "Please create Spinnaker Application to continue"
          }
        },
        "SERVICE_NAME": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": {
            "required": "Service Name is required",
            "empty": "Pipelines are not present for this Application"
          }
        },
        "START_DEPLOYMENT_BTN": {
          "TOOLTIP": "Please create Spinnaker Application to 'Start New Deployment'",
          "VALIDATION_MESSAGE": {
            "required": "Service Name is required"
          }
        }
      },
      "APPLICATION_DETAILS": {
        "HEADER": "Application Details",
        "BODY": "<ul class='helpTextUI'><li><strong>Application Name</strong>: User defined name of the application</li> <li><strong>Description</strong>: Application description</li> <li><strong>Email ID</strong>: Your email id</li></ul>",
        "APPLICATION_NAME": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": {
            "exists": "Application already exists",
            "noSpecialCharacters": "Application Name cannot contain special characters",
            "cannotContainSpace": "Application Name cannot contain space",
            "required": "Application Name cannot be empty",
            "startingFromNumber": "Application Name cannot start with numbers",
            "maxlength": "Application name should not have more than 63 characters!"
          }
        },
        "APPLICATION_DESCRIPTION": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": ""
        },
        "EMAIL_ID": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": {
            "email": "Email Id is invalid",
            "required": "Email Id cannot be empty"
          }
        }
      },
      "SERVICE_DETAILS": {
        "HEADER": "Services",
        "BODY": "<p>An Application can contain multiple services. A service can contain multiple pipelines. When a Service is created, a Pipeline with the same name is created automatically. You can add more pipelines by clicking on '+' symbol in <strong>Service Pipeline</strong></p>",
        "SERVICE_NAME": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": {
            "exists": "Service already exists",
            "noSpecialCharacters": "Service Name cannot contain special characters",
            "cannotContainSpace": "Service Name cannot contain space",
            "required": "Service Name cannot be empty",
            "startingFromNumber": "Service Name cannot start with number",
            "maxlength": "Service name should not have more than 63 characters!"
          }
        },
        "SERVICE_PIPELINE": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": ""
        },
        "ADD_NEW_SERVICE": {
          "TOOLTIP": "Add a new Service",
          "VALIDATION_MESSAGE": ""
        },
        "SHOW_OR_HIDE_SERVICE": {
          "TOOLTIP": "Show/Hide this service in the deployment dashboard",
          "VALIDATION_MESSAGE": ""
        },
        "DELETE_PIPELINE_ICON": {
          "TOOLTIP": "Delete Pipeline from Service",
          "VALIDATION_MESSAGE": ""
        },
        "DELETE_PERMISSION": {
          "TOOLTIP": "Insufficient Permission to Delete this Service",
          "VALIDATION_MESSAGE": ""
        },
        "DELETE_SERVICE": {
          "TOOLTIP": "Service can be deleted on deleting pipelines",
          "VALIDATION_MESSAGE": ""
        }
      },
      "GROUP_PERMISSION": {
        "APP_PERMISSIONS": {
          "TOOLTIP": "Authorization definition for this Application",
          "VALIDATION_MESSAGE": {
            "groupValid": "Groups cannot be empty",
            "permissionsValid": "Atleast 1 permission should be assigned to the groups",
            "allPermissionForOneGroup": "Atleast 1 group should have all permissions"
          }
        },
        "INTEGRATORS_PERMISSIONS": {
          "TOOLTIP": "Configure specific user group’s access to this integration.",
          "VALIDATION_MESSAGE": ""
        },
        "CLOUD_PROVIDER_PERMISSIONS": {
          "TOOLTIP": "Authorization definition for this Cloud Targets",
          "VALIDATION_MESSAGE": ""
        },
        "AGENT_PERMISSIONS": {
          "TOOLTIP": "Authorization definition for this Agent",
          "VALIDATION_MESSAGE": ""
        },
        "POLICY_PERMISSIONS": {
          "TOOLTIP": "Authorization definition for this Policy",
          "VALIDATION_MESSAGE": ""
        },
        "ADD_GROUP": {
          "TOOLTIP": "Add New Group",
          "VALIDATION_MESSAGE": ""
        },
        "DELETE": {
          "TOOLTIP": "Delete",
          "VALIDATION_MESSAGE": ""
        }
      },
      "GATE_DETAILS": {
        "HEADER": "Gate Configuration",
        "BODY": "<p>Select Gates from <strong>Existing Gates</strong> dropdown to load Gate Configuration and to add new Gate Configuration click the <strong>Add New Gate</strong> button</p> <p>Autopilot has the following Gate Types</p> <ul class='helpTextUI'> <li><strong>Approval</strong>: Fetches relevant information from multiple CI/CD Tools, presents the data in one place, to enable the user to make quick and informed decision on pipeline execution</li> <li><strong>Verification</strong>: Analyze logs & metrics from your target application to evaluate the risk in software delivery</li> <li><strong>Test Verification</strong>: Analyze logs from your Test Harness to evaluate the risk in software delivery</li>  <li><strong>Policy</strong>: Defines a set of conditions that need to be verified while creating or executing a CI/CD pipeline</li> </ul>",
        "PIPELINE": {
          "TOOLTIP": "Shows the structure of how the Gates are stacked in the Pipeline",
          "VALIDATION_MESSAGE": ""
        },
        "TYPE": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": ""
        },
        "EXISITING_GATE": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": ""
        },
        "ENVIRONMENT": {
          "TOOLTIP": "Specify Environment for this Gate",
          "VALIDATION_MESSAGE": {
            "required": "Environment Name is Invalid"
          }
        },
        "CUSTOM_ENVIRONMENT_NAME": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": {
            "noSpecialCharacters": "Environment Name cannot contain special characters",
            "cannotContainSpace": "Environment Name cannot contain space",
            "required": "Environment Name cannot be empty",
            "startingFromNumber": "Environment Name cannot start with number",
            "maxlength": "Environment name should not have more than 63 characters!",
            "exists": "Environment name already exists"
          }
        },
        "GATE_NAME": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": {
            "exists": "Gate already exists",
            "noSpecialCharacters": "Gate Name cannot contain special characters",
            "cannotContainSpace": "Gate Name cannot contain space",
            "required": "Gate Name cannot be empty",
            "startingFromNumber": "Gate Name cannot start with number",
            "maxlength": "Gate name should not have more than 63 characters!"
          }
        },
        "DEPENDS_ON": {
          "TOOLTIP": "This field determines the placement of the current Gate in the Pipeline. This field is not required if there are no Stages in the Pipeline",
          "VALIDATION_MESSAGE": {
            "required": "Depends On cannot be empty"
          }
        },
        "CONNECTOR": {
          "TOOLTIP": "Tool to gather information for informed Approvals",
          "VALIDATION_MESSAGE": {
            "required": "Please select Connector"
          }
        },
        "ACCOUNT": {
          "TOOLTIP": "Account name of the connector",
          "VALIDATION_MESSAGE": {
            "required": "Please select Account"
          }
        },
        "TEMPLATE": {
          "TOOLTIP": "Define the specific fields of interest from connector",
          "VALIDATION_MESSAGE": {
            "required": "Please select Template"
          }
        },
        "ADD_NEW_TEMPLATE": {
          "TOOLTIP": "Add New Connector",
          "VALIDATION_MESSAGE": ""
        },
        "EDIT_TEMPLATE": {
          "TOOLTIP": "Edit Template",
          "VALIDATION_MESSAGE": ""
        },
        "VIEW_TEMPLATE": {
          "TOOLTIP": "View Template",
          "VALIDATION_MESSAGE": ""
        },
        "DELETE_TEMPLATE": {
          "TOOLTIP": "Delete Template",
          "VALIDATION_MESSAGE": ""
        },
        "TEMPLATE_TOOL_TYPE": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": ""
        },
        "TEMPLATE_NAME": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": {
            "noSpecialCharacters": "Template Name cannot contain special characters",
            "required": "Template Name cannot be empty",
            "startingFromNumber": "Template Name cannot start with number",
            "maxlength": "Template Name should not have more than 63 characters!"
          }
        },
        "TEMPLATE_DESCRIPTION": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": ""
        },
        "AUTOMATED_APPROVAL": {
          "TOOLTIP": "Use predefined conditions to Approve or Reject a request. You can configure conditions using Policies.",
          "VALIDATION_MESSAGE": {
            "required": "Please select Approval Condition"
          }
        },
        "APPROVAL_GROUPS": {
          "TOOLTIP": "Selected groups will be able to review this Approval Gate",
          "VALIDATION_MESSAGE": {
            "required": "Please select Approval Groups to continue"
          }
        },
        "APPROVAL_GROUP_MSG": {
          "TOOLTIP": "Selected groups should have atleast view access to the application",
          "VALIDATION_MESSAGE": ""
        },
        "GATE_SECURITY_SOURCE_URL": {
          "TOOLTIP": "Source Url",
          "VALIDATION_MESSAGE": ""
        },
        "GATE_SECURITY_SOURCE_URL_COPY": {
          "TOOLTIP": "Copy Source Url",
          "VALIDATION_MESSAGE": ""
        },
        "PAYLOAD_CONSTRAINTS": {
          "TOOLTIP": "Payload Constraints for Gate Security",
          "VALIDATION_MESSAGE": ""
        },
        "PAYLOAD_CONSTRAINTS_KEY": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": {
            "cannotContainSpace": "Key cannot contain space",
            "required": "Invalid Key"
          }
        },
        "LOG_TEMPLATE": {
          "TOOLTIP": "A collection of all the information needed to run the log analysis",
          "VALIDATION_MESSAGE": ""
        },
        "CREATE_GATE_CONFIG_TEMPLATE": {
          "TOOLTIP": "Create New Template",
          "VALIDATION_MESSAGE": ""
        },
        "EDIT_GATE_CONFIG_TEMPLATE": {
          "TOOLTIP": "Edit Template",
          "VALIDATION_MESSAGE": ""
        },
        "VIEW_GATE_CONFIG_TEMPLATE": {
          "TOOLTIP": "View Template",
          "VALIDATION_MESSAGE": ""
        },
        "DELETE_GATE_CONFIG_TEMPLATE": {
          "TOOLTIP": "Delete Template",
          "VALIDATION_MESSAGE": ""
        },
        "METRIC_TEMPLATE": {
          "TOOLTIP": "Information needed to run the metric analysis",
          "VALIDATION_MESSAGE": ""
        },
        "POLICY": {
          "TOOLTIP": "",
          "VALIDATION_MESSAGE": ""
        },
        "DELETE_PERMISSION": {
          "TOOLTIP": "Insufficient Permission to Delete this Gate",
          "VALIDATION_MESSAGE": ""
        }
      },
      "LOGGED_INUSER_DETAILS": {
        "HEADER": "No Users found",
        "BODY": ""
      },
      "APPLICATION_DEPLOYMENT": {
        "DEPLOYMENT_GRID_SYNC": {
          "TOOLTIP": "When the cluster deployment matches with the latest pipeline execution it is 'In Sync'; if not, it is 'Out of Sync'"
        }
      },
    "INTEGRATION": {
    "AMAZONS3":{
      "HEADER": "Amazon S3",
      "BODY":"<span><p>Spinnaker can be configured to use AWS S3 bucket as Spinnaker's persistent storage or Artifact source</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account Name</strong>: User-defined account name for your AWS S3 access. The account name appears in Spinnaker as an input source for artifact selection.<span class='noBr'></span></li><li><strong>Access Key Id</strong>: AWS IAM user access key who has access to the identified S3 bucket. Not required, If Spinnaker is running in EC2 or EKS with an associated IAM role. In that case, the IAM instance role is used for S3 connectivity.</li><li><strong>Secret Access Key</strong>: AWS IAM user Secret Key. Not required, If Spinnaker is running in EC2 or EKS with an associated IAM role. In that case, the IAM instance role is used for S3 connectivity.</li><li><strong>Region</strong>: AWS region where the AWS S3 bucket is located</li><li><strong>API Region</strong>: AWS S3 API region, only required when using an S3 clone such as Minio</li><li><strong>API Endpoint</strong>: AWS S3 API endpoint, only required when using an S3 clone such as Minio</li><li><strong>Connect to CD</strong>: Toggle on to propagate the change into the CD Tool.</li><li><strong>Permissions</strong>: Enable/disable access to the Amazon S3 account in Autopilot to specific user groups</li></ul></span>",
      "ACCOUNTNAME":{
        "TOOLTIP":"User-defined account name for your AWS S3 access. The account name appears in Spinnaker as an input source for artifact selection.",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
      },
      "ACCESS_ID":{
        "TOOLTIP":"AWS IAM user's access key who has access to the identified S3 bucket. Not required, If Spinnaker is running in EC2 or EKS with an associated IAM role. In that case, the IAM instance role is used for S3 connectivity.",
        "VALIDATION_MESSAGE":{
          "required":"Access Key Id cannot be empty"
        }
      },
      "SECRET_KEY":{
        "TOOLTIP":"AWS IAM user Secret Key. Not required, If Spinnaker is running in EC2 or EKS with an associated IAM role. In that case, the IAM instance role is used for S3 connectivity.",
        "VALIDATION_MESSAGE":{
          "required":"Secret Access Key cannot be empty"
        }
      },
      "REGION":{
        "TOOLTIP":"AWS region where the AWS S3 bucket is located",
        "VALIDATION_MESSAGE":{
          "required":"Region cannot be empty"
        }
      },
      "APIENDPOINT":{
        "TOOLTIP":"AWS S3 API endpoint, only required when using an S3 clone such as Minio",
        "VALIDATION_MESSAGE":{
        }
      },
      "APIREGION":{
        "TOOLTIP":"AWS S3 API region, only required when using an S3 clone such as Minio",
        "VALIDATION_MESSAGE":{
        }
      },
      "SPINNAKERTOGGLE":{
        "TOOLTIP":"Switch On this toggle to configure the resource in a gitops enabled Spinnaker instance",
        "VALIDATION_MESSAGE":{}
      }
    },
    "ARTIFACTORY":{
      "HEADER": "Artifactory",
      "BODY":"<span><p>JFrog Artifactory integration can be used as an Artifact source in Spinnaker and also a Data source for Approval-Gate.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account Name</strong>: User-defined account name for your Jfrog Artifactory access. The account name appears in Spinnaker as an Artifactory trigger type input.</li><li><strong>Endpoint</strong>: The base URL of your Artifactory search is reachable at. <span class='noBr'>(Example: https://xyz.my-jfrog.com)</span></li><li><strong>Repo</strong>: The Artifactory repo which needs to be searched</li><li><strong>Repo Type</strong>: The package type of repo in your Artifactory is to be searched. Default is Maven.</li><li><strong>Group Id</strong>: The group id in your Artifactory is to be searched</li><li><strong>Username</strong>: The Artifactory user's username for authentication</li><li><strong>Password</strong>: The Artifactory user's password for authentication</li><li><strong>Token</strong>: Artifactory personal access token. You can find <a href='https://www.jfrog.com/confluence/display/JFROG/Access+Tokens' target='_blank'>here</a> how to generate personal access tokens. <span class='autolinebreak'>(Example: ZlQDAwMFwvdXNlcnNcL21hZGh1a2FyIiwic2NwIjoiYXBwbGllZC1wZXJtaXNzaW9uc1wvYWRtaW4gYXBpOioiLCJhdWQiOlsiamZydEAqIiwiamZhY0AqIiwiamZldnmbWRAKiJdLCJpc3MiOiJqZmZlQDAAzNzY3MiwiaWF0IjoxNjI5ODY0ODcyLCJqdGkiOiI1ZWFiNjlhYi1hZDY0LTRjOGItOTMyZC0wMDAxMWZiZWU5YWIifQ.tzBgL3fQgZ1dwlLLS2UAT7G)</span></li><li><strong>Connect to Spinnaker</strong>: Toggle on to propagate the change into the CD Tool.</li><li><strong>Permissions</strong>: Enable or disable specific user groups' access to the Artifactory account in ISD.</li></ul></span>",
      "ACCOUNTNAME":{
        "TOOLTIP":"User-defined account name for your Jfrog Artifactory access. The account name appears in Spinnaker as an Artifactory trigger type input.",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
      },
      "ENDPOINT":{
        "TOOLTIP":"The base URL of your Artifactory search is reachable at",
        "VALIDATION_MESSAGE":{
          "required":"Endpoint cannot be empty",
          "invalidUrl": "Endpoint URL is invalid"
        }
      },
      "REPO":{
        "TOOLTIP":"The repo in your artifactory to be searched",
        "VALIDATION_MESSAGE":{
          "required":"Repo cannot be empty"
        }
      },
      "REPOTYPE":{
        "TOOLTIP":"The package type of repo in your Artifactory is to be searched. Default is Maven.",
        "VALIDATION_MESSAGE":{
        }
      },
      "GROUPID":{
        "TOOLTIP":"The group id in your Artifactory is to be searched.",
        "VALIDATION_MESSAGE":{
        }
      },
      "AUTHENTICATIONTYPE":{
        "TOOLTIP":"Select how the external resource confirms the user credentials",
        "VALIDATION_MESSAGE":{
          "required":"Authentication cannot be empty"
        }
      },
      "TOKEN":{
        "TOOLTIP":"The Token of the artifactory user to authenticate as",
        "VALIDATION_MESSAGE":{
          "required":"Token cannot be empty"
        }
      },
      "USERNAME":{
        "TOOLTIP":"The Artifactory user's username for authentication",
        "VALIDATION_MESSAGE":{
          "required":"User Name cannot be empty"
        }
      },
      "PASSWORD":{
        "TOOLTIP":"The Artifactory user's password for authentication",
        "VALIDATION_MESSAGE":{
          "required":"Password cannot be empty"
        }
      },
      "SPINNAKERTOGGLE":{
        "TOOLTIP":"Toggle on to propagate the change into the CD Tool.",
        "VALIDATION_MESSAGE":{}
      }
    },
    "BITBUCKET":{
      "HEADER": "Bitbucket Cloud",
      "BODY":"<span><p>BitBucket Cloud integration can be used as a datasource for Approval Gate as well as to configure Spinnaker for BitBucket Cloud.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account Name</strong>: User-defined account name for your BitBucket Cloud access. <span class='noBr'>(Example: opsmx-bitbucket)</span></li><li><strong>Host URL</strong>: BitBucket Cloud (SaaS) Web URL. <span class='noBr'>It is usually https://bitbucket.org </span></li><li><strong>API URL</strong>: This is needed by Autopilot to access Bitbucket Cloud resources such as accounts & repositories through API calls <span class='noBr'>(Example: https://api.bitbucket.org/2.0/repositories)</span></li><li><strong>Authentication Type</strong>: Select one of the available options. If you are unsure, consult your BitBucket administrator to determine which authentication mechanism is used.</li><li><strong>Anonymous</strong>: No username or password is used. Access identity is anonymous.</li><li><strong>User Name</strong>: The BitBucket Cloud Service username </li><li><strong>Token</strong>: The user's username and access token This token is obtained from the Bitbucket user profile page here. <span class='noBr'>(Example: xCPkVZfxaE9iULmfYYkK)</span></li> <li><strong>Password</strong>: The BitBucket Cloud Service password</li><li><strong>Connect to Spinnaker</strong>: Toggle on to propagate the change into the CD Tool.</li><li><strong>Permissions</strong>: Enable/disable access to the Bitbucket Account in Autopilot to specific user groups</li></ul></span>",
      "ACCOUNTNAME":{
        "TOOLTIP":"User-defined account name for your BitBucket Cloud access.",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
      },
      "HOSTURL":{
        "TOOLTIP":"BitBucket Cloud (SaaS) Web URL. It is usually https://bitbucket.org",
        "VALIDATION_MESSAGE":{
          "required":"Host URL cannot be empty",
          "invalidUrl": "Host URL is invalid"
        }
      },
      "APIURL":{
        "TOOLTIP":"Bitbucket API base URL. Eg. https://api.github.com",
        "VALIDATION_MESSAGE":{
          "required":"API URL cannot be empty",
          "invalidUrl": "API URL is invalid"
        }
      },
      "AUTHENTICATIONTYPE":{
        "TOOLTIP":"Select one of the available options. If you are unsure, consult your BitBucket administrator to determine which authentication mechanism is used.",
        "VALIDATION_MESSAGE":{}
      },
      "TOKEN":{
        "TOOLTIP":"The user's access token. This token is obtained from the Bitbucket user profile page.",
        "VALIDATION_MESSAGE":{
          "required":"Token cannot be empty"
        }
      },
      "USERNAME":{
        "TOOLTIP":"The BitBucket Cloud Service username",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "User Name cannot contain special characters other than - and _",
          "cannotContainSpace":"User Name cannot contain space",
          "required":"User Name cannot be empty",
          "startingFromNumber": "User Name cannot start with numbers"
        }
      },
      "PASSWORD":{
        "TOOLTIP":"The BitBucket Cloud Service password",
        "VALIDATION_MESSAGE":{
          "required":"Password cannot be empty"
        }
      },
      "SPINNAKERTOGGLE":{
        "TOOLTIP":"Switch On this toggle to configure the resource in a gitops enabled Spinnaker instance",
        "VALIDATION_MESSAGE":{}
      }
    },
    "BITBUCKET_SERVER":{
      "HEADER": "Bitbucket Server",
      "BODY":"<span><p>BitBucket Server integration can be used as a datasource for Approval Gate as well as to configure Spinnaker for BitBucket Server.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account Name</strong>: User-defined account name for your BitBucket Cloud access. <span class='noBr'>(Example: opsmx-bitbucket)</span></li><li><strong>Host URL</strong>: BitBucket Cloud (SaaS) Web URL. <span class='noBr'> It is usually https://bitbucket.org</span></li><li><strong>Authentication Type</strong>: Select one of the available options. If you are unsure, consult your BitBucket administrator to determine which authentication mechanism is used.</li><li><strong>Anonymous</strong>: No username or password is used. Access identity is anonymous.</li><li><strong>Token</strong>: The user's username and access token This token is obtained from the Bitbucket user profile page. You can find <a href='https://confluence.atlassian.com/bitbucketserver/personal-access-tokens-939515499.html' target='_blank'>here</a> how to generate personal access tokens. <span class='noBr'>(Example: DjpMgHmwqUnIvvmljFgqGQ)</span></li><li><strong>Username & Password </strong>: Accepts the user's username and password to connect to Bitbucket. Deprecated and not recommended.</li><li><strong>User Name</strong>: Bitbucket Server User Name</li><li><strong>Password</strong>: Bitbucket Server Password</li><li><strong>Connect to Spinnaker</strong>: Toggle on to propagate the change into the CD Tool.</li><li><strong>Permissions</strong>: Enable/disable access to the Bitbucket Server account in Autopilot to specific user groups</li></ul></span>",
      "ACCOUNTNAME":{
        "TOOLTIP":"User-defined account name for your BitBucket Cloud access.",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
      },
      "HOSTURL":{
        "TOOLTIP":"BitBucket Cloud (SaaS) Web URL. It is usually https://bitbucket.org",
        "VALIDATION_MESSAGE":{
          "required":"Host URL cannot be empty",
          "invalidUrl": "Host URL is invalid"
        }
      },
      "AUTHENTICATIONTYPE":{
        "TOOLTIP":"Select one of the available options. If you are unsure, consult your BitBucket administrator to determine which authentication mechanism is used.",
        "VALIDATION_MESSAGE":{}
      },
      "TOKEN":{
        "TOOLTIP":"The user's access token. This token is obtained from the Bitbucket user profile page.",
        "VALIDATION_MESSAGE":{
          "required":"Token cannot be empty"
        }
      },
      "USERNAME":{
        "TOOLTIP":"The BitBucket Server username",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "User Name cannot contain special characters other than - and _",
          "cannotContainSpace":"User Name cannot contain space",
          "required":"User Name cannot be empty",
          "startingFromNumber": "User Name cannot start with numbers"
        }
      },
      "PASSWORD":{
        "TOOLTIP":"The BitBucket server password",
        "VALIDATION_MESSAGE":{
          "required":"Password cannot be empty"
        }
      },
      "SPINNAKERTOGGLE":{
        "TOOLTIP":"Switch On this toggle to configure the resource in a gitops enabled Spinnaker instance",
        "VALIDATION_MESSAGE":{}
      }
    },
    "DOCKERHUB":{
      "HEADER": "Docker Registry",
      "BODY":"<span><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account Name</strong>: User-defined account name for your Docker registry access.</li><li><strong>Registry URL</strong>: The registry URL from which you want to pull and deploy images. <span class='noBr'> DockerHub example: https://hub.docker.com</span></li><li><strong>Email</strong>: Users docker registry email. If no value is specified, the default value of fake.email@spinnaker.io will be used.</li><li><strong>Repositories</strong>: An optional list of repositories to cache images from. If not provided, Spinnaker will try to read the list of accessible repositories from the registries _catalog endpoint. <span class='noBr'> Example: library/ubuntu (Public repositories are prefixed with library/)</span></li><li><strong>Group Membership</strong>: Select an authentication type that corresponds to the connection credential parameter.</li><li><strong>Connect to Spinnaker</strong>: Toggle on to propagate the change into the CD Tool.</li></ul></span>",
      "ACCOUNTNAME":{
        "TOOLTIP":"User-defined account name for your Docker registry access.",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
      },
      "URL":{
        "TOOLTIP":"The registry URL from which you want to pull and deploy images. DockerHub example: https://hub.docker.com",
        "VALIDATION_MESSAGE": {
      "required": "Registry URL cannot be empty"
    }
      },
    "EMAIL":{
      "TOOLTIP":"Users docker registry email. If no value is specified, the default value of fake.email@spinnaker.io will be used."
    },
    "REPOSITORIES":{
    "TOOLTIP":"An optional list of repositories to cache images from. If not provided, Spinnaker will try to read the list of accessible repositories from the registries _catalog endpoint. Example: library/ubuntu (Public repositories are prefixed with library/)"
    },
    "GROUPMEMBERSHIP":{
      "TOOLTIP":""
      },
      "AUTHENTICATIONTYPE":{
        "TOOLTIP":"Select an authentication type that corresponds to the connection credential parameter.",
        "VALIDATION_MESSAGE":{}
      },
      "TOKEN":{
        "TOOLTIP":"The token of the Docker Registry user to authenticate as",
        "VALIDATION_MESSAGE":{
          "required":"Token cannot be empty"
        }
      },
      "USERNAME":{
        "TOOLTIP":"The username of the Docker Registry user to authenticate as",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "User Name cannot contain special characters other than - and _",
          "cannotContainSpace":"User Name cannot contain space",
          "required":"User Name cannot be empty",
          "startingFromNumber": "User Name cannot start with numbers"
        }
      },
      "PASSWORD":{
        "TOOLTIP":"The password of the Docker Registry user to authenticate as",
        "VALIDATION_MESSAGE":{
          "required":"Password cannot be empty"
        }
      },
      "HOSTURL":{
        "TOOLTIP":"Docker Registry Host URL",
        "VALIDATION_MESSAGE":{
          "required":"Host URL cannot be empty",
          "invalidUrl": "Host URL is invalid"
        }
      },
      "SPINNAKERTOGGLE":{
        "TOOLTIP":"Switch On this toggle to configure the resource in a gitops enabled Spinnaker instance",
        "VALIDATION_MESSAGE":{}
      }
    },
    "OCR":{
      "HEADER": "Generic Docker Registries (ACR, Quay, JFrog)",
      "BODY":"<span><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account Name</strong>: User-defined account name for your GCR Docker registry access.</li><li><strong>Registry URL</strong>: The registry URL from which you want to pull and deploy images. <span class='noBr'> For example: https://quay.io - RedHat quay.io</span></li><li><strong>Email</strong>: Users docker registry email. If no value is specified, the default value of fake.email@spinnaker.io will be used.</li><li><strong>Repositories</strong>: An optional list of repositories to cache images from. If not provided, Spinnaker will try to read the list of accessible repositories from the registries _catalog endpoint. <span class='noBr'> Example: library/ubuntu (Public repositories are prefixed with library/)</span></li><li><strong>Authentication Type</strong>: Select an authentication type that corresponds to the connection credential parameter.</li><li><strong>Connect to Spinnaker</strong>: Toggle on to propagate the change into the CD Tool.</li></ul></span>",
      "ACCOUNTNAME":{
        "TOOLTIP":"User-defined account name for your GCR Docker registry access.",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
      },
      "REPOSITORIES":{
        "TOOLTIP":"An optional list of repositories to cache images from. If not provided, Spinnaker will try to read the list of accessible repositories from the registries _catalog endpoint. Example: library/ubuntu (Public repositories are prefixed with library/)",
        "VALIDATION_MESSAGE":{
          "cannotContainSpace":"Repository cannot contain space",
          "startingFromNumber": "Repository cannot start with numbers"
        }
      },
      "URL":{
        "TOOLTIP":"The registry URL from which you want to pull and deploy images. For example: https://quay.io - RedHat quay.io",
        "VALIDATION_MESSAGE":{
          "required":"Registry URL cannot be empty"
        }
      },
      "EMAIL":{
        "TOOLTIP":"Users docker registry email. If no value is specified, the default value of fake.email@spinnaker.io will be used."
      },
      "GROUPMEMBERSHIP":{
        "TOOLTIP":"A user must be a member of at least one specified group in order to make changes to this account’s cloud resources",
        "VALIDATION_MESSAGE":{
          "cannotContainSpace":"Repository cannot contain space"
        }
      },
      "AUTHENTICATIONTYPE":{
        "TOOLTIP":"Select an authentication type that corresponds to the connection credential parameter.",
        "VALIDATION_MESSAGE":{}
      },
      "TOKEN":{
        "TOOLTIP":"Your docker registry token",
        "VALIDATION_MESSAGE":{
          "required":"Token cannot be empty"
        }
      },
      "PASSWORD":{
        "TOOLTIP":"Your docker registry password",
        "VALIDATION_MESSAGE":{
          "required":"Password cannot be empty"
        }
      },
      "USERNAME":{
        "TOOLTIP":"Your docker registry username",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "User Name cannot contain special characters other than - and _",
          "cannotContainSpace":"User Name cannot contain space",
          "required":"User Name cannot be empty",
          "startingFromNumber": "User Name cannot start with numbers"
        }
      },
      "HOSTURL":{
        "TOOLTIP":"Container Registry Host URL",
        "VALIDATION_MESSAGE":{
          "required":"Host URL cannot be empty",
          "invalidUrl": "Host URL is invalid"
        }
      },
      "SPINNAKERTOGGLE":{
        "TOOLTIP":"Toggle on to propagate the change into the CD Tool."
      }
    },
    "GITHUB":{
      "HEADER": "GitHub",
      "BODY":"<span><p>GITHUB integration can be used as a datasource for Approval Gate as well as to configure Spinnaker for GitHub.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account Name</strong>: User-defined account name for your GitHub access.<span class='noBr'>(Example: opsmx-github)</span></li><li><strong>URL</strong>: Github's host address, such as https://github.com</li><li><strong>API URL</strong>: Github's API endpoint host address, <span class='noBr'>such as https://api.github.com</span></li><li><strong>Token</strong>: GitHub personal access token. You can find <a href='https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token' target='_blank'>here</a> how to generate personal access tokens. <span class='noBr'>(Example: ghp_ln1eJK4yuomnY6JREp72IDJC4Hq6Sm)</span></li><li><strong>User Name</strong>: The GitHub username</li><li><strong>Connect to Spinnaker</strong>: Toggle to configure Spinnaker for GitHub</li><li><strong>Permissions</strong>: Enable/disable access to the GITHUB account in Autopilot to specific user groups</li></ul></span>",
      "ACCOUNTNAME":{
        "TOOLTIP":"User-defined account name for your GitHub access.",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
      },
      "HOSTURL":{
        "TOOLTIP":"Github's host address, such as https://github.com",
        "VALIDATION_MESSAGE":{
          "required":"Host URL cannot be empty",
          "invalidUrl": "Host URL is invalid"
        }
      },
      "URL":{
        "TOOLTIP":"Github's API endpoint host address, such as https://api.github.com",
        "VALIDATION_MESSAGE":{
          "required":"API URL cannot be empty",
          "invalidUrl": "API URL is invalid"
        }
      },
      "TOKEN":{
        "TOOLTIP":"The user's token",
        "VALIDATION_MESSAGE":{
          "required":"Token cannot be empty"
        }
      },
      "USERNAME":{
        "TOOLTIP":"The GitHub username",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "User Name cannot contain special characters other than - and _",
          "cannotContainSpace":"User Name cannot contain space",
          "required":"User Name cannot be empty",
          "startingFromNumber": "User Name cannot start with numbers"
        }
      },
      "SPINNAKERTOGGLE":{
        "TOOLTIP":"Switch On this toggle to configure the resource in a gitops enabled Spinnaker instance",
        "VALIDATION_MESSAGE":{}
      }
    },
    "GITLAB":{
      "HEADER": "GitLab",
      "BODY":"<span><li><strong>Account Name</strong>: User-defined account name for your GitLab access.</li><li><strong>Host URL</strong>: GitLab's host address, such as https://gitlab.com</li><li><strong>Username</strong>: The GitLab server username </li><li><strong>Token</strong>: The user's personal access token. Please refer <a href='https://docs.gitlab.com/ee/user/profile/personal_access_tokens.html' target='_blank'>this document</a> for generating tokens.</li></span>",
      "ACCOUNTNAME":{
        "TOOLTIP":"User-defined account name for your GitLab access.",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
      },
      "HOSTURL":{
        "TOOLTIP":"GitLab's host address, such as https://gitlab.com",
        "VALIDATION_MESSAGE":{
          "required":"Host URL cannot be empty",
          "invalidUrl": "Host URL is invalid"
        }
      },
      "APIBASEURL":{
        "TOOLTIP":"",
        "VALIDATION_MESSAGE":{
          "required":"API URL cannot be empty",
          "invalidUrl": "API URL is invalid"
        }
      },
      "AUTHENTICATIONTYPE":{
        "TOOLTIP":"Select how the external resource confirms the user credentials",
        "VALIDATION_MESSAGE":{}
      },
      "TOKEN":{
        "TOOLTIP":"GitLab token",
        "VALIDATION_MESSAGE":{
          "required":"Token cannot be empty"
        }
      },
      "SPINNAKERTOGGLE":{
        "TOOLTIP":"Switch On this toggle to configure the resource in a gitops enabled Spinnaker instance",
        "VALIDATION_MESSAGE":{}
      },
      "USERNAME":{
        "TOOLTIP":"The GitLab server username"
      }
    },
    "GITREPO":{
      "HEADER": "Git Repo",
      "BODY": "<span><li><strong>Account Name</strong>: User-defined account name for your Git Repo access.</li><li><strong>API URL</strong>: The API URL of the Git repository URL.<p><strong>Examples</strong>:</p><ul><li>https://api.github.com</li><li>https://api.bitbucket.org/2.0/respositories</li><li>https://gitlab.com/api/v4/</li></ul></li><li><strong>Authentication Type</strong>: Select an authentication type that corresponds to the connection credential parameter. Recommended using the user token method.</li></span>",
      "ACCOUNTNAME":{
        "TOOLTIP":"User-defined account name for your Git Repo access.",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
      },
      "APIURL":{
        "TOOLTIP":"<div><div>The API URL of the Git repository URL.</div><strong>Examples</strong>:<ul><li>https://api.github.com</li><li>https://api.bitbucket.org/2.0/respositories</li><li>https://gitlab.com/api/v4/</li></ul></div>",
        "VALIDATION_MESSAGE":{
          "required":"API URL cannot be empty",
          "invalidUrl": "API URL is invalid"
        }
      },
      "DEPLOYMENT":{
        "TOOLTIP":"This Halyard deployment will be used for Account creation / update",
        "VALIDATION_MESSAGE":{
          "required":"deployment URL cannot be empty",
          "invalidUrl": "deployment URL is invalid"
        }
      },
      "AUTHENTICATIONTYPE":{
        "TOOLTIP":"Select an authentication type that corresponds to the connection credential parameter. Recommended using the user token method.",
        "VALIDATION_MESSAGE":{}
      },
      "URL":{
        "TOOLTIP":"",
        "VALIDATION_MESSAGE":{
          "required":"API URL cannot be empty",
          "invalidUrl": "API URL is invalid"
        }
      },
      "TOKEN":{
        "TOOLTIP":"Git token",
        "VALIDATION_MESSAGE":{
          "required":"Token cannot be empty"
        }
      },
      "PASSWORD":{
        "TOOLTIP":"Git password",
        "VALIDATION_MESSAGE":{
          "required":"Password cannot be empty"
        }
      },
      "USERNAME":{
        "TOOLTIP":"Git username",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "User Name cannot contain special characters other than - and _",
          "cannotContainSpace":"User Name cannot contain space",
          "required":"User Name cannot be empty",
          "startingFromNumber": "User Name cannot start with numbers"
        }
      },
      "SPINNAKERTOGGLE":{
        "TOOLTIP":"Switch On this toggle to configure the resource in a gitops enabled Spinnaker instance",
        "VALIDATION_MESSAGE":{}
      }
    },
    "HELM":{
      "HEADER": "Helm",
      "BODY": "<span><li><strong>Account Name</strong>: User-defined account name for target Helm repository access.</li><li><strong>Repository</strong>: Helm Chart Repository’s HTTP endpoint.</li><li><strong>Authentication Type</strong>: Select an authentication type that corresponds to the connection credential parameter.</li><li><strong>Connect to Spinnaker</strong>: Toggle ON to propagate the change to Spinnaker Toggle on to propagate the change into the CD Tool.</li></span>",
      "ACCOUNTNAME":{
        "TOOLTIP":"User-defined account name for target Helm repository access",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
      },
      "REPOSITORY":{
        "TOOLTIP":"Helm Chart Repository’s HTTP endpoint",
        "VALIDATION_MESSAGE":{
          "required":"Repository cannot be empty",
          "invalidUrl": "Repository URL is invalid"
        }
      },
      "DEPLOYMENT":{
        "TOOLTIP":"This Halyard deployment will be used for Account creation / update",
        "VALIDATION_MESSAGE":{
        }
      },
      "AUTHENTICATIONTYPE":{
        "TOOLTIP":"Select an authentication type that corresponds to the connection credential parameter.",
        "VALIDATION_MESSAGE":{}
      },
      "TOKEN":{
        "TOOLTIP":"",
        "VALIDATION_MESSAGE":{
          "required":"Token cannot be empty"
        }
      },
      "USERNAME":{
        "TOOLTIP":"User Name",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "User Name cannot contain special characters other than - and _",
          "cannotContainSpace":"User Name cannot contain space",
          "required":"User Name cannot be empty",
          "startingFromNumber": "User Name cannot start with numbers"
        }
      },
      "PASSWORD": {
        "TOOLTIP": "Password",
        "VALIDATION_MESSAGE":{
          "required" : "Password cannot be empty"
        }
      },
      "PASSWORDCOMMAND": {
        "TOOLTIP": "Command to retrieve docker token/password, commands must be available in environment",
        "VALIDATION_MESSAGE":{
        }
      },
      "FILE": {
        "TOOLTIP": "The path to a file containing your docker password in plaintext (not a docker/config.json file)",
        "VALIDATION_MESSAGE": {
        }
      },
      "SPINNAKERTOGGLE":{
        "TOOLTIP":"Toggle on to propagate the change into the CD Tool.",
        "VALIDATION_MESSAGE":{}
      }
    },
    "HTTP":{
      "HEADER": "Http",
      "BODY": "<span><li><strong>Account Name</strong>: User-defined account name for HTTP protocol-based artifacts</li><li><strong>Authentication Type</strong>: Select an authentication type that corresponds to the connection credential parameter.</li><li><strong>Connect to Spinnaker</strong>: Toggle on to propagate the change into the CD Tool.</li></span>",
      "ACCOUNTNAME":{
        "TOOLTIP":"User-defined account name for HTTP protocol-based artifacts",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
      },
  
      "AUTHENTICATIONTYPE":{
        "TOOLTIP":"Select an authentication type that corresponds to the connection credential parameter.",
        "VALIDATION_MESSAGE":{}
      },
      "TOKEN":{
        "TOOLTIP":"",
        "VALIDATION_MESSAGE":{
          "required":"Token cannot be empty"
        }
      },
      "USERNAME":{
        "TOOLTIP":"HTTP basic auth User Name",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "User Name cannot contain special characters other than - and _",
          "cannotContainSpace":"User Name cannot contain space",
          "required":"User Name cannot be empty",
          "startingFromNumber": "User Name cannot start with numbers"
        }
      },
      "PASSWORD": {
        "TOOLTIP": "Password",
        "VALIDATION_MESSAGE":{
        }
      },
      "PASSWORDCOMMAND": {
        "TOOLTIP": "Command to retrieve docker token/password, commands must be available in environment",
        "VALIDATION_MESSAGE":{
        }
      },
      "FILE": {
        "TOOLTIP": "The path to a file containing your docker password in plaintext (not a docker/config.json file)",
        "VALIDATION_MESSAGE": {
        }
      },
      "SPINNAKERTOGGLE":{
        "TOOLTIP":"Toggle on to propagate the change into the CD Tool.",
        "VALIDATION_MESSAGE":{}
      }
    },
    "GCS":{
      "HEADER": "GCS",
      "BODY": "<span><p><strong>Fields</strong>:</p><ul class='helpTextUl'></ul><li><strong>Account Name</strong>: User-defined account name for your Google Cloud Storage access.</li><li><strong>Authentication Type</strong>: Select an authentication type that corresponds to the connection credential parameter. </li><li><strong>Json-Key file</strong>: Configures Google service account’s json file </li><li><strong>Connect to Spinnaker</strong>: Toggle on to propagate the change into the CD Tool. </li></ul></span>",
      "ACCOUNTNAME":{
        "TOOLTIP":"User-defined account name for your Google Cloud Storage access.",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
      },
      "AUTHENTICATIONTYPE":{
        "TOOLTIP":"Select an authentication type that corresponds to the connection credential parameter.",
        "VALIDATION_MESSAGE":{}
      },
      "FILE": {
        "TOOLTIP": "Configures Google service account’s json file",
        "VALIDATION_MESSAGE": {
        }
      },
      "SPINNAKERTOGGLE":{
        "TOOLTIP":"Toggle on to propagate the change into the CD Tool.",
        "VALIDATION_MESSAGE":{}
      }
    },
    "ECR":{
      "HEADER": "ECR",
      "BODY": "<span><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account Name</strong>: User-defined account name for your ECR Docker registry access.</li><li><strong>Registry URL</strong>: The registry URL from which you want to pull and deploy images. <span class='noBr'> For example:https://aws_account_id.dkr.ecr.region.amazonaws.com</span></li><li><strong>Email</strong>: Users docker registry email. If no value is specified, the default value of fake.email@spinnaker.io will be used.</li><li><strong>Repositories</strong>: An optional list of repositories to cache images from. If not provided, Spinnaker will try to read the list of accessible repositories from the registries _catalog endpoint. <span class='noBr'> Example: library/ubuntu (Public repositories are prefixed with library/)</span></li><li><strong>Authentication Type</strong>: Select an authentication type that corresponds to the connection credential parameter.</li><li><strong>Connect to Spinnaker</strong>: Toggle on to propagate the change into the CD Tool.</li></ul></span>",
      "ACCOUNTNAME":{
        "TOOLTIP":"User-defined account name for your ECR Docker registry access.",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
      },
      "REPOSITORIES":{
        "TOOLTIP":"Users docker registry email. If no value is specified, the default value of fake.email@spinnaker.io will be used.",
        "VALIDATION_MESSAGE":{
          "cannotContainSpace":"Repository cannot contain space",
          "startingFromNumber": "Repository cannot start with numbers"
        }
      },
      "URL":{
        "TOOLTIP":"The registry URL from which you want to pull and deploy images. For example:https://aws_account_id.dkr.ecr.region.amazonaws.com",
        "VALIDATION_MESSAGE":{
          "required" : "Registry URL cannot be empty"
        }
      },
      "GROUPMEMBERSHIP":{
        "TOOLTIP":"A user must be a member of at least one specified group in order to make changes to this account’s cloud resources",
        "VALIDATION_MESSAGE":{
          "cannotContainSpace":"Repository cannot contain space"
        }
      },
      "REGION": {
        "TOOLTIP": "AWS region"
      },
      "EMAIL":{
        "TOOLTIP":"An optional list of repositories to cache images from. If not provided, Spinnaker will try to read the list of accessible repositories from the registries _catalog endpoint. Example: library/ubuntu (Public repositories are prefixed with library/)",
        "VALIDATION_MESSAGE":{
          "email":"Email Id is invalid",
          "required":"Email Id cannot be empty"
        }
      },
      "AUTHENTICATIONTYPE":{
        "TOOLTIP":"Select an authentication type that corresponds to the connection credential parameter.",
        "VALIDATION_MESSAGE":{}
      },
      "TOKEN":{
        "TOOLTIP":"",
        "VALIDATION_MESSAGE":{
          "required":"Token cannot be empty"
        }
      },
      "USERNAME":{
        "TOOLTIP":"Your docker registry username",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "User Name cannot contain special characters other than - and _",
          "cannotContainSpace":"User Name cannot contain space",
          "required":"User Name cannot be empty",
          "startingFromNumber": "User Name cannot start with numbers"
        }
      },
      "PASSWORD": {
        "TOOLTIP": "Your docker registry password",
        "VALIDATION_MESSAGE":{
        }
      },
      "PASSWORDCOMMAND": {
        "TOOLTIP": "Command to retrieve docker token/password, commands must be available in environment",
        "VALIDATION_MESSAGE":{
          "required" : "Password-command cannot be empty"
        }
      },
      "FILE": {
        "TOOLTIP": "The path to a file containing your docker password in plaintext (not a docker/config.json file)",
        "VALIDATION_MESSAGE": {
        }
      },
      "SPINNAKERTOGGLE":{
        "TOOLTIP":"Toggle on to propagate the change into the CD Tool.",
        "VALIDATION_MESSAGE":{}
      }
    },
    "PUBSUB":{
      "HEADER": "PUBSUB",
      "BODY": "<span><li><strong>Account Name</strong>: User-defined account name for your Google Cloud Pub/Sub access.</li></span>",
      "ACCOUNTNAME":{
        "TOOLTIP":"User-defined account name for your Google Cloud Pub/Sub access.",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
      },
      "PROJECTNAME": {
        "TOOLTIP": "The name of the GCP project your subscription lives in",
        "VALIDATION_MESSAGE":{
          "cannotContainSpace":"Project Name cannot contain space",
          "required":"Project Name cannot be empty"
        }
      },
      "SUBSCRIPTIONNAME": {
        "TOOLTIP": "The name of the subscription to listen to. This identifier does not include the name of the project, and must already be configured for Spinnaker to work.",
        "VALIDATION_MESSAGE":{
          "cannotContainSpace":"Subscription Name cannot contain space",
          "required":"Subscription Name cannot be empty"
        }
      },
      "MESSAGEFORMAT": {
        "TOOLTIP":"Supporting Message Formats: GCB,GCS,GCR,CUSTOM",
        "VALIDATION_MESSAGE": {}
      },
      "TEMPLATEFILE": {
        "TOOLTIP":"Applicable only for CUSTOM message format",
        "VALIDATION_MESSAGE": {}
      },
      "AUTHENTICATIONTYPE":{
        "TOOLTIP":"Select how the external resource confirms the user credentials",
        "VALIDATION_MESSAGE":{}
      },
      "FILE": {
        "TOOLTIP": "JSON service account that Spinnaker will use as credentials",
        "VALIDATION_MESSAGE": {
        }
      },
      "SPINNAKERTOGGLE":{
        "TOOLTIP":"Switch On this toggle to configure the resource in a gitops enabled Spinnaker instance",
        "VALIDATION_MESSAGE":{}
      }
    },
    "GCB":{
      "HEADER": "GCB",
      "BODY": "",
      "ACCOUNTNAME":{
        "TOOLTIP":"The name of the account to operate on",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
      },
      "PROJECTNAME": {
        "TOOLTIP": "The name of the GCP project in which to trigger and monitor builds",
        "VALIDATION_MESSAGE":{
          "cannotContainSpace":"Project Name cannot contain space",
          "required":"Project Name cannot be empty"
        }
      },
      "SUBSCRIPTIONNAME": {
        "TOOLTIP": "The name of the PubSub subscription on which to listen for build changes",
        "VALIDATION_MESSAGE":{
          "cannotContainSpace":"Subscription Name cannot contain space",
          "required":"Subscription Name cannot be empty"
        }
      },
      "AUTHENTICATIONTYPE":{
        "TOOLTIP":"Select how the external resource confirms the user credentials",
        "VALIDATION_MESSAGE":{}
      },
      "FILE": {
        "TOOLTIP": "JSON service account that Spinnaker will use as credentials",
        "VALIDATION_MESSAGE": {
        }
      },
      "USERNAME":{
        "TOOLTIP":"GCB User Name",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "User Name cannot contain special characters other than - and _",
          "cannotContainSpace":"User Name cannot contain space",
          "required":"User Name cannot be empty",
          "startingFromNumber": "User Name cannot start with numbers"
        }
      },
      "PASSWORD": {
        "TOOLTIP": "Password",
        "VALIDATION_MESSAGE":{
        }
      },
      "SPINNAKERTOGGLE":{
        "TOOLTIP":"Switch On this toggle to configure the resource in a gitops enabled Spinnaker instance",
        "VALIDATION_MESSAGE":{}
      }
    },
    "GCR":{
      "HEADER": "GCR",
      "BODY": "<span><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account Name</strong>: User-defined account name for your GCR Docker registry access.</li><li><strong>Registry URL</strong>: The registry URL from which you want to pull and deploy images. <span class='noBr'> For example: https://gcr.io - Global GCR, https://[us|eu|asia].gcr.io - Regional GCR</span></li><li><strong>Email</strong>: Users docker registry email. If no value is specified, the default value of fake.email@spinnaker.io will be used.</li><li><strong>Repositories</strong>: An optional list of repositories to cache images from. If not provided, Spinnaker will try to read the list of accessible repositories from the registries _catalog endpoint. <span class='noBr'> Example: library/ubuntu (Public repositories are prefixed with library/)</span></li><li><strong>Authentication Type</strong>: Select an authentication type that corresponds to the connection credential parameter.</li><li><strong>Connect to Spinnaker</strong>: Toggle on to propagate the change into the CD Tool.</li></ul></span>",
      "ACCOUNTNAME":{
        "TOOLTIP":"User-defined account name for your GCR Docker registry access.",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
      },
      "AUTHENTICATIONTYPE":{
        "TOOLTIP":"Select an authentication type that corresponds to the connection credential parameter.",
        "VALIDATION_MESSAGE":{}
      },
      "REPOSITORIES":{
        "TOOLTIP":"An optional list of repositories to cache images from. If not provided, Spinnaker will try to read the list of accessible repositories from the registries _catalog endpoint. Example: library/ubuntu (Public repositories are prefixed with library/)",
        "VALIDATION_MESSAGE":{
          "cannotContainSpace":"Repository cannot contain space",
          "startingFromNumber": "Repository cannot start with numbers"
        }
      },
      "REQUIREDGROUPMEMBERSHIP":{
        "TOOLTIP":"A user must be a member of at least one specified group in order to make changes to this account’s cloud resources",
        "VALIDATION_MESSAGE":{
          "cannotContainSpace":"Repository cannot contain space"
        }
      },
      "EMAIL":{
        "TOOLTIP":"Users docker registry email. If no value is specified, the default value of fake.email@spinnaker.io will be used.",
        "VALIDATION_MESSAGE":{
          "email":"Email Id is invalid",
          "required":"Email Id cannot be empty"
        }
      },
      "URL":{
        "TOOLTIP":"The registry URL from which you want to pull and deploy images. For example: https://gcr.io - Global GCR, https://[us|eu|asia].gcr.io - Regional GCR",
        "VALIDATION_MESSAGE":{
          "required":"Registry URL cannot be empty",
          "invalidUrl": "Registry URL is invalid"
        }
      },
      "TOKEN":{
        "TOOLTIP":"",
        "VALIDATION_MESSAGE":{
          "required":"Token cannot be empty"
        }
      },
      "USERNAME":{
        "TOOLTIP":"GCR User Name",
        "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "User Name cannot contain special characters other than - and _",
          "cannotContainSpace":"User Name cannot contain space",
          "required":"User Name cannot be empty",
          "startingFromNumber": "User Name cannot start with numbers"
        }
      },
      "PASSWORD": {
        "TOOLTIP": "Your docker registry password",
        "VALIDATION_MESSAGE":{
          "required" : "Password cannot be empty"
        }
      },
      "PASSWORDCOMMAND": {
        "TOOLTIP": "Command to retrieve docker token/password, commands must be available in environment",
        "VALIDATION_MESSAGE":{
          "required" : "Password-command cannot be empty"
        }
      },
      "FILE": {
        "TOOLTIP": "The path to a file containing your docker password in plaintext (not a docker/config.json file)",
        "VALIDATION_MESSAGE": {
        }
      },
      "SPINNAKERTOGGLE":{
        "TOOLTIP":"Toggle on to propagate the change into the CD Tool.",
        "VALIDATION_MESSAGE":{}
      }
    },
    "BAMBOO":{
        "HEADER": "Bamboo CI",
        "BODY":" <span><p>Bamboo CI integration can be used as a datasource for Approval Gate.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'> <li><strong>Name</strong>: User defined name for the Bamboo CI Account <span class='noBr'>(Example: opsmx-bamboo)</span></li><li><strong>Endpoint</strong>: Bamboo CI URL <span class='noBr'>(Example: https://xyz.mybamboo.com)</span></li><li><strong>Token</strong>: Bamboo CI personal access token. You can find <a href='https://confluence.atlassian.com/bamboo/personal-access-tokens-976779873.html' target='_blank'>here</a> how to generate personal access tokens. <span>(Example: YmFrwqw0w9r90skfsOk9wcdd014p98kklw==)</span></li><li><strong>User Name</strong>: Bamboo CI User Name</li><li><strong>Password</strong>: Bamboo CI Password</li><li><strong>Permissions</strong>: Enable/disable access to the Bamboo CI account in Autopilot to specific usergroups</li></ul></span>",
        "ACCOUNTNAME":{
          "TOOLTIP":"The name of the account to operate on",
          "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
        },
        "ENDPOINT":{
          "TOOLTIP":"Bamboo URL",
          "VALIDATION_MESSAGE":{
            "required":"Bamboo End Point cannot be empty",
            "invalidUrl": "Bamboo End Point URL is invalid"
          }
        },
        "AUTHENTICATIONTYPE":{
          "TOOLTIP":"Select how the external resource confirms the user credentials",
          "VALIDATION_MESSAGE":{}
        },
        "TOKEN":{
          "TOOLTIP":"Your Bamboo token",
          "VALIDATION_MESSAGE":{
            "required":"Token cannot be empty"
          }
        },
        "USERNAME":{
          "TOOLTIP":"Your Bamboo username",
          "VALIDATION_MESSAGE":{
            "noSpecialCharacters": "User Name cannot contain special characters other than - and _",
            "cannotContainSpace":"User Name cannot contain space",
            "required":"User Name cannot be empty",
            "startingFromNumber": "User Name cannot start with numbers"
          }
        },
        "PASSWORD":{
          "TOOLTIP":"Your Bamboo password",
          "VALIDATION_MESSAGE":{
            "required":"Password cannot be empty"
          }
        }
      },
      "JENKINS":{
        "HEADER":"Jenkins",
        "BODY":"<span><p>Jenkins integration can be used as a datasource for Approval Gate as well as to configure Spinnaker for Jenkins.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account Name</strong>: User-defined account name for your Jenkins access. <span class='noBr'>(Example: opsmx-jenkins)</span></li><li><strong>Host URL</strong>: Jenkins host address, <span class='noBr'>such as https://jenkins.opsmx.net</span></li><li><strong>Authentication Type</strong>: Select an authentication type that corresponds to the connection credential parameter. It is preferable to use token authentication with username and token. </li><li><strong>Token</strong>: Jenkins personal access token. You can find <a href='https://www.jenkins.io/doc/book/using/using-credentials/' target='_blank'>here</a> how to generate personal access tokens. <span>(Example: 77d67609a841b1811a114b7fbfa109b3c2)</span></li><li><strong>CSRF</strong>: Recommended to toggle on the CSRF (Cross-Site Request Forgery) flag</li><li><strong>User Name</strong>: Jenkins User Name</li><li><strong>Password</strong>: Jenkins Password</li><li><strong>Connect to Spinnaker</strong>: Toggle to configure Spinnaker for Jenkins</li><li><strong>Permissions</strong>: Enable/disable access to the Jenkins account in Autopilot to specific user groups</li></ul></span>",
        "ACCOUNTNAME":{
          "TOOLTIP":"User-defined account name for your Jenkins access.",
          "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
        },
        "HOSTURL":{
          "TOOLTIP":"Jenkins host address, such as https://jenkins.opsmx.net",
          "VALIDATION_MESSAGE":{
            "required":"Host URL cannot be empty",
            "invalidUrl": "Host URL is invalid"
          }
        },
        "AUTHENTICATIONTYPE":{
          "TOOLTIP":"Select an authentication type that corresponds to the connection credential parameter. It is preferable to use token authentication with username and token.",
          "VALIDATION_MESSAGE":{}
        },
        "CSRFFLAG":{
          "TOOLTIP":"Recommended to toggle on the CSRF (Cross-Site Request Forgery) flag.",
          "VALIDATION_MESSAGE":{}
        },
        "TOKEN":{
          "TOOLTIP":"Your Jenkins token",
          "VALIDATION_MESSAGE":{
            "required":"Token cannot be empty"
          }
        },
        "USERNAME":{
          "TOOLTIP":"Your Jenkins username",
          "VALIDATION_MESSAGE":{
            "noSpecialCharacters": "User Name cannot contain special characters other than - and _",
            "cannotContainSpace":"User Name cannot contain space",
            "required":"User Name cannot be empty",
            "startingFromNumber": "User Name cannot start with numbers"
          }
        },
        "PASSWORD":{
          "TOOLTIP":"Your Jenkins password",
          "VALIDATION_MESSAGE":{
            "required":"Password cannot be empty"
          }
        },
        "SPINNAKERTOGGLE":{
          "TOOLTIP":"Switch On this toggle to configure the resource in a gitops enabled Spinnaker instance",
          "VALIDATION_MESSAGE":{}
        }
      },
      "JIRA":{
        "HEADER": "Jira",
        "BODY":"",
        "ACCOUNTNAME":{
          "TOOLTIP":"User defined name for the Jira account",
          "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
        },
        "EMAIL":{
          "TOOLTIP":"Jira Email Id",
          "VALIDATION_MESSAGE":{
            "email":"Email Id is invalid",
            "required":"Email Id cannot be empty"
          }
        },
        "TOKEN":{
          "TOOLTIP":"Jira Personal Access Token",
          "VALIDATION_MESSAGE":{
            "required":"Token cannot be empty"
          }
        },
        "HOSTURL":{
          "TOOLTIP":"Jira Host URL",
          "VALIDATION_MESSAGE":{
            "required":"Host URL cannot be empty",
            "invalidUrl": "Host URL is invalid"
          }
        },
        "SPINNAKERTOGGLE":{
          "TOOLTIP":"Switch On this toggle to configure the resource in a gitops enabled Spinnaker instance",
          "VALIDATION_MESSAGE":{}
        }
      },
      "SERVICENOW":{
        "HEADER": "Service Now",
        "BODY":"<span><p>Service integration can be used to configure ServiceNow Custom stages in Spinnaker. In addition, it can also be used as a datasource for Approval Gate.</p><p><strong>Fields</strong>:</p><ul class='helpTextUl'><li><strong>Account Name</strong>: User defined name for the Service Account <span class='noBr'>(Example: myservicenow)</span></li><li><strong>Host URL</strong>: ServiceNow URL <span class='noBr'>(Example: https://servicenow.opsmx.com)</span></li><li><strong>User Name</strong>: ServiceNow User Name, for authentication</li><li><strong>Password</strong>: ServiceNow Password for the User who is authenticated</li><li><strong>Connect to Spinnaker</strong>: Toggle to configure Spinnaker for ServiceNow</li><li><strong>Permissions</strong>: Enable/disable access to the ServiceNow account in Autopilot to specific usergroups</li></ul></span>",
        "ACCOUNTNAME":{
          "TOOLTIP":"User defined name for the Service Now account",
          "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
        },
        "USERNAME":{
          "TOOLTIP":"Service Now User Name",
          "VALIDATION_MESSAGE":{
            "noSpecialCharacters": "User Name cannot contain special characters other than - and _",
            "cannotContainSpace":"User Name cannot contain space",
            "required":"User Name cannot be empty",
            "startingFromNumber": "User Name cannot start with numbers"
          }
        },
        "PASSWORD":{
          "TOOLTIP":"Service Now Password",
          "VALIDATION_MESSAGE":{
            "required":"Password cannot be empty"
          }
        },
        "HOSTURL":{
          "TOOLTIP":"Service Now Host URL",
          "VALIDATION_MESSAGE":{
            "required":"Host URL cannot be empty",
            "invalidUrl": "Host URL is invalid"
          }
        }
      }
      ,
      "APPDYNAMICS":{
        "HEADER": "APPDYNAMICS",
        "BODY":"",
        "ACCOUNTNAME":{
          "TOOLTIP":"User defined name for the APPDYNAMICS account",
          "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
        },
        "CONTROLLERHOST":{
          "TOOLTIP":"APPDYNAMICS Controller Host",
          "VALIDATION_MESSAGE":{
            "required":"Controller Host  cannot be empty",
            "invalidUrl": "Controller Host URL is invalid"
          }
        },
        "TEMPORARYACCESSTOKEN":{
          "TOOLTIP":"APPDYNAMICS Personal Temporary Access Token",
          "VALIDATION_MESSAGE":{
            "required":"Temporary Access Token cannot be empty"
          }
        }
      },
      "CLOUDWATCH":{
        "HEADER": "AWS-CLOUDWATCH",
        "BODY":"",
        "ACCOUNTNAME":{
          "TOOLTIP":"User defined name for the AWS-CLOUDWATCH account",
          "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
        },
        "ACCESS_ID":{
          "TOOLTIP":"AWS-CLOUDWATCH Access Key Id",
          "VALIDATION_MESSAGE":{
            "required":"Access Key Id cannot be empty"
          }
        },
        "SECRET_KEY":{
          "TOOLTIP":"AWS-CLOUDWATCH Secret Access Key",
          "VALIDATION_MESSAGE":{
            "required":"Secret Access Key cannot be empty"
          }
        }
      },
      "DATADOG":{
        "HEADER": "DATADOG",
        "BODY":"",
        "ACCOUNTNAME":{
          "TOOLTIP":"User defined name for the DATADOG account",
          "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
        },
        "API_KEY":{
          "TOOLTIP":"DATADOG Api Key",
          "VALIDATION_MESSAGE":{
            "required":"API key cannot be empty"
          }
        },
        "APPLICATION_KEY":{
          "TOOLTIP":"DATADOG Application Key",
          "VALIDATION_MESSAGE":{
            "required":"Application Key cannot be empty"
          }
        }
      },
      "DYNATRACE":{
        "HEADER": "Dynatrace",
        "BODY":"",
        "ACCOUNTNAME":{
          "TOOLTIP":"User defined name for the Dynatrace account",
          "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
        },
        "END_POINT":{
          "TOOLTIP":"Dynatrace URL",
          "VALIDATION_MESSAGE":{
            "required":"Endpoint Url cannot be empty",
            "invalidUrl": "Endpoint URL is invalid"
          }
        },
        "API_TOKEN":{
          "TOOLTIP":"Dynatrace Personal Access Token",
          "VALIDATION_MESSAGE":{
            "required":"Api Token cannot be empty"
          }
        }
      },
      "ELASTICSEARCH":{
        "HEADER": "Elasticsearch",
        "BODY":"<span><li><strong>Account Name</strong>: User-defined account name for your Elasticsearch access.</li><li><strong>Endpoint</strong>: Elasticsearch host address, from which you access the Elasticsearch</li><li><strong>Username</strong>: Elasticsearch username </li><li><strong>Password</strong>: Elasticsearch password</li><li><strong>Kibana Endpoint</strong>: Elasticsearch Kibana host address, from which you access the Elasticsearch Kibana</li><li><strong>Kibana username</strong>: Elasticsearch Kibana username</li><li><strong>Kibana Password</strong>: Elasticsearch Kibana password</li><span>",
        "ACCOUNTNAME":{
          "TOOLTIP":"User-defined account name for your Elasticsearch access.",
          "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
        },
        "ENDPOINT":{
          "TOOLTIP":"Elasticsearch host address, from which you access the Elasticsearch",
          "VALIDATION_MESSAGE":{
            "required":"Elastic End Point cannot be empty",
            "invalidUrl": "Elastic End Point URL is invalid"
          }
        },
        "USERNAME":{
          "TOOLTIP":"Elasticsearch username ",
          "VALIDATION_MESSAGE":{
            "noSpecialCharacters": "User Name cannot contain special characters other than - and _",
            "cannotContainSpace":"User Name cannot contain space",
            "startingFromNumber": "User Name cannot start with numbers"
          }
        },
        "PASSWORD":{
          "TOOLTIP":"Elasticsearch password",
          "VALIDATION_MESSAGE":{
            "required":"Password cannot be empty"
          }
        },
        "KIBANAENDPOINT":{
          "TOOLTIP":"Elasticsearch Kibana host address, from which you access the Elasticsearch Kibana",
          "VALIDATION_MESSAGE":{
            "required":"Kibana End Point cannot be empty",
            "invalidUrl": "Kibana End Point URL is invalid"
          }
        },
        "KIBANAUSERNAME":{
          "TOOLTIP":"Elasticsearch Kibana username",
          "VALIDATION_MESSAGE":{
            "noSpecialCharacters": "Kibana User Name cannot contain special characters other than - and _",
            "cannotContainSpace":"Kibana User Name cannot contain space",
            "required":"Kibana User Name cannot be empty",
            "startingFromNumber": "Kibana User Name cannot start with numbers"
          }
        },
        "KIBANAPASSWORD":{
          "TOOLTIP":"Elasticsearch Kibana password",
          "VALIDATION_MESSAGE":{
            "required":"Kibana Password cannot be empty"
          }
        }
      },
        "GRAPHITE":{
          "HEADER": "Graphite",
          "BODY":"<span><li><strong>Account Name</strong>: User-defined account name for your Graphite access.</li><li><strong>Endpoint</strong>: Graphite host address, from which you access the Graphite </li></span>",
          "ACCOUNTNAME":{
            "TOOLTIP":"User-defined account name for your Graphite access.",
            "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
          },
          "URL":{
            "TOOLTIP":"Graphite host address, from which you access the Graphite ",
            "VALIDATION_MESSAGE":{
              "required":"End Point cannot be empty",
              "invalidUrl": "End Point URL is invalid"
            }
          }
        },
        "GRAYLOG":{
          "HEADER": "GRAYLOG",
          "BODY":"<span><li><strong>Account Name</strong>: User-defined account name for your Graylog access.</li><li><strong>Endpoint</strong>: Graylog host address, from which you access the Graylog </li><li><strong>Token</strong>: The user's token </li></span>",
          "ACCOUNTNAME":{
            "TOOLTIP":"User-defined account name for your Graylog access.",
            "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
          },
          "ENDPOINT":{
            "TOOLTIP":"Graylog host address, from which you access the Graylog ",
            "VALIDATION_MESSAGE":{
              "required":"End Point cannot be empty",
              "invalidUrl": "End Point URL is invalid"
            }
          },
          "TOKEN":{
            "TOOLTIP":"GrayLog Personal Access Token",
            "VALIDATION_MESSAGE":{
              "required":"Token cannot be empty"
            }
          }
        },
        "NEWRELIC":{
          "HEADER": "New Relic",
          "BODY":"<span><li><strong>Account Name</strong>: User-defined account name for your NewRelic access.</li><li><strong>Api Key</strong>: The user's token to authenticate with Newrelic</li><li><strong>Application Key</strong>: The application key identifies which account the incoming data belongs to.</li><li><strong>Account ID</strong>: Provide account ID to identify the account </li><li><strong>Query Key</strong>: Provide a query key to filter the data </li></span>",
          "ACCOUNTNAME":{
            "TOOLTIP":"User-defined account name for your NewRelic access.",
            "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
          },
          "APIKEY":{
            "TOOLTIP":"NewRelic Api Key",
            "VALIDATION_MESSAGE":{
              "required":"API key cannot be empty"
            }
          },
          "APPLICATIONKEY":{
            "TOOLTIP":"The application key identifies which account the incoming data belongs to.",
            "VALIDATION_MESSAGE":{
              "required":"Application Key cannot be empty"
            }
          },
          "ACCOUNTID":{
            "TOOLTIP":"Provide account ID to identify the account ",
            "VALIDATION_MESSAGE":{
              "required":"Account Id cannot be empty"
            }
          },
          "QUERYKEY":{
            "TOOLTIP":"Provide a query key to filter the data ",
            "VALIDATION_MESSAGE":{
              "required":"Query Key cannot be empty"
            }
          },
          "TOKEN":{
            "TOOLTIP":"The user's token"
          }
        },
        "PROMETHEUS":{
          "HEADER": "Prometheus",
          "BODY":"<span><li><strong>Account Name</strong>: User-defined account name for your Prometheus access.</li><li><strong>Endpoint</strong>: Prometheus host address, from which you access the Prometheus</li><li><strong>Username</strong>: Prometheus username</li><li><strong>Password</strong>: Prometheus password</li></span>",
          "ACCOUNTNAME":{
            "TOOLTIP":"User-defined account name for your Prometheus access.",
            "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
          },
          "ENDPOINT":{
            "TOOLTIP":"Prometheus host address, from which you access the Prometheus",
            "VALIDATION_MESSAGE":{
              "required":"End Point cannot be empty",
              "invalidUrl": "End Point URL is invalid"
            }
          },
          "USERNAME":{
            "TOOLTIP":"Prometheus username",
            "VALIDATION_MESSAGE":{
              "noSpecialCharacters": "User Name cannot contain special characters other than - and _",
              "cannotContainSpace":"User Name cannot contain space",
              "required":"User Name cannot be empty",
              "startingFromNumber": "User Name cannot start with numbers"
            }
          },
          "PASSWORD":{
            "TOOLTIP":"Prometheus password",
            "VALIDATION_MESSAGE":{
              "required":"Password cannot be empty"
            }
          }
        },
        "SPLUNK":{
          "HEADER": "Splunk",
          "BODY":"<span><li><strong>Account Name</strong>: User-defined account name for your Splunk access.</li><li><strong>Splunk Url</strong>: Splunk host address, from which you access the Splunk</li><li><strong>Username</strong>: The Splunk's username</li><li><strong>Password</strong>: Splunk's password</li><li><strong>Splunk DashBoard Url </strong>: Splunk Dashboard URL that you want to access </li><span>",
          "ACCOUNTNAME":{
            "TOOLTIP":"User-defined account name for your Splunk access.",
            "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
          },
          "END_POINT":{
            "TOOLTIP":"Splunk host address, from which you access the Splunk",
            "VALIDATION_MESSAGE":{
              "required":"Splunk Url  cannot be empty",
              "invalidUrl": "Splunk URL is invalid"
            }
          },
          "PASSWORD":{
            "TOOLTIP":"Splunk's password",
            "VALIDATION_MESSAGE":{
              "required":"Password cannot be empty"
            }
          },
          "USER_NAME":{
            "TOOLTIP":"Splunk's user name",
            "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
          },
          "DASHBOARD_ENDPOINT":{
            "TOOLTIP":"Splunk Dashboard URL that you want to access ",
            "VALIDATION_MESSAGE":{
              "required":"Splunk DashBoard Url cannot be empty",
              "invalidUrl": "Splunk DashBoard URL is invalid"
            }
          }
        },
        "STACKDRIVER":{
          "HEADER": "Stackdriver",
          "BODY":"",
          "ACCOUNTNAME":{
            "TOOLTIP":"User defined name for the Stackdriver account",
            "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
          },
          "KEY_FILE":{
            "TOOLTIP":"Stackdriver Encrypted Key file",
            "VALIDATION_MESSAGE":{
              "required":"Encrypted Key File cannot be empty"
            }
          }
        },
        "SUMOLOGIC":{
          "HEADER": "Sumo Logic",
          "BODY":"",
          "ACCOUNTNAME":{
            "TOOLTIP":"User defined name for the Sumologic account",
            "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
          },
          "ACCESSID":{
            "TOOLTIP":"sumologic Access Id. You can generate Access Id (Administration > Security > Access Keys)",
            "VALIDATION_MESSAGE":{
              "required":"Access Id cannot be empty"
            }
          },
          "ACCESSKEY":{
            "TOOLTIP":"sumologic Access Key. You can generate Access Id (Administration > Security > Access Keys)",
            "VALIDATION_MESSAGE":{
          "required":"Access key cannot be empty"
            }
          },
          "ZONE":{
            "TOOLTIP":"sumologic Zone",
            "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Zone cannot contain special characters other than -",
          "cannotContainSpace":"Zone cannot contain space",
          "required":"Zone cannot be empty",
          "startingFromNumber": "Zone cannot start with numbers"
        }
          }
        },
        "VMWARETANZU":{
          "HEADER": "VMWare Tanzu Observability",
          "BODY":"<span><li><strong>Account Name</strong>: User-defined account name for your VMWare Tanzu access</li><li><strong>Endpoint</strong>: VMWare Tanzu host address, from which you access the VMWare Tanzu</li><li><strong>Email</strong>: Provide the user's registered and authorized email</li><li><strong>API token</strong>: The user's API token </li></span>",
          "ACCOUNTNAME":{
            "TOOLTIP":"User-defined account name for your VMWare Tanzu access",
            "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
          },
          "END_POINT":{
            "TOOLTIP":"VMWare Tanzu host address, from which you access the VMWare Tanzu",
            "VALIDATION_MESSAGE":{
              "required":"End Point cannot be empty",
              "invalidUrl": "End Point is invalid"
            }
          },
          "EMAIL":{
            "TOOLTIP":"Provide the user's registered and authorized email",
            "VALIDATION_MESSAGE":{
              "email":"Email is invalid",
              "required":"Email cannot be empty"
            }
          },
          "API_TOKEN":{
            "TOOLTIP":"The user's API token ",
            "VALIDATION_MESSAGE":{
              "required":"Api Token cannot be empty"
            }
          }
        },
        "MSTEAMS":{
          "HEADER": "Microsoft Teams",
          "BODY":""
        },
        "SLACK":{
          "HEADER": "Slack",
          "BODY":"<span><li><strong>Account Name</strong>: User-defined account name for your Slack access.</li><li><strong>BotName</strong>: Provide the bot name where you want to receive notifications in slack</li><li><strong>Token</strong>: The user's token to authenticate with slack.</li></span>",
          "ACCOUNTNAME":{
            "TOOLTIP":"User defined name for the Slack account",
            "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
          },
          "BOTNAME":{
            "TOOLTIP":"Slack Bot Name",
            "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Bot Name cannot contain special characters other than -",
          "cannotContainSpace":"Bot Name cannot contain space",
          "required":"Bot Name cannot be empty",
          "startingFromNumber": "Bot Name cannot start with numbers"
        }
          },
          "TOKEN":{
            "TOOLTIP":"Slack Personal Access Token",
            "VALIDATION_MESSAGE":{
              "required":"Token cannot be empty"
            }
          },
          "SPINNAKERTOGGLE":{
            "TOOLTIP":"Switch On this toggle to configure the resource in a gitops enabled Spinnaker instance",
            "VALIDATION_MESSAGE":{}
          }
        },
        "OPA":{
          "HEADER": "OPA",
          "BODY":"<span><li><strong>Account Name</strong>: User-defined account name for your OPA server access.</li><li><strong>EndPoint</strong>: OPA server host address, <span>such as https://opa:8181</span></li></span>",
          "ACCOUNTNAME":{
            "TOOLTIP":"User-defined account name for your OPA server access",
            "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
          },
          "ENDPOINT":{
            "TOOLTIP":"OPA server host address, such as https://opa:8181",
            "VALIDATION_MESSAGE":{
              "required":"End Point cannot be empty",
              "invalidUrl": "End Point URL is invalid"
            }
          }
        },
        "AQUAWAVE":{
          "HEADER": "Aqua Wave",
          "BODY":"<span><li><strong>Account Name</strong>: User-defined account name for your Aqua Wave access.</li><li><strong>Username</strong>: The Aquawave username</li><li><strong>Token</strong>: The user's token.</li></span>",
          "ACCOUNTNAME":{
            "TOOLTIP":"User-defined account name for your Aqua Wave access.",
            "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
          },
          "USERNAME":{
            "TOOLTIP":"The Aquawave username",
            "VALIDATION_MESSAGE":{
              "noSpecialCharacters": "User Name cannot contain special characters other than - and _",
              "cannotContainSpace":"User Name cannot contain space",
              "required":"User Name cannot be empty",
              "startingFromNumber": "User Name cannot start with numbers"
            }
          },
          "TOKEN":{
            "TOOLTIP":"Aqua Wave Personal Access Token",
            "VALIDATION_MESSAGE":{
              "required":"Bearer token cannot be empty"
            }
          }
        },
        "APPSCAN":{
          "HEADER": "HCL AppScan",
          "BODY":"<span><li><strong>Account Name</strong>: User-defined account name for your HCL AppScan access.</li><li><strong>Token</strong>: The user's token</li></span>",
          "ACCOUNTNAME":{
            "TOOLTIP":"User-defined account name for your HCL AppScan access.",
            "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
          },
          "TOKEN":{
            "TOOLTIP":"The user's personal access token ",
            "VALIDATION_MESSAGE":{
              "required":"Bearer token cannot be empty"
            }
          }
        },
        "JFROG":{
          "HEADER": "JFrog XRay Scanning",
          "BODY":"<span><li><strong>Account Name</strong>: User-defined account name for your Jfrog Xray access.</li><li><strong>Endpoint</strong>: Your Jfrog Xray host address, from which you access the Jfrog Xray instance</li><li><strong>Token</strong>: The user's token.</li></span>",
          "ACCOUNTNAME":{
            "TOOLTIP":"User-defined account name for your Jfrog Xray access.",
            "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
          },
          "ENDPOINT":{
            "TOOLTIP":"Jfrog Xray host address, from which you access the Jfrog Xray instance",
            "VALIDATION_MESSAGE":{
              "required":"Endpoint cannot be empty",
              "invalidUrl": "Endpoint URL is invalid"
            }
          },
          "TOKEN":{
            "TOOLTIP":"The user's token from jfrog xray to authenticate",
            "VALIDATION_MESSAGE":{
              "required":"Token cannot be empty"
            }
          }
        },
        "PRISMACLOUD":{
          "HEADER": "Prisma Cloud",
          "BODY":"<span><li><strong>Account Name</strong>: User-defined account name for your Prisma Cloud access.</li><li><strong>Host Url</strong>: Your Prisma Cloud host address, from which you access the Prisma Cloud instance</li><li><strong>Access Key ID</strong>: The user's access key who has access to the Prisma Cloud. If you are unsure, consult your Prisma Cloud administrator to get an access key.</li><li><strong>Secret key</strong>: The user's secret key</li></span>",
          "ACCOUNTNAME":{
            "TOOLTIP":"User-defined account name for your Prisma Cloud access.",
            "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
          },
          "HOSTURL":{
            "TOOLTIP":"Prisma Cloud host address, from which you access the Prisma Cloud instance",
            "VALIDATION_MESSAGE":{
              "required":"Host URL cannot be empty",
              "invalidUrl": "Host URL is invalid"
            }
          },
          "APPLICATIONURL":{
            "TOOLTIP":"Prisma Cloud Application URL",
            "VALIDATION_MESSAGE":{
              "required":"Application URL cannot be empty",
              "invalidUrl": "Application URL is invalid"
            }
          },
          "ACCESSKEYID":{
            "TOOLTIP":"The user's access key who has access to the Prisma Cloud. If you are unsure, consult your Prisma Cloud administrator to get an access key.",
            "VALIDATION_MESSAGE":{
              "required":"Access Key Id cannot be empty"
            }
          },
          "SECRETKEY":{
            "TOOLTIP":"The user's secret key",
            "VALIDATION_MESSAGE":{
              "required":"Secret Key cannot be empty"
            }
          }
        },
        "SONARQUBE":{
          "HEADER": "SonarQube",
          "BODY":"<span><li><strong>Account Name</strong>: User-defined account name for your Sonarqube access. </li><li><strong>Host Url</strong>: Sonarqube host address, from which you access the Sonaqube instance</li><li><strong>Token</strong>: The user's token (it is optional)</li></span>",
          "ACCOUNTNAME":{
            "TOOLTIP":"User defined name for the SonarQube account",
            "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
          },
          "HOSTURL":{
            "TOOLTIP":"Sonarqube host address, from which you access the Sonaqube instance",
            "VALIDATION_MESSAGE":{
              "required":"Host URL cannot be empty",
              "invalidUrl": "Host URL is invalid"
            }
          },
          "TOKEN":{
            "TOOLTIP":"The user's token (it is optional)",
            "VALIDATION_MESSAGE":{
              "required":"Token cannot be empty"
            }
          }
        },
        "AUTOPILOT":{
          "HEADER": "Autopilot",
          "BODY":"",
          "ACCOUNTNAME":{
            "TOOLTIP":"User-defined account name for your Sonarqube access. ",
            "VALIDATION_MESSAGE":{
          "noSpecialCharacters": "Account Name cannot contain special characters other than -",
          "cannotContainSpace":"Account Name cannot contain space",
          "required":"Account Name cannot be empty",
          "startingFromNumber": "Account Name cannot start with numbers"
        }
          },
          "USERNAME":{
            "TOOLTIP":" Autopilot User Name",
            "VALIDATION_MESSAGE":{
              "noSpecialCharacters": "User Name cannot contain special characters other than - and _",
              "cannotContainSpace":"User Name cannot contain space",
              "required":"User Name cannot be empty",
              "startingFromNumber": "User Name cannot start with numbers"
            }
          }
        }
    },
      "UNCHANGED_FORM": "Form is unchanged. Please make modifications in the form to enable the button.",
      "INVALID_FORM": "Few fields are mandatory or invalid. Please fill the form to enable the button.",
      "NO_WRITE_ACCESS": "You have only read permission. Please check with your administrator for updating permissions.",
      "METRIC_TEMPLATE": {
        "APM_INFRA": {
          "TEMPLATE_NAME": {
            "TOOLTIP": "The unique name of the template for identification",
            "VALIDATION_MESSAGE": {
              "required": "Template Name cannot be empty",
              "noSpecialCharacters": "Template Name cannot contain special characters",
              "cannotContainSpace": "Template Name cannot contain space",
              "startingFromNumber": "Template Name cannot start with number",
              "maxlength": "Template name should not have more than 63 characters!",
              "exists": "Template already exists"
            }
          },
          "APM_MONITORING_PROVIDER": {
            "TOOLTIP": "Select an APM datasource provider of choice",
            "VALIDATION_MESSAGE": {}
          },
          "APM_ACCOUNT": {
            "TOOLTIP": "Select the account of interest in the configured APM datasource ",
            "VALIDATION_MESSAGE": {}
          },
          "APM_APPLICATION": {
            "TOOLTIP": "Select the application of interest that you want to monitor",
            "VALIDATION_MESSAGE": {}
          },
          "APM_API_SELECTION": {
            "TOOLTIP": "Select the relevant API metrics to monitor ",
            "VALIDATION_MESSAGE": {}
          },
          "INFRA_MONITORING_PROVIDER": {
            "TOOLTIP": "Select an INFRA metrics datasource provider of choice",
            "VALIDATION_MESSAGE": {}
          },
          "INFRA_ACCOUNT": {
            "TOOLTIP": "Select the account of interest in the configured INFRA metrics datasource ",
            "VALIDATION_MESSAGE": {}
          },
          "INFRA_METRIC_GROUPS": {
            "TOOLTIP": "Metrics groups organized as groups for quick overview on each infrastructure component",
            "VALIDATION_MESSAGE": {}
          },
          "FILTER_KEY": {
            "TOOLTIP": "A metric scope placeholder to filter the scope of the metric",
            "VALIDATION_MESSAGE": {
              "required": "Filter Key cannot be empty",
              "cannotContainSpace": "Filter Key cannot contain space"
            }
          },
          "BASELINE": {
            "TOOLTIP": "A unique metric scope to identify the baseline metric",
            "VALIDATION_MESSAGE": {
              "required": "Baseline cannot be empty",
              "cannotContainSpace": "Baseline cannot contain space"
            }
          },
          "NEW_RELEASE": {
            "TOOLTIP": "A unique metric scope to identify the canary metric",
            "VALIDATION_MESSAGE": {
              "required": "New Release cannot be empty",
              "cannotContainSpace": "New Release cannot contain space"
            }
          },
          "NORMALIZATION": {
            "TOOLTIP": "The selected Load metric will be dividing all the metrics to make the metrics more comparable to each other",
            "VALIDATION_MESSAGE": {}
          },
          "THRESHOLD": {
            "TOOLTIP": "Select 'Hard' mode for a stringent analysis and 'Easy' mode for a more lenient analysis",
            "VALIDATION_MESSAGE": {}
          },
          "SPECIFY_CRITICAL_WATCHLIST": {
            "TOOLTIP": "Metrics marked as critical, will affect the overall verification score if they fail Metrics marked as in watchlist will be shown first in the metric analysis report",
            "VALIDATION_MESSAGE": {}
          }
        },
        "CUSTOM": {
          "TEMPLATE_NAME": {
            "TOOLTIP": "The unique name of the template for identification",
            "VALIDATION_MESSAGE": {
              "required": "Template Name cannot be empty",
              "noSpecialCharacters": "Template Name cannot contain special characters",
              "cannotContainSpace": "Template Name cannot contain space",
              "startingFromNumber": "Template Name cannot start with number",
              "maxlength": "Template name should not have more than 63 characters!",
              "exists": "Template already exists"
            }
          },
          "DATA_SOURCE": {
            "TOOLTIP": "Select a datasource provider of choice",
            "VALIDATION_MESSAGE": {
              "required": "Data source cannot be empty"
            }
          },
          "ACCOUNT": {
            "TOOLTIP": "Select the account of interest in the configured datasource ",
            "VALIDATION_MESSAGE": {
              "required": "Account cannot be empty"
            }
          },
          "FILTER_KEY": {
            "TOOLTIP": "Metric Scope Placeholder will be replaced by Baseline & New Release values in the Metric Query; For example, Scope Placeholder “pod_name” will be replaced by Baseline & New Release values in the metric query avg(container_memory_usage_bytes{pod=~'pod_name',container!=''}) for getting baseline & New Release metrics data respectively from the monitoring provider",
            "VALIDATION_MESSAGE": {
              "required": "Filter Key cannot be empty",
              "cannotContainSpace": "Filter Key cannot contain space"
            }
          },
          "BASELINE": {
            "TOOLTIP": "Unique metric scope to identify the baseline metric data",
            "VALIDATION_MESSAGE": {
              "required": "Baseline cannot be empty",
              "cannotContainSpace": "Baseline cannot contain space"
            }
          },
          "NEW_RELEASE": {
            "TOOLTIP": "Unique metric scope to identify the canary metric data",
            "VALIDATION_MESSAGE": {
              "required": "New Release cannot be empty",
              "cannotContainSpace": "New Release cannot contain space"
            }
          },
          "ADD_NEW_QUERY": {
            "TOOLTIP": "Add New Query",
            "VALIDATION_MESSAGE": {}
          },
          "QUERY_SELECTION": {
            "TOOLTIP": "Select the relevant metrics to monitor ",
            "VALIDATION_MESSAGE": {}
          },
          "QUERY_NAME": {
            "TOOLTIP": "A meaningful name given to a query or a group of similar queries ",
            "VALIDATION_MESSAGE": {
              "required": "Query Name cannot be empty"
            }
          },
          "QUERY_STRING": {
            "TOOLTIP": "Query to fetch the metric from the data source provider",
            "VALIDATION_MESSAGE": {
              "required": "Query String cannot be empty"
            }
          },
          "RISK_DIRECTION": {
            "TOOLTIP": "Direction in which the metric difference is allowed to expand",
            "VALIDATION_MESSAGE": {}
          },
          "THRESHOLD": {
            "TOOLTIP": "Percentage difference beyond which the Metric is treated as FAIL",
            "VALIDATION_MESSAGE": {}
          },
          "CRITICAL": {
            "TOOLTIP": "Critical",
            "VALIDATION_MESSAGE": {}
          },
          "WATCHLIST": {
            "TOOLTIP": "Metrics marked as in watchlist will be shown first in the metric analysis report",
            "VALIDATION_MESSAGE": {}
          },
          "WEIGHT": {
            "TOOLTIP": "Numerical importance given to a metric; it can range from 0 as lowest to 1 as the highest",
            "VALIDATION_MESSAGE": {}
          },
          "CRITICALITY": {
            "TOOLTIP": "Normal is selected to remove the metric from the metric group for score calculation if it has no data, Critical is selected to fail the entire analysis if this metric fails or has no data, Must Have Data is used to fail a metric if data is missing",
            "VALIDATION_MESSAGE": {}
          },
          "NAN_STRATEGY": {
            "TOOLTIP": "Handles NaN values which can occur if there is no data in a particular interval for metric data. ",
            "VALIDATION_MESSAGE": {}
          }
        }
      },
      "USAGE_INSIGHTS": {
        "APPLICATIONS": {
          "TOOLTIP": "Application"
        },
        "PIPELINES": {
          "TOOLTIP": "Pipelines"
        },
        "PIPELINES_WITH_INTELLIGENT_GATES": {
          "TOOLTIP": "Pipelines with Intelligent Gates"
        },
        "INTELLIGENT_GATES_BREAKDOWN": {
          "TOOLTIP": "Intelligent Gates Breakdown"
        },
        "GATES_USED": {
          "TOOLTIP": "Gates Used"
        },
        "USERS": {
          "TOOLTIP": "Users"
        }
      },
      "DELIVERY_INSIGHTS": {
        "PIPELINES": {
          "TOOLTIP": "Number of pipeline executions over time"
        },
        "MOST_ACTIVE_PIPELINES": {
          "TOOLTIP": "Pipelines which have executed most number of times"
        },
        "MOST_SUCCESSFUL_PIPELINES": {
          "TOOLTIP": "Pipelines which have successfully executed most number of times"
        },
        "MOST_FAILED_PIPELINES": {
          "TOOLTIP": "Pipelines which have failed most number of times"
        },
        "FASTEST_PIPELINES": {
          "TOOLTIP": "Pipelines with fastest execution times"
        },
        "SLOWEST_PIPELINES": {
          "TOOLTIP": "Pipelines with slowest execution times"
        },
        "MANUAL_JUDGMENT": {
          "TOOLTIP": "Pipelines with manual judgement having slowest execution times"
        }
      },
      "ACCESS_MANAGEMENT": {
        "ADMINISTRATOR": {
          "INFO": "Super Administrator Groups will not appear in the dropdown since their Access Permissions cannot be modified. Administrators will have full Access to all Resources.",
          "TOOLTIP": "Groups with Administration Permissions"
        },
        "USER_ROLE_LISTING": {
          "HEADER": "ROLE MANAGEMENT",
          "BODY": "Users should be assigned user roles only if they need global access to one or more resources."
        },
        "USER_ROLE_CREATION": {
          "ROLENAME": {
            "TOOLTIP": "",
            "VALIDATION_MESSAGE": {
              "required": "Role Name cannot be empty",
              "cannotContainSpace": "Role Name cannot contain space",
              "noSpecialCharacters": "Role Name cannot contain special character",
              "startingFromNumber": "Role Name should not start with number"
            }
          },
          "USER_GROUPS": {
            "TOOLTIP": "",
            "VALIDATION_MESSAGE": {
              "required": "Groups cannot be empty"
            }
          },
          "PERMISSIONS": {
            "VALIDATION_MESSAGE": {
              "required": "Atleast one feature has to be enabled with permissions"
            }
          }
        },
        "FEATURE_VISIBILTY_LISTING": {
          "HEADER": "FEATURE FLAG MANAGEMENT",
          "BODY": "Feature Visibility is used for scenarios where one or more user groups need exclusive access to a specific feature. For example, the 'Compliance Team' should only access the Policy Management feature. Administrators can enable the feature flag for the compliance team user group. The feature visibility function will ensure that the policy management feature is not visible for all other user groups."
        },
        "FEATURE_VISIBILTY_CREATION": {
          "ROLENAME": {
            "TOOLTIP": "",
            "VALIDATION_MESSAGE": {
              "required": "Role Name cannot be empty",
              "cannotContainSpace": "Role Name cannot contain space",
              "noSpecialCharacters": "Role Name cannot contain special character",
              "startingFromNumber": "Role Name should not start with number"
            }
          },
          "USER_GROUPS": {
            "TOOLTIP": "",
            "VALIDATION_MESSAGE": {
              "required": "Groups cannot be empty"
            }
          },
          "PERMISSIONS": {
            "VALIDATION_MESSAGE": {
              "required": "Atleast one feature has to be enabled"
            }
          }
        }
      },
      "LOG_TEMPLATE": {
        "STRING_PATTERN": {
          "TOOLTIP": "String Pattern",
          "VALIDATION_MESSAGE": {
            "required": "String Pattern cannot be empty"
          }
        },
        "LOG_TOPICS": {
          "TOOLTIP": "Strings that appear in logs with their characterization"
        },
        "LOG_TAGS": {
          "TOOLTIP": "Create custom tags based on business logic."
        },
        "CHARACTERIZATION_TOPIC": {
          "TOOLTIP": "Characterization Topic",
          "VALIDATION_MESSAGE": {
            "required": "Characterization Topic cannot be empty"
          }
        },
        "TYPE": {
          "TOOLTIP": "Type",
          "VALIDATION_MESSAGE": {}
        },
        "ENABLE_CLUSTER_TAG": {
          "TOOLTIP": "Create custom tags based on business logic.",
          "VALIDATION_MESSAGE": {}
        },
        "CLUSTER_TAG_STRING": {
          "TOOLTIP": "The string pattern that appears in logs",
          "VALIDATION_MESSAGE": {
            "required": "Cluster Tag String cannot be empty"
          }
        },
        "CLUSTER_TAG": {
          "TOOLTIP": "Cluster Tag",
          "VALIDATION_MESSAGE": {
            "required": "Cluster Tag cannot be empty"
          }
        },
        "LOG_TEMPLATE_NAME": {
          "TOOLTIP": "Log Template Name",
          "VALIDATION_MESSAGE": {
            "required": "Template Name cannot be empty",
            "noSpecialCharacters": "Template Name cannot contain special characters",
            "cannotContainSpace": "Template Name cannot contain space",
            "startingFromNumber": "Template Name cannot start with number",
            "maxlength": "Template name should not have more than 63 characters!",
            "exists": "Template already exists"
          }
        },
        "PROVIDER": {
          "TOOLTIP": "Data source for Risk Analysis",
          "VALIDATION_MESSAGE": {
            "required": "Provider cannot be empty"
          }
        },
        "LOG_ACCOUNT": {
          "TOOLTIP": "Account of the Log provider; Refer Integrations tab under Setup",
          "VALIDATION_MESSAGE": {
            "required": "Log Account cannot be empty"
          }
        },
        "QUERY_FILTER_KEY": {
          "TOOLTIP": "Unique Key which identify logs to be processed in the Index",
          "VALIDATION_MESSAGE": {
            "required": "Query Filter Key cannot be empty",
            "cannotContainSpace": "Query Filter Key cannot contain space"
          }
        },
        "BASELINE": {
          "TOOLTIP": "Unique value which identify baseline logs in the Index",
          "VALIDATION_MESSAGE": {
            "required": "Baseline cannot be empty",
            "cannotContainSpace": "Baseline cannot contain space"
          }
        },
        "NEW_RELEASE": {
          "TOOLTIP": "Unique value which identify New Release logs in the Index",
          "VALIDATION_MESSAGE": {
            "required": "New Release cannot be empty",
            "cannotContainSpace": "New Release cannot contain space"
          }
        },
        "RESPONSE_KEYWORDS": {
          "TOOLTIP": "Field name in the Index containing logs to be processed",
          "VALIDATION_MESSAGE": {
            "required": "Response Keywords cannot be empty",
            "cannotContainSpace": "Response Keywords cannot contain space"
          }
        },
        "TIMESTAMP_KEY": {
          "TOOLTIP": "Unique Key which identify the timestamp for log; this field is optional; by default, it is @timestamp for elasticsearch and timestamp for graylog",
          "VALIDATION_MESSAGE": {
            "cannotContainSpace": "Timestamp Key cannot contain space"
          }
        },
        "AUTOBASELINE": {
          "TOOLTIP": "ML based learning of the baseline from historic analysis",
          "VALIDATION_MESSAGE": {}
        },
        "CONTEXTUAL_CLUSTER": {
          "TOOLTIP": "Enable/disable cluster of unexpected events in similar context",
          "VALIDATION_MESSAGE": {}
        },
        "CONTEXTUAL_WINDOW_SIZE": {
          "TOOLTIP": "Number of Log events to be seen in a Context. Allowed size in between 25 and 50",
          "VALIDATION_MESSAGE": {
            "max": "Allowed size is in between 25 to 50",
            "min": "Allowed size is in between 25 to 50"
          }
        },
        "INFO_CLUSTER_SCORING": {
          "TOOLTIP": "Enabling this option will include INFO clusters in scoring",
          "VALIDATION_MESSAGE": {}
        },
        "SENSITIVITY": {
          "TOOLTIP": "Impact of Unexpected Issues on the log scoring",
          "VALIDATION_MESSAGE": {
            "required": "Sensitivity cannot be empty"
          }
        },
        "SCORING_ALGORITHM": {
          "TOOLTIP": "Scoring Algorithm for Risk Analysis",
          "VALIDATION_MESSAGE": {}
        },
        "LOG_GROUP": {
          "TOOLTIP": "Group of log streams that share the same retention, monitoring, and access control settings",
          "VALIDATION_MESSAGE": {
            "required": "Log Group cannot be empty",
            "cannotContainSpace": "Log Group cannot contain space"
          }
        },
        "LOG_STREAM": {
          "TOOLTIP": "Sequence of log events that share the same source",
          "VALIDATION_MESSAGE": {
            "required": "Log Stream cannot be empty",
            "cannotContainSpace": "Log Stream cannot contain space"
          }
        },
        "REGION": {
          "TOOLTIP": "Geographic area where AWS data center",
          "VALIDATION_MESSAGE": {
            "required": "Region cannot be empty"
          }
        },
        "INDEX_PATTERN": {
          "TOOLTIP": "Index containing logs for processing",
          "VALIDATION_MESSAGE": {
            "required": "Intex Pattern cannot be empty",
            "cannotContainSpace": "Intex Pattern cannot contain space"
          }
        },
        "CUSTOM_REGEX": {
          "TOOLTIP": "Custom Regular Expression to filter the logs",
          "VALIDATION_MESSAGE": {}
        },
        "REGULAR_EXPRESSION": {
          "TOOLTIP": "Sequence of characters that specifies a search pattern",
          "VALIDATION_MESSAGE": {
            "cannotContainSpace": "Regular Expression cannot contain space"
          }
        },
        "RESPONSE_KEY": {
          "TOOLTIP": "Field name in the Index where regex to be searched",
          "VALIDATION_MESSAGE": {}
        },
        "STREAM_ID": {
          "TOOLTIP": "The streams are a mechanism to route messages into categories in realtime while they are processed",
          "VALIDATION_MESSAGE": {
            "required": "Stream ID cannot be empty",
            "cannotContainSpace": "Stream ID cannot contain space"
          }
        },
        "NAMESPACE": {
          "TOOLTIP": "Namespace",
          "VALIDATION_MESSAGE": {
            "required": "Namespace cannot be empty",
            "cannotContainSpace": "Namespace cannot contain space"
          }
        },
        "TEST_CASE_KEY": {
          "TOOLTIP": "Field in the log index which holds the test case names",
          "VALIDATION_MESSAGE": {
            "required": "Test Case Key cannot be empty",
            "cannotContainSpace": "Test Case Key cannot contain space"
          }
        },
        "TEST_SUITE_KEY": {
          "TOOLTIP": "Field in the log index which  holds the test suite names",
          "VALIDATION_MESSAGE": {
            "required": "Test Suite Key cannot be empty",
            "cannotContainSpace": "Test Suite Key cannot contain space"
          }
        }
      }
    }
kind: ConfigMap
metadata:
  name: oes-ui-config
  labels:
    app: oes
    component: ui
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
---
# Source: oes/templates/configmaps/oes-ui-nginxconf.yaml
apiVersion: v1
data:
  nginx.conf: |
    # For more information on configuration, see:
    #   * Official English Documentation: http://nginx.org/en/docs/
    #   * Official Russian Documentation: http://nginx.org/ru/docs/
  
    user nginx;
    worker_processes auto;
    error_log /var/log/nginx/error.log debug;
    pid /tmp/nginx.pid;
  
    # Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.
    include /usr/share/nginx/modules/*.conf;
  
    events {
        worker_connections 1024;
    }
  
    http {
        log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                          '$status $body_bytes_sent "$http_referer" '
                          '"$http_user_agent" "$http_x_forwarded_for"';
  
        access_log  /var/log/nginx/access.log  main;
  
        sendfile            on;
        tcp_nopush          on;
        tcp_nodelay         on;
        keepalive_timeout   65;
        types_hash_max_size 2048;
  
        include             /etc/nginx/mime.types;
        default_type        application/octet-stream;
  
        # Load modular configuration files from the /etc/nginx/conf.d directory.
        # See http://nginx.org/en/docs/ngx_core_module.html#include
        # for more information.
        include /etc/nginx/conf.d/*.conf;
  
        server {
            listen       8080 default_server;
            #listen       [::]:8080 default_server;
            server_name  _;
            root /var/www/html;
  
            # Load configuration files for the default server block.
            include /etc/nginx/default.d/*.conf;
  
            location ^~ /deck/gate/ {
              proxy_pass http://oes-gate:8084/ ;
              proxy_set_header Host $host;
            }
  
            location ^~ /deck {
              proxy_pass http://spin-deck:9000/ ;
            }
  
            location ^~ /plugin-manifest.json {
              proxy_pass http://spin-deck:9000 ;
            }
  
            location ^~ /gate/ {
              proxy_pass http://oes-gate:8084/ ;
              proxy_set_header Host $host;
            }
  
            location ^~ /application {
              proxy_pass http://oes-ui:8080 ;
              proxy_set_header Host $host;
            }
  
            location ^~ /ui {
              try_files $uri $uri/ /ui/index.html;
              proxy_set_header Host $host;
            }
  
            # Go to Gate if you don't know what to do
            location / {
              proxy_pass http://oes-gate:8084/ ;
              proxy_set_header Host $host;
            }
  
  
        }
    }

kind: ConfigMap
metadata:
  name: oes-ui-nginxconf
  labels:
    app: oes
    component: ui
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
---
# Source: oes/templates/configmaps/opa-persist.yaml
apiVersion: v1
data:
  opa-persist.sh: |
    wait_period=0
    while true
    do
    kubectl get po -n opsmx-isd -o jsonpath='{range .items[*]}{..metadata.name}{"\t"}{..containerStatuses..ready}{"\n"}{end}' > /tmp/inst.status
    SAPOR=$(grep oes-sapor /tmp/inst.status | awk '{print $2}')
    PLATFORM=$(grep oes-platform /tmp/inst.status | awk '{print $2}')

    wait_period=$(($wait_period+10))

    if [ "$SAPOR" == "true" ] && [ "$PLATFORM" == "true" ];
    then
      echo \"Spinnaker and OES services are Up and Ready..\"
      set -x
      sleep 5
      BASEURL=$GATEURL
      USERPASS="-u ${GATEUSER}:${GATEPASS}"
      curl $USERPASS $BASEURL/oes/v1/policies/list > listofpolicies.json
      #Get the policy NAMES
      [ -s "listofpolicies.json" ] && (cat listofpolicies.json | jq .[] | jq -r .policyName > policies) || sleep infinity
      #for each NAME
      while read -e name; do
        #Get content
        curl $USERPASS $BASEURL/oes/v1/policy/$name > tmp.json

        #Get Policy ID
        ID=`cat tmp.json|jq .response | jq '.policyId'`
        #Delete Policy ID
        cat tmp.json|jq .response | jq 'del(.policyId)'  > update.json

        #update
        curl $USERPASS -X PUT -H "Content-Type: application/json" -d @update.json $BASEURL/oes/v1/policy/$ID
      done <  policies
      sleep infinity
      #endFOR
    else
      if [ $wait_period -gt 2000 ];
      then
          echo \"Script is timed out as the OES is not ready yet.......\"
          break
      else
          echo \"Waiting for OES services to be ready\"
          sleep 1m
      fi
    fi
    done
kind: ConfigMap
metadata:
  name: opa-persist
---
# Source: oes/templates/configmaps/standard-error-codes.yaml
apiVersion: v1
data:
  standard-error-codes.csv: |-
    standardErrorCodesMapping.ISD-IsEmpty-400-01 = ISD-IsEmpty-400-01 : {0} - {1} is empty. Please provide the {1}.
    standardErrorCodesMapping.ISD-IsNull-400-02 = ISD-IsNull-400-02 : {0} - {1} is null. Please provide the {1}.
    standardErrorCodesMapping.ISD-MustBeAlphanumericName-400-03 = ISD-MustBeAlphanumericName-400-03 : {0} - {1} should be alphanumeric without any special characters !
    standardErrorCodesMapping.ISD-ExceedsMaxStringLength-400-04 = ISD-ExceedsMaxStringLength-400-04 : {0} - {1} should not have more than {2} characters.
    standardErrorCodesMapping.ISD-NotConfigured-400-05 = ISD-NotConfigured-400-05 : {0} - {1} is not configured. Please configure the {1} !
    standardErrorCodesMapping.ISD-PolicyNotProvided-400-06 = ISD-PolicyNotProvided-400-06 : {0} - Policies are mandatory for automated approval gate.
    standardErrorCodesMapping.ISD-EmptyKeyOrValueInJson-400-07 = ISD-EmptyKeyOrValueInJson-400-07 : {0} - {1} is missing in json !
    standardErrorCodesMapping.ISD-UnableToParseJSON-400-08 = ISD-UnableToParseJSON-400-08 : {0} - Unable to parse Json. Please provide a valid json with required data !
    standardErrorCodesMapping.ISD-MustBeANumber-400-09 = ISD-MustBeANumber-400-09 : {0} - {1} must be a number : {2}
    standardErrorCodesMapping.ISD-InvalidURL-400-10 = ISD-InvalidURL-400-10 : {0} - {1} is invalid - {2}
    standardErrorCodesMapping.ISD-BadRequest-400-11 = ISD-BadRequest-400-11 : {0} - {1} {2}
    standardErrorCodesMapping.ISD-Unauthorized-401-01 = ISD-Unauthorized-401-01 : {0} - {1} not authorized. {2}.
    standardErrorCodesMapping.ISD-Unauthorized-401-02 = ISD-Unauthorized-401-02 : {0} - User group not found for user : {1}.
    standardErrorCodesMapping.ISD-NotAdmin-401-03 = ISD-NotAdmin-401-03 : {0} - {1} is not an admin !
    standardErrorCodesMapping.ISD-Forbidden-403-01 = ISD-Forbidden-403-01 : {0} - {1} doesn't have {2} permission on this feature: {3}
    standardErrorCodesMapping.ISD-Forbidden-403-02 = ISD-Forbidden-403-02 : {0} - {1} is invalid.
    standardErrorCodesMapping.ISD-Forbidden-403-03 = ISD-Forbidden-403-03 : {0} - {1} : {2}.
    standardErrorCodesMapping.ISD-Forbidden-403-04 = ISD-Forbidden-403-04 : {0} - {1} namespace is not accessible for given kubeconfig account {2}.
    standardErrorCodesMapping.ISD-IsNotFound-404-01 = ISD-IsNotFound-404-01 : {0} - {1} not found : {2}
    standardErrorCodesMapping.ISD-NoData-404-02 = ISD-NoData-404-02 : {0} - No data found for {1}
    standardErrorCodesMapping.ISD-DoesNotExist-404-03 = ISD-DoesNotExist-404-03 : {0} - {1} does not exist {2}.
    standardErrorCodesMapping.ISD-IsNotFound-404-04 = ISD-IsNotFound-404-04 : {0} - {1} not found {2}.
    standardErrorCodesMapping.ISD-AlreadyExists-409-01 = ISD-AlreadyExists-409-01 : {0} - {1} already exists: {2}
    standardErrorCodesMapping.ISD-FailedToDelete-412-01 = ISD-FailedToDelete-412-01 : {0} - Unable to delete {1} as {1} is already in use !
    standardErrorCodesMapping.ISD-FailedToDeletePolicy-412-02 = ISD-FailedToDeletePolicy-412-02 : {0} - Unable to delete policy as it is already in use for {1} gate !
    standardErrorCodesMapping.ISD-FailedToUpdate-412-03 = ISD-FailedToUpdate-412-03 : {0} - Unable to update {1} as {1} is already in use !
    standardErrorCodesMapping.ISD-InvalidURL-422-01 = ISD-InvalidURL-422-01 : {0} - The requested {1} URL is invalid !
    standardErrorCodesMapping.ISD-ConnectionOrAuthenticationFailed-422-02 = ISD-ConnectionOrAuthenticationFailed-422-02 : {0} - {1} connection or authentication failed : HTTP status {2}
    standardErrorCodesMapping.ISD-InvalidCredentials-422-03 = ISD-InvalidCredentials-422-03 : {0} - {1} credentials are invalid !
    standardErrorCodesMapping.ISD-InvalidEndpoint-422-04 = ISD-InvalidEndpoint-422-04 : {0} - {1} endpoint is invalid !
    standardErrorCodesMapping.ISD-InvalidEndpointOrCredentials-422-05 = ISD-InvalidEndpointOrCredentials-422-05 : {0} - {1} endpoint or credentials are invalid !
    standardErrorCodesMapping.ISD-UsernameOrPasswordIsBlank-422-06 = ISD-UsernameOrPasswordIsBlank-422-06 : {0} - {1} is blank but {2} is supplied. Both must be present or blank.
    standardErrorCodesMapping.ISD-UnknownDatasource-422-07 = ISD-UnknownDatasource-422-07 : {0} - Unknown datasource or datasource is currently not supported : {1}
    standardErrorCodesMapping.ISD-InvalidProvider-422-08 = ISD-InvalidProvider-422-08 : {0} - {1} provider is invalid !
    standardErrorCodesMapping.ISD-InvalidPath-422-09 = ISD-InvalidPath-422-09 : {0} - {1} path is invalid !
    standardErrorCodesMapping.ISD-UnableToGenerate-422-10 = ISD-UnableToGenerate-422-10 : {0} - Unable to generate {1} !
    standardErrorCodesMapping.ISD-FailedToCreate-422-11 = ISD-FailedToCreate-422-11 : {0} - Failed to create {1}.
    standardErrorCodesMapping.ISD-EndpointIsBlank-422-12 = ISD-EndpointIsBlank-422-12 : {0} - {1} endpoint is blank. {2} must be blank.
    standardErrorCodesMapping.ISD-ConnectionOrAuthenticationFailed-422-13 = ISD-ConnectionOrAuthenticationFailed-422-13 : {0} - {1} connection or authentication failed.
    standardErrorCodesMapping.ISD-FailedToUpdate-422-14 = ISD-FailedToUpdate-422-14 : {0} - Failed to Update {1}.
    standardErrorCodesMapping.ISD-FailedToDelete-422-15 = ISD-FailedToDelete-422-15 : {0} - Failed to Delete {1}.
    standardErrorCodesMapping.ISD-DoesNotMatch-422-16 = ISD-DoesNotMatch-422-16 : {0} - {1} does not match {2}.
    standardErrorCodesMapping.ISD-DoesNotExist-422-17 =  ISD-DoesNotExist-422-17 : {0} - {1} does not exist {2}.
    standardErrorCodesMapping.ISD-DoesNotSupport-422-18 = ISD-DoesNotSupport-422-18 : {0} - {1} does not support {2}.
    standardErrorCodesMapping.ISD-UnableToVerify-422-19 = ISD-UnableToVerify-422-19 : {0} - Unable to verify {1}.
    standardErrorCodesMapping.ISD-FailedToInitialize-422-20 = ISD-FailedToInitialize-422-20 : {0} - Failed to initialize {1}.
    standardErrorCodesMapping.ISD-DoesNotHave-422-21 = ISD-DoesNotHave-422-21 : {0} - {1} does not have {2}.
    standardErrorCodesMapping.ISD-UnableToAddStage-424-01 = ISD-UnableToAddStage-424-01 : {0} - Unable to add stage in {1} !
    standardErrorCodesMapping.ISD-UnableToDelete-424-02 = ISD-UnableToDelete-424-02 : {0} - Unable to delete {1} while analysis is under process !
    standardErrorCodesMapping.ISD-UnableToDelete-424-03 = ISD-UnableToDelete-424-03 : {0} - Unable to delete {1} as already in use {2}
    standardErrorCodesMapping.ISD-UnableToDelete-424-04 = ISD-UnableToDelete-424-04 : {0} - Unable to delete {1} as it is involved in multi-service analysis !
    standardErrorCodesMapping.ISD-ShouldBeNumber-500-01 = ISD-ShouldBeNumber-500-01 : {0} - {1} should be an number !
    standardErrorCodesMapping.ISD-ShouldBePositiveNumber-500-02 = ISD-ShouldBePositiveNumber-500-02 : {0} - {1} should be an positive number !
    standardErrorCodesMapping.ISD-UnableToFetch-500-03 = ISD-UnableToFetch-500-03 : {0} - Unable to fetch {1} from database. Please try after some time !
    standardErrorCodesMapping.ISD-UnableToCreate-500-04 = ISD-UnableToCreate-500-04 : {0} - Unable to create {1} !
    standardErrorCodesMapping.ISD-UnableToDelete-500-05 = ISD-UnableToDelete-500-05 : {0} - Unable to delete {1} !
    standardErrorCodesMapping.ISD-UnableToUpdate-500-06 = ISD-UnableToUpdate-500-06 : {0} - Unable to update {1} !
    standardErrorCodesMapping.ISD-UnableToValidate-500-07 = ISD-UnableToValidate-500-07 : {0} - Unable to validate {1} !
    standardErrorCodesMapping.ISD-ServiceUnavailable-503-01 = ISD-ServiceUnavailable-503-01 : {0} - {1} : {2}
    standardErrorCodesMapping.ISD-ServiceUnavailable-503-02 = ISD-ServiceUnavailable-503-02 : {0} - {1}
    standardErrorCodesMapping.ISD-UnKnowHostException-503-03 = ISD-UnKnowHostException-503-03 : {0} - {1}
kind: ConfigMap
metadata:
  labels:
    app: oes
  name: standard-error-codes-config
---
# Source: oes/templates/customstages/ansible-config.yaml
apiVersion: v1
data:
  run.sh: |
        #!/bin/bash

        file="$inventoryfile"

        if test -z "$file"

        then

        echo "No Inventory file specified taking default values"

        exit 1

        else

        echo "Inventory file specified Manually"

        ssh-keygen -t rsa -N "" -f ~/.ssh/id_rsa

        git clone "https://"$gitusername":"$gitpassword"@"$gitrepo""

        host1=$(head -1 $file)

        ip=$(cat $file | head -2 | tail -1)

        host2=$(echo $host1 | cut -d "[" -f2 | cut -d "]" -f1)

        sshpass -p "$userpassword" ssh-copy-id -o StrictHostKeyChecking=no $nodeuser@$ip

        cat $file >> /etc/ansible/hosts

        touch /etc/ansible/group_vars/$host2

        echo "ansible_ssh_user: $nodeuser" > /etc/ansible/group_vars/$host2

        ansible -i /etc/ansible/hosts $host2 -m ping

        ansible-playbook --syntax-check "$ansiblefile"

        ansible-playbook "$ansiblefile"

        fi

kind: ConfigMap
metadata:
  name: ansible-config
---
# Source: oes/templates/customstages/custom-notification-email-config.yaml
apiVersion: v1
data:
  run.sh: |
    #!/bin/sh
    #Install SSMTP
    apk add ssmtp > /dev/null
    #Removing default file
    cat /dev/null >/etc/ssmtp/ssmtp.conf
    #Add configuration in ssmtp.conf file
    ssmtpemail=$(echo "$ssmtpemail" | tr -d [:space:])
    email=$(echo "$email"| tr -d [:space:])
    body=$(echo $body | tr -d [:space:])
    if [ -z $ssmtpemail ]
    then
    echo "not specified smtp email"
    exit 5
    else
    if [ -z $email ]
    then
    echo "not specified the sender email address"
    exit 5
    else
    if [ -z "$body" ]
    then
    echo "not specified the Email body"
    exit 5
    else
    cat <<EOT>> /etc/ssmtp/ssmtp.conf
    root=$ssmtpemail
    mailhub=smtp.gmail.com:587
    AuthUser=$ssmtpemail
    AuthPass=$emailpassword
    UserTLS=YES
    UseSTARTTLS=YES
    rewriteDomain=gmail.com
    hostname=localhost
    FromLineOverride=YES
    EOT
    #add body to file
    touch body.txt
    cat <<EOT>> body.txt
    $body
    EOT
    export MAILFROM="$ssmtpemail"
    export MAILTO="$email,$ccmail"
    export SUBJECT="$subject"
    export BODY="body.txt"
    (
    echo "From: $MAILFROM"
    echo "To: $MAILTO"
    echo "Subject: $SUBJECT"
    cat $BODY
    ) | /usr/sbin/sendmail $MAILTO
    fi
    fi
    fi
kind: ConfigMap
metadata:
  name: email-config
---
# Source: oes/templates/customstages/opsmx-terraspin-backend-config.yaml
apiVersion: v1
data:
  gcloudauth.sh: |
    #!/bin/bash
    #set -x
    jsonkey=$(ls /home/terraspin/opsmx/gcp/)
    if [ -z "$jsonkey" ]
            then
              echo "gcp service account is not configured in backend"
                exit 5
     else
        echo "Authenticating to gcp using service account"

         saemail=$(cat /home/terraspin/opsmx/gcp/$jsonkey | jq -r '.client_email')

          if [ "$?" -eq 0 ]
          then

    export GOOGLE_APPLICATION_CREDENTIALS=/home/terraspin/opsmx/gcp/$jsonkey
    gcloud auth activate-service-account $saemail --key-file=/home/terraspin/opsmx/gcp/$jsonkey > /dev/null


    bash run.sh
    else

    echo "service email is missing in the json key which you stored in backend"
    exit 5
    fi
    fi
  role.sh: "#!/bin/bash\nrole=$awsrole\nns=$namespace\nif [ -z \"$role\" ]\nthen\n
    \   echo \"not provided account name\"\n    exit 5\nelse\n    echo \"Checking
    the account validity\"\n    curl -soq GET \"http://spin-clouddriver-ro.$ns.svc.cluster.local:7002/credentials/$role\"
    --header \"Content-Type: application/json\" > roleinfo.json\n    if [ \"$?\" -eq
    0 ]\n    then\n        ##Extract the assume role from the account info Json using
    the jq\n        awsregion=$(cat roleinfo.json  | jq -r '.regions[].name')\n        awsassumeRole=$(cat
    roleinfo.json | jq -r '.assumeRole')\n        awsaccountId=$(cat roleinfo.json
    | jq -r '.accountId')\n        ##Get the Account Credentials using the Assume
    role \n        aws sts assume-role --role-arn \"arn:aws:iam::$awsaccountId:$awsassumeRole\"
    --role-session-name AWSCLI-Session > creds.json\n        ##Get the Account Credentials
    using the Assume role\n        awsaccesskey=$(cat creds.json | jq -r '.Credentials.AccessKeyId')\n
    \       awssecretkey=$(cat creds.json | jq -r '.Credentials.SecretAccessKey')\n
    \       awssessiontoken=$(cat creds.json | jq -r '.Credentials.SessionToken')\n
    \       export AWS_ACCESS_KEY_ID=$awsaccesskey\n        export AWS_SECRET_ACCESS_KEY=$awssecretkey\n
    \       export AWS_SESSION_TOKEN=$awssessiontoken\n        export AWS_REGION=$awsregion\n
    \       #aws configure list\n        bash run.sh\n    else\n        echo \"In-Valid
    account $role\"\n        exit 1\n    fi\nfi\n"
  run.sh: "#!/bin/bash \n#set -x\n\nterraformcommand=\"$command\"\nscriptact=$(echo
    \"$scriptaccount\" | tr -d [:space:])\ntfrepo=$(echo \"$repo\" | tr -d [:space:])\ntflocation=$(echo
    \"$location\" | tr -d [:space:])\noverride=$(echo \"$overridefile\" | tr -d [:space:])\nTFCMD=$(echo
    \"$terraformcommand\" | tr -d [:space:])\nstatefolder=$(echo \"$staterep\" | awk
    -F/ '{print $2}' | sed 's/\\.git\\>//g')\n\necho \"-------- Terraform Command
    ----------\"\necho \"            $TFCMD                   \"\necho \"-------------------------------------\"\n\nif
    [ -z $scriptact ]\nthen\n\techo \" Not Specified the Tf script account \"\n\texit
    1\nelse\n\tcheckaccount=$(cat /home/terraspin/opsmx/app/config/artifactaccounts.json
    | jq -r '.[][] | select (.accountname == \"'$scriptact'\")')\n\tif [ -z \"$checkaccount\"
    ]\n\tthen\n\t\techo \"Script Account is Not there artifactaccounts.json\"\n\t\texit
    1\n\telse\n\t\techo \"Script account is located in artifactaccounts.json\"\n\t\tusername=$(cat
    /home/terraspin/opsmx/app/config/artifactaccounts.json | jq -r '.[][] | select
    (.accountname == \"'$scriptact'\")|.username')\n\t\tpassword=$(cat /home/terraspin/opsmx/app/config/artifactaccounts.json
    | jq -r '.[][] | select (.accountname == \"'$scriptact'\")|.password')\n\t\thost=$(cat
    /home/terraspin/opsmx/app/config/artifactaccounts.json | jq -r '.[][] | select
    (.accountname == \"'$scriptact'\")|.host')\n                echo host $host\n\t\thosturl=$(echo
    ${host##*/})\n\t\tif [[ \"$tfrepo\" == *//* ]]\n                then\n                        echo
    \"checking the input Artifact repo  and branch\"\n                        tfbranch=$(echo
    $tfrepo | awk -F// '{print $2}')\n                        tfrepo=$(echo $tfrepo
    | awk -F// '{print $1}')\n                                if [[ \"$tfrepo\" ==
    */* ]] && [[ $tfrepo == *\".git\"* ]]\n                                then\n
    \                                       echo \"valid Artifact repo  name\"\n                                        if
    [ -z $tfbranch ]\n                                        then\n                                                 echo
    \"invalid input format of Artifact repo specify as ....> org/repo.git//branch\"\n
    \                                                exit 5\n                                         else\n
    \                                                echo \"Artifact repo Branch specified
    as $tfbranch\"\n                                         fi\n                                 else\n
    \                                        echo \"In valid repo name format of Artifact
    repo should be....> Org/repo.git \"\n                                         exit
    5\n                                 fi\n                         \n                 else\n
    \                        echo \"invalid input format of Artifact repo specify
    as ....>  org/repo.git//branch\"\n                         exit 5\n                 fi\n\tfi\nfi\n\n\n###################################################\n#TERRADORM
    COMMANDS FUNCTIONALITY \n###################################################\nif
    [ $TFCMD == \"plan\" ]\nthen\n    echo \"Plan executing............\"\n    cd
    $HOME\n    git clone https://$username:$password@$hosturl/$tfrepo workspace -b
    $tfbranch > /dev/null\n    cd workspace/$tflocation\n    TF_WORKSPACE=$TF_WORKSPACE
    terraform init\n    if [ $? -eq 0 ]; then\n       echo \"Terraform Init Completed\"\n
    \   else \n        echo \"$TF_WORKSPACE workspace does not exists... creating
    newly\"\n        terraform workspace new $TF_WORKSPACE\n        TF_WORKSPACE=$TF_WORKSPACE
    terraform init -reconfigure\n        echo \"Terraform Init Completed\"\n    fi\n
    \   terraform validate\n    if [ -z $override ]\n    then\n#\t    echo \"Not Specified
    the Override File\"\n\t    terraform plan -out=terraform.plan\n    else\n\t    terraform
    plan -var-file=$override -out=terraform.plan\n    fi\n    if [ $? -eq 0 ]; then\n\t
    \   echo \"Terraform Plan Completed\"\n    \n    else\n\t    echo Terraform Plan
    FAILED\n\t    exit 5\n    fi\n\nelif [ $TFCMD == \"apply\" ]\nthen\n    echo \"Apply
    executing...........................\"\n     cd $HOME\n     git clone https://$username:$password@$hosturl/$tfrepo
    workspace -b $tfbranch > /dev/null\n     cd workspace/$tflocation\n     TF_WORKSPACE=$TF_WORKSPACE
    terraform init\n     terraform validate\n     #terraform plan -var-file=$override
    -out terraform.plan\n\tif [ -z $override ]\n\tthen\n\t\t#echo \"Not Specified
    the Override File\"\n\t\tterraform apply -auto-approve\n\t\tif [ $? -eq 0 ]; then\n\t\t\techo
    \"------------------------------------------------\"\n\t\t\techo \"           Terraform
    Apply Completed            \"\n\t\t\techo \"------------------------------------------------\"\n\t\t\techo
    \"SPINNAKER_PROPERTY_TERRAFORMAPPLY=\"COMPLETED\"\"\n\t\t\tFILE=outputs.tf\n\t\t\tif
    test -f \"$FILE\"; then\n\t\t\t\techo \"$FILE exists.\"\n\t\t\t\tterraform output
    > outputvariables\n\t\t\t\tcat outputvariables | tr -d ' ' | tr -d '\"'\n\t\t\tfi\n\t\telse\n\t\t\techo
    Terraform Apply  FAILED\n                        echo \"SPINNAKER_PROPERTY_TERRAFORMAPPLY=\"FAILED\"\"\n
    \                       exit 5\n\t\tfi\n\n\telse\n\t\tterraform apply -var-file=$override
    -auto-approve\n\t\tif [ $? -eq 0 ]; then\n                        echo \"------------------------------------------------\"\n
    \                       echo \"           Terraform Apply Completed            \"\n
    \                       echo \"------------------------------------------------\"\n
    \                       echo \"SPINNAKER_PROPERTY_TERRAFORMAPPLY=\"COMPLETED\"\"\n\t\t\tFILE=outputs.tf\n\t\t\tif
    test -f \"$FILE\"; then\n\t\t\t\techo \"$FILE exists.\"\n\t\t\t\tterraform output
    > outputvariables\n\t\t\t\tcat outputvariables | tr -d ' ' | tr -d '\"'\n\t\t\tfi\n\t\telse\n
    \                       echo Terraform Apply  FAILED\n                        echo
    \"SPINNAKER_PROPERTY_TERRAFORMAPPLY=\"FAILED\"\"\n                        exit
    5\n                fi\n\n\n\tfi\n\nelif [ $TFCMD == \"destroy\" ]\nthen\n    echo
    \"Destroy executed\"\n\t\t     cd $HOME\n                     git clone https://$username:$password@$hosturl/$tfrepo
    workspace -b $tfbranch > /dev/null\n                     cd workspace/$tflocation\n
    \                    TF_WORKSPACE=$TF_WORKSPACE terraform init\n                     terraform
    validate\n\n                        if [ -z $override ]\n                        then\n
    \                             #  echo \"Not Specified the Override File\"\n                                terraform
    destroy -auto-approve\n\t\t\t\tif [ $? -eq 0 ]; then\n\t\t\t\t\techo \"------------------------------------------------\"\n\t\t\t\t\techo
    \"           Terraform Destroy Completed            \"\n\t\t\t\t\techo \"------------------------------------------------\"\n\t\t\t\t\techo
    \"SPINNAKER_PROPERTY_TERRAFORMDESTROY=\"COMPLETED\"\"\n\t\t\t\telse\n\t\t\t\t\techo
    \"Terraform Destroy Failed\"\n\t\t\t\t\texit 5\n\t\t\t\tfi\n\t\t\telse\n                                terraform
    destroy -var-file=$override -auto-approve\n\t\t\t\tif [ $? -eq 0 ]; then\n                                        echo
    \"------------------------------------------------\"\n                                        echo
    \"           Terraform Destroy Completed          \"\n                                        echo
    \"------------------------------------------------\"\n                                        echo
    \"SPINNAKER_PROPERTY_TERRAFORMDESTROY=\"COMPLETED\"\"\n                                else\n
    \                                       echo \"Terraform Destroy Failed\"\n\t\t\t\t\texit
    5\n                                fi\n\n                        fi\nelse\n    echo
    \"Not able to validate Terraform state \"plan\" or \"apply\" or \"destroy\" \"\nfi\n"
kind: ConfigMap
metadata:
  name: opsmx-terraspin-backend-config
---
# Source: oes/templates/customstages/updatepr-config.yaml
apiVersion: v1
data:
  run.sh: "#!/bin/sh\naccesstoken=$(echo \"$accesstoken\" | tr -d [:space:])\nmethod=$(echo
    \"$method\"| tr -d [:space:])\nurl=$(echo $url | tr -d [:space:])\nif [ -z $accesstoken
    ]\nthen\n\techo \"not specified accesstoken\"\n\texit 5\nelse\n\tif [ -z $method
    ]\n\tthen\n\t\techo \"not specified the method ....POST\"\n\t\texit 5\n\telse\n\t\tif
    [ -z \"$url\" ]\n\t\tthen\n\t\t       echo \"not specified the URL\"\n\t\t       exit
    5\n\t       else\n\t\t       curl -s -H \"Authorization: token $accesstoken\"
    -X $method -d '{\"body\":\"'\"$payload\"'\"}' \"$url\"\n\t\t       if [ $? -eq
    0 ]\n\t\t       then\n\t\t\t       echo \"curl call succeded\"\n\t\t       else\n\t\t\t
    \      echo Curl call not succeded with the URL $url\n\t\t\t       exit 5\n\t\t
    \      fi\n\t       fi\n       fi\nfi\n"
kind: ConfigMap
metadata:
  name: updatepr-config
---
# Source: oes/templates/forwarder/oes-forwarder-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: opsmx-controller-controller1
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
data:
  configFile: |
    serviceHostname: opsmx-controller-controller1
    agentHostname: controller.exampleopsmx.net
    remoteCommandHostname: controller.exampleopsmx.net
    controlHostname: opsmx-controller-controller1
    #agentAdvertisePort: "443"
    serviceAuth:
      currentKeyName: "public.pem"
      headerMutationKeyName: "public.pem"
    services:
      outgoingServices:
        - name: front50
          type: front50
          enabled: true
          config:
            url: http://spin-front50:8080
        - name: fiat
          type: fiat
          enabled: true
          config:
            url: http://spin-fiat:7003
      incomingServices:  # This part is to be automated in the next version. For now, the agent MUST be called opsmx-agent
        - name: agent-clouddriver
          serviceType: clouddriver
          port: 7002
          useHTTP: true
          destination: opsmx-agent
          destinationService: agent-clouddriver
---
# Source: oes/templates/pipeline-promotion/pipe-promot-config-cm.yaml
apiVersion: v1
data:
  repo.properties: |
    #properties file for pipeline promotion scripts

    # Common Stuff
    repo_type=git
    repo_name=repo_name
    root_folder=pipeline/
    #S3 Specific
    export AWS_ACCESS_KEY_ID=access_key
    export AWS_SECRET_ACCESS_KEY=secret_key

    #git mandatory patameters
    git_url=example.repo.com
    git_project=project_name
    git_user=username
    git_branch=samplerepo
    #git_password=
    #API
    git_api_url=https://api.github.com/repos  # bitbucket

    #Auto PR requirements
    merge_branch=false
    auto_merge=false
    git_approve_user=approver_user
    target_branch=master

    #optional
    #git_user_email=krish@company.com

    #delete pipeLine
    delete_on_sync_spin=
    delete_on_sync_repo=
    #git_approve_user_password=
    #git_secret_sshkey=
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: pipe-promot-config
---
# Source: oes/templates/pipeline-promotion/pipe-promot-scripts-cm.yaml
apiVersion: v1
data:
  bitbucket.sh: |
    #!/bin/bash
    #this script funtions only work for bitbucket central repository
    #this script funtions only work for git repo
    #env variables needed for this to work are as below
    #***git_url="example.bitbucket.com" make sure you dont add http/https or / in the url
    #****git_repo="pipelinepromotion" repo to be pushed/download pipeline json files from
    #***git_project="kes" project key is needed to clone/push/pull merge code
    #***git_user="tes.user" user is needed for cloning and pusing changes (stash does not support only access key)
    #***git_branch="testbranch" the branch to which the code should be merged with
    #***merge_branch=false if true then provide all the below env variables
    #   git_secret_token="dafjaljoahfoasjoijso" needed to create pull requests should be the git_users secret token
    #   git_pr_token="slkdfjaljoajfopaj" this is approver token to approve pull requests / you can also provide approver password here.
    #   git_approve_user="test.approver"  username of the pull request approver
    #   git_password="adjoowddaw" make sure your password does not include special characters like # @*/. special characters cause git clone command to fail with https
    #  repo_type="stash" for selfhosted bitbucket server please use stash as repo type
    #***root_folder="path/to/pipeline-promotion/folder" folder to be selected in the repo to which the pipeline jobs to be pushed
    #***command=upload for running specific job -
    #                                         upload - to upload spinnaker pipeline json files to repo
    #                                         download - to download pipeline json file from repo and apply on spinnaker
    #***spinnaker_applications="testapp,sampleapp" application needed to collect the pipeline information
    #spinnaker_pipelines="" provide pipelines to be collected, if nothing given, all the pipelines of the application are collected
    #git_secret_sshkey="sshkey" ssh key if you want to clone repo with ssh protocol
    # note *** env variables are mandatory to work with the script

    source scripts/git.sh
    git_bitbucket_api=$git_api_url
    pr_id=0
    approve_pr_bitbucket(){
      approve_req=$(curl -X POST -u $git_approve_user:$git_pr_token \
      $git_bitbucket_api${git_project}/${git_repo}/pullrequests/${pr_id}/approve -o -I -L -s -w "%{http_code}")
      echo $approve_req
      if [[ $approve_req == "200" ]];then
        echo "merge request approved successfully"
      else
        echo "FAIL: failed to approve the request "
        exit 1
      fi
    }
    merge_pr_bitbucket(){
      merge_req=$(curl  -X POST -u $git_user:$git_secret_token   \
      $git_bitbucket_api${git_project}/${git_repo}/pullrequests/${pr_id}/merge -o -I -L -s -w "%{http_code}")
      echo $merge_req
      if [[ $merge_req == 200  ]]; then
        echo "merged pr successfully"
      elif [[ $merge_req == 202 ]]; then
        echo "merging is in progress will be merged in less than a min"
      else
        echo "FAILED: failed to merge $merge_pr"
        exit 1
    fi
    }
    create_pr_bitbucket(){
      local output=$(curl  -X POST -H "Content-Type: application/json" -u $git_user:$git_secret_token   $git_bitbucket_api${git_project}/${git_repo}/pullrequests -d '{
        "title": "merging '$git_branch' to '$target_branch'",
        "source": {
                "branch": {
                    "name": "'$git_branch'"
                }
            },
            "destination": {
                "branch": {
                    "name": "'$target_branch'"
                }
            }
    }')
      echo $output
      echo $output > pr_response.json
      grep  "There are no changes to be pulled" pr_response.json
      if [ "$?" = 0 ]
      then
        echo "master branch is already up-to-date"
        exit 0
      else
        pr_id=$(cat  pr_response.json| jq '(.id)' | sed 's/\"//g')
        if [ $? = 0 ]; then
          echo "successfully created pull request "
          #rm -f pr_response.json
        else
          echo "ERROR: failed to raise pull request $output"
          exit 1
      fi
    fi
    }
    sync_spin_to_bitbucket(){
      setup_git
      sync_spin_to_git
      if [[ $merge_branch == "true" && $target_branch != "" && ($git_branch != $target_branch)  ]];then
        if [[ $git_api_url_port != "" ]];then
          git_bitbucket_api=$git_bitbucket_api:$git_api_url_port
          create_pr_bitbucket
          if [[ $auto_merge == "true" ]]; then
            approve_pr_bitbucket
            sleep 5
            merge_pr_bitbucket
          fi
        else
          create_pr_bitbucket
          if [[ $auto_merge == "true" ]]; then
            approve_pr_bitbucket
            sleep 5
            merge_pr_bitbucket
          fi
        fi
      fi
    }
  deployer.sh: |
    #!/bin/bash
    echo "In deployer.sh"
    SBASE=scripts
    source config/repo.properties
    BRANCH_NAME_UI=$(echo $branch_ui | sed 's/[][]//g')
    echo $BRANCH_NAME_UI
    if [ -z "$BRANCH_NAME_UI" ]
    then
      echo "Not Provided the Branch in the spinnaker UI....Continuing with the default branch specified in configmap"
      echo $git_branch
    else
      echo "Provided the User defined Branch in spinnaker UI"
      git_branch=$BRANCH_NAME_UI
      echo $git_branch
    fi
    ROOT_FOLDER_UI=$(echo $rootfolder_ui | sed 's/[][]//g')
    echo $ROOT_FOLDER_UI
    if [ -z "$ROOT_FOLDER_UI" ]
    then
      echo "Not Provided the Save Path in the spinnaker UI....Continuing with the default path specified in configmap"
      echo $root_folder
    else
      echo "Provided the User defined Branch in spinnaker UI"
      root_folder=$ROOT_FOLDER_UI
      echo $root_folder
    fi
    source $SBASE/spin.sh
    source $SBASE/stash.sh
    source $SBASE/s3.sh
    source $SBASE/github.sh
    source $SBASE/bitbucket.sh
    echo "Sourcing complete"
    sync_repo_from_spinnaker(){
      if [[ $repo_type = "s3" ]];
      then
        upload_spin_to_s3
      elif [[ $repo_type = "stash" ]]; then
        sync_spin_to_stash
      elif [[ $repo_type == "bitbucket" ]]; then
        sync_spin_to_bitbucket
      elif [[ $repo_type = "git" ]]; then
        sync_spin_to_github
      elif [[ $repo_type = "gitea" ]]; then
        sync_spin_to_github
      else
        echo "Not specified Repo type"
        exit 5
      fi
    }
    sync_spinnaker_from_repo(){
      if [[ $repo_type = "s3" ]];
      then
        sync_from_s3_spin
      elif [[ $repo_type = "stash" || $repo_type = "git" || $repo_type = "bitbucket" ]]; then
        sync_git_to_spin
      elif [[ $repo_type = "gitea" ]]; then
        sync_git_to_spin
      fi
    }
    if [[ "$command" == "download" ]]; then
      sync_spinnaker_from_repo
    elif [[ "$command" == "upload" ]]; then
      echo "executing upload"
      #statement
      sync_repo_from_spinnaker
    else
      echo "ERROR: unknown command"
    fi
    echo "Done executing"
  git.sh: |
    #!/bin/bash
    source scripts/spin.sh
    git_repo=$repo_name
    tempdir="/tmp/"
    pull_requred=false
    branch_check() {
    if [[ $git_branch == "" ]]
    then
      cd $tempdir/$git_repo
      defaultbranch=$(git branch | awk '{print $2}')
      git_branch="$defaultbranch"
      echo "WAR: Not specified the branch to push the pipeline json, Considering the default branch $git_branch ..."
      cd -
    fi
    }
    setup_git() {
      echo "Setting up the Git "
      local name=${git_user:-spinnaker}
      local email=${git_user_email:-phani@opsmx.io}
      git config --global user.email "$email"
      git config --global user.name "$name"
    }
    validate_clone() {
      if [ $? == 0 ]
      then
        echo "Cloning done ${git_repo}"
      else
        echo "Cloning failed with repo ${git_repo}, Please check credentials and repo access...."
        exit 5
      fi
      branch_check
    }
    git_clone_http() {
      echo "cloning $git_project/$git_repo over https"
      if [[ $repo_type == "git" || $repo_type == "bitbucket" ]]; then
        clone_result=$(git clone https://$git_user:${git_secret_token}@${git_url}/${git_project}/${git_repo}.git $tempdir/$git_repo 2> /dev/null)
        validate_clone
      elif [[ $repo_type == "gitea" ]]; then
        clone_result=$(git clone http://$git_user:${git_secret_token}@${git_url}/${git_project}/${git_repo}.git $tempdir/$git_repo 2> /dev/null)
        validate_clone
      elif [[ $repo_type == "stash" ]]; then
        #statements
        if [[ $git_url_port != "" ]]; then
          clone_result=$(git  clone https://$git_user:${git_secret_token}@${git_url}:$git_url_port/scm/${git_project}/$git_repo.git $tempdir/$git_repo 2> /dev/null)
          validate_clone
        else
          clone_result=$(git  clone https://$git_user:${git_secret_token}@${git_url}/scm/${git_project}/$git_repo.git $tempdir/$git_repo 2> /dev/null)
          validate_clone
        fi
      fi
      #echo $clone_result
    }
    load_ssh(){
      mkdir /home/opsmx/.ssh
      cp /etc/git-secret/git_secret_sshkey ~/.ssh/id_rsa
      chmod 400 ~/.ssh/id_rsa
      ssh-keyscan github.com >> ~/.ssh/known_hosts
    }
    git_clone_ssh(){
      echo "cloning $git_project/$git_repo over ssh"
      if [[ $repo_type == "git" || $repo_type == "bitbucket" ]]
      then
        load_ssh
        clone_result=$(git clone git@${git_url}:${git_project}/$git_repo.git $tempdir/$git_repo 2> /dev/null)
        validate_clone
      elif [[ $repo_type == "stash" && $git_url_port != "" ]]; then
        #statements
        clone_result=$(git clone ssh://git@${git_url}:$git_url_port/${git_project}/$git_repo.git $tempdir/$git_repo 2> /dev/null)
      else
        clone_result=$(git clone ssh://git@${git_url}:${git_project}/$git_repo.git $tempdir/$git_repo $tempdir/$git_repo 2> /dev/null)
      fi
      #echo $clone_result
    }
    git_add_file() {
      local file=$1
      git add $file
    }
    git_add_all() {
      git add $1
    }
    git_tag_all() {
      git tag -a Backup-$TAGSTAMP -m "$msg"
      git push --tags
    }
    git_delete_file() {
      local file=$1
      git rm $file
    }
    git_checkout_branch(){
      all_branches=$(git branch -r| grep -w  origin/$git_branch)
      echo $all_lbranches
      if [[ $all_branches != "" ]]
      then
        branch_checkout_result=$(git checkout $git_branch)
        echo $branch_checkout_result
        pull_requred=true
      else
        git checkout -b $git_branch
      fi
    }
    git_add_all(){
      git add $1
    }
    git_commit_all() {
      local branch=$git_branch
      local msg="checking application and pipeline raw data"
      if [ "$pull_requred" = true ]; then
        git pull origin $branch --no-edit
        if [ "$?" != "0" ];then
         echo "[ERROR]: Failed to pull $branch upstream."
         exit 1
        fi
      fi
      opts=""
      if [ "$git_commit_sign" == "true" ]; then
        opts="-s"
      fi
      #git commit $opts -a -m $msg
      git commit -m "$msg"
      git push --set-upstream origin $branch
      if [ "$?" != "0" ];then
        echo "[ERROR]: Failed to push $branch upstream."
        exit 1
      fi
    }
    sync_spin_to_git() {
      echo "In upload function which copies spinnaker application and pipeline from spinnaker to repo"
      local user_root_folder=$root_folder
      if [ "$git_secret_sshkey" != "" ]; then
        git_clone_ssh
      elif [ "$git_secret_token" != "" ]; then
        git_clone_http
      else
        echo "git cloning requires either a git_aws_secret_key to be set or git_aws_secret_token"
       exit 5
      fi
      projectdir=$tempdir/$git_repo
      cd $projectdir
      #We are done, get update git
      git_checkout_branch
      if [ -z $spinnaker_applications ]
      then
        spin application list > app.json
        spinnaker_app=$(cat app.json | jq -r '[.[].name]| @csv' | sed 's/","/,/g; s/^"\|"$//g')
        rm -rf app.json
        get_pipelines_data  $spinnaker_app
      else
        get_pipelines_data  $spinnaker_applications
      fi
      git_add_all $root_folder
      git_commit_all
      return 0
    }
    sync_git_to_spin(){
      setup_git
      if [ "$git_secret_sshkey" != "" ]; then
        git_clone_ssh
      elif [ "$git_secret_token" != "" ]; then
        git_clone_http
      else
        echo "git cloning requires either a git_aws_secret_key to be set or git_aws_secret_token"
       exit 5
      fi
      projectdir=$tempdir/$git_repo
      cd $projectdir
      git_checkout_branch
      syncup_spin
    }
  github.sh: |
    #!/bin/bash
    #this script funtions only work for github central repository
    #this script funtions only work for git repo
    #env variables needed for this to work are as below
    #***git_url="example.bitbucket.com" make sure you dont add http/https or / in the url
    #****git_repo="pipelinepromotion" repo to be pushed/download pipeline json files from
    #***git_project="kes" project key is needed to clone/push/pull merge code
    #***git_user="tes.user" user is needed for cloning and pusing changes (stash does not support only access key)
    #***git_branch="testbranch" the branch to which the code should be merged with
    #***merge_branch=false if true then provide all the below env variables
    #   git_secret_token="dafjaljoahfoasjoijso" needed to create pull requests should be the git_users secret token
    #   git_pr_token="slkdfjaljoajfopaj" this is approver token to approve pull requests / you can also provide approver password here.
    #   git_approve_user="test.approver"  username of the pull request approver
    #   git_password="adjoowddaw" make sure your password does not include special characters like # @*/. special characters cause git clone command to fail with https
    #  repo_type="stash" for selfhosted bitbucket server please use stash as repo type
    #***root_folder="path/to/pipeline-promotion/folder" folder to be selected in the repo to which the pipeline jobs to be pushed
    #***command=upload for running specific job -
    #                                         upload - to upload spinnaker pipeline json files to repo
    #                                         download - to download pipeline json file from repo and apply on spinnaker
    #***spinnaker_applications="testapp,sampleapp" application needed to collect the pipeline information
    #spinnaker_pipelines="" provide pipelines to be collected, if nothing given, all the pipelines of the application are collected
    #git_secret_sshkey="sshkey" ssh key if you want to clone repo with ssh protocol
    # note *** env variables are mandatory to work with the script

    source scripts/git.sh
    git_hub_api_url=$git_api_url
    approve_pr_github(){
      approve_req=$(curl -o -I -L -s -w "%{http_code}" -X POST -H "Accept: application/vnd.github.v3+json" -u $git_approve_user:$git_pr_token  $git_hub_api_url/$git_user/${git_repo}/pulls/${pr_id}/reviews \
      -d '{"body": "Spinnaker says LGTM","event": "APPROVE"}')
      echo $approve_req
      if [[ $approve_req == "200" ]];then
        echo "merge request approved successfully"
      else
        echo "FAIL: failed to approve the request $"
        exit 1
      fi
    }
    merge_pr_github(){
      merge_req=$(curl -o -I -L -s -w "%{http_code}" -X PUT -H "Accept: application/vnd.github.v3+json" -u $git_user:$git_secret_token $git_hub_api_url/$git_user/${git_repo}/pulls/${pr_id}/merge)
      echo $merge_req
      if [[ $merge_req == "200" ]]; then
        echo "merged pr successfully"
      else
        echo "FAILED: failed to merge $merge_pr"
        exit 1
    fi
    }
    create_pr_github(){
      local output=$(curl  -X POST -H "Accept: application/vnd.github.v3+json" -u $git_user:$git_secret_token $git_hub_api_url/${git_user}/${git_repo}/pulls \
      -d '{"title": "pull request to merge '$git_branch' to master","body": "pull request to merge latest pipleine jobs information to '$target_branch'", "head": "'${git_branch}'","base": "'$target_branch'"}')
      if [ "$?" != 0 ]
      then
        echo "master branch is already up-to-date"
        exit 0
      else
        echo $output
        echo $output > pr_response.json
        errors=$(cat  pr_response.json| jq '(.errors)' | sed 's/\"//g')
        if [[ $errors != null ]]; then
          echo "ERROR: failed to raise pull request $errors"
          exit 1
        fi
        pr_id=$(cat  pr_response.json| jq '(.number)' | sed 's/\"//g')
        if [[  $pr_id != ""  ]]; then
          echo "successfully created pull request "
        else
          echo "ERROR: failed to raise pull request $output"
          exit 1
      fi
    fi
    }
    sync_spin_to_github(){
      setup_git
      sync_spin_to_git
      if [[ $merge_branch == "true" && $target_branch != "" && ($git_branch != $target_branch)  ]];then
        if [[ $git_api_url_port != "" ]];then
          git_hub_api_url=$git_hub_api_url:$git_api_url_port
          create_pr_github
          if [[ $auto_merge == "true" ]]; then
            approve_pr_github
            merge_pr_github
          fi
        else
          create_pr_github
          if [[ $auto_merge == "true" ]]; then
            approve_pr_github
            merge_pr_github
          fi
        fi
      fi
    }
  s3.sh: |
    #!/bin/bash
    source scripts/spin.sh
    absolute_path="$(dirname $(readlink -f $0))"
    # s3_folder=folder/in/s3/bucket if not given script uploads to root folder or the s3 bucket
    # ***bucket_name=testenvpipelinebucket "bucktet name to upload pipeline configuration"
    # ***AWS_ACCESS_KEY_ID="SKJGIHOBGIHIHOOH" access key to access s3 bucket
    # ***AWS_SECRET_ACCESS_KEY="sdfjlasj2e334234sdljflsjflsd98y9sy/0UVv6eCg" secret to access s3 bucket
    # ***repo_type=s3 provide repo type as s3
    #***command=upload for running specific job -
    #                                         upload - to upload spinnaker pipeline json files to repo
    #                                         download - to download pipeline json file from repo and apply on spinnaker
    #***spinnaker_applications="testapp,sampleapp" application needed to collect the pipeline information
    #spinnaker_pipelines="" provide pipelines to be collected, if nothing given, all the pipelines of the application are collected

    # note *** env variables are mandatory to work with the script
    s3_folder=$root_folder
    tempdir="/tmp/"
    bucket_name=$repo_name
    create_bucket(){
      #to create a bucket in s3 bucket name needed
      aws s3 mb s3://$bucket_name
      if [ $? != 0 ]; then
        echo "[ERROR]: Failed to create s3 bucket  might be aleady existing"
      fi
    }

    list_bucket(){
      # to llst bucket objects
      aws s3 ls s3://$bucket_name/
      if [ $? != 0 ]; then
        echo "[ERROR]: Failed to list s3 bucket "
      fi
    }

    list_application_folder(){
      # to list an object folder
      aws ls s3://$bucket_name/${s_folder}/$1 | awk '{print $4}'
    }

    upload_spin_to_s3(){
      # get the pipeline data from spinnaker and store in root_folder
      echo APP $spinnaker_applications
      if [ -z $spinnaker_applications ]
      then
        spin application list > app.json
        spinnaker_app=$(cat app.json | jq -r '[.[].name]| @csv' | sed 's/","/,/g; s/^"\|"$//g')
        rm -rf app.json
        get_pipelines_data $spinnaker_app
      else
        get_pipelines_data $spinnaker_applications
      fi
      #  get_pipelines_data
      #upload spinnaker pipelines data and upload to s3 folder
      aws s3 cp $tempdir/$bucket_name/$s3_folder s3://$bucket_name/$s3_folder --recursive
      if [ "$?" != 0 ]; then
        echo "[ERROR]: Failed to upload to bucket" $bucket_name
      else
        echo "uploaded to bucket successfully"
      fi
    }
    sync_from_s3_spin(){
      echo "downloading  spinnaker application pipelines configuration"
      aws s3 sync  s3://$bucket_name/$s3_folder $tempdir$s3_folder
      #apply configuration in spinnaker
      syncup_spin
    }
    delete_s3_object(){
      #delete an object in bucket
      aws rm s3://$bucket_name/${s3_folder}/${application_name}/  --recursive
      if [ $? != 0 ]; then
        echo "[ERROR]: Failed to delete s3 application folder "
      else
        echo "created bucket successfully"
      fi
    }
  spin.sh: |
    #!/bin/bash
    #source $(dirname $0)/git.sh
    tempdir="/tmp/"
    #spinnaker_applications="sampleapp"
    get_app_pipelines(){
      spin pipeline list --application $1  > tmp.json
      if [ "$?" != "0" ]; then
        echo "ERROR: spin pipeline list --application $1"
        return 1
      fi
      cat tmp.json | jq '.[] | (.name)' | sed 's/\"//g' > pipelines_in_application.list
      cat tmp.json | jq '.[] | (.id)' | sed 's/\"//g' > pipelines_guid.list
      rm tmp.json
    }

    live_backup_spin() {
    #This function will backup existing spinnaker data and store it in local for further comparison
      if [[ $repo_type = "s3" ]]; then
        projectdir=$tempdir/$root_folder
      else
        projectdir=$tempdir/${git_repo}/$root_folder
      fi
      live_projectdir_workdir=$projectdir/live_backup
      if [ -d "$live_projectdir_workdir" ]
      then
        echo "given live_spinnaker_project_work_dir is present"
      else
        echo "given live_spinnaker_project_work_dir is not present therefore creating it"
        mkdir -p "$projectdir/live_backup"
      fi
      cd $live_projectdir_workdir
      spinnaker_app=$spinnaker_applications
      IFS=',' read -r -a spinnaker_app_array <<< "$spinnaker_app"

      spinnaker_pipe=$spinnaker_pipelines
      IFS=',' read -r -a spinnaker_pipe_array <<< "$spinnaker_pipe"

      for (( m=0; m<${#spinnaker_app_array[@]}; m++ )); do
         sourceApp=${spinnaker_app_array[$m]}
         echo -e "Processing application $sourceApp\n"
         mkdir -p $sourceApp ; cd $sourceApp
         # Get into the correct directory
         spin -k pipeline list --application $sourceApp  > tmp.json
         if [ "$?" != "0" ]; then
           echo "ERROR: spin pipeline list --application $sourceApp"
           return 1
         fi
         cat tmp.json | jq '.[] | (.name)' | sed 's/\"//g' > live_pipelines_in_application.list
         cat tmp.json | jq '.[] | (.id)' | sed 's/\"//g' > live_pipelines_guid.list
         rm tmp.json

         spin -k application get $sourceApp  > $sourceApp.json
         if [ "$?" != "0" ]; then
           echo "ERROR: spin application get $sourceApp"
           return 1
         fi

         if [[ ${#spinnaker_pipe_array[@]} > 0 ]]; then
           for (( p=0; p<${#spinnaker_pipe_array[@]}; p++ )); do
                pipeLine=${spinnaker_pipe_array[$p]}
                echo -e "    Processing pipeline $pipeLine\n"
                # Check if pipeline exists
                existingPipe=`grep \^${pipeLine}\$ live_pipelines_in_application.list`
                if [[ "$existingPipe" == "${pipeLine}" ]]; then
                   spin -k pipeline get --application $sourceApp  --name "$pipeLine" > "$pipeLine.json"
                   if [ "$?" != "0" ]; then
                       echo "ERROR: spin spin pipeline get --application $sourceApp  --name \"$pipeLine\""
                       return 1
                   fi
                else
                   echo "WARNING: pipeline=${pipeLine} not found in application=$sourceApp ... skipping"
                fi
             done
         else # No pipelines defined, get all the pipelines
             while read -r line; do
                echo -e "    Processing pipeline $line\n"
                spin -k pipeline get --application $sourceApp --name "$line" > "$line.json"
                if [ "$?" != "0" ]; then
                  echo "ERROR: spin spin pipeline get --application $sourceApp  --name $line"
                  return 1
                fi
             done < live_pipelines_in_application.list
         fi
         cd ..
      done
      return 0
    }

    delete_odd_pipelines() {
      #Delete the additional pielines that are in spinnaker and not in git
      for (( m=0; m<${#spinnaker_app_array[@]}; m++ )); do
        sourceApp=${spinnaker_app_array[$m]}
        if [ -f "$projectdir/live_backup/$sourceApp/odd_pipeline.txt" ]; then
          if [ ! -s "$projectdir/live_backup/$sourceApp/odd_pipeline.txt" ]; then
            echo "no new pipelines to delete"
          else
            echo "============ Delete pipeline in $sourceApp Application ============="
            while IFS= read -r pipelinename; do
              echo "Deleting the pipeline $pipelinename"
              spin -k pipeline delete --name $pipelinename --application $sourceApp
            done < $projectdir/live_backup/$sourceApp/odd_pipeline.txt
            rm -rf $projectdir/live_backup/$sourceApp/odd_pipeline.txt
          fi
        fi
      done
    }
    #Create default parameterconfig-files
    create_default_params() {
      targetDir=${1:-default-config}
      echo "Processing pipelines and creating output in $targetDir"
      mkdir -p $targetDir
      for json in *.json ; do
        [[ -f "$json" ]] || continue
          echo "processing $json"
          cat "$json" | jq '.parameterConfig | reduce .[] as $p  ({};.Parameters += {($p.name): $p.default})'  >  $targetDir/tmp-param.json 2>/dev/null
          cat "$json" | jq '.triggers[0] '  >  $targetDir/tmp-trig.json 2>/dev/null
          if [[ `cat $targetDir/tmp-trig.json | wc -c` -gt 5 ]]
          then
            cat $targetDir/tmp-param.json | jq '.triggerValues=$pp' --argfile pp $targetDir/tmp-trig.json > $targetDir/"$json" 2>/dev/null
          else
            cp  $targetDir/tmp-param.json $targetDir/"$json"
          fi
        done
        rm -f $targetDir/tmp-param.json
        rm -f $targetDir/tmp-trig.json
        #Remove all files with zero size
        echo "Removing files that do not have any parameters defined"
        find $targetDir -type f -size -4c -delete # No parameterConfig in the file
        #find $targetDir -type f -size -4c -print -delete # No parameterConfig in the file
    }

    equate_pipelines_in_app() {
     #This function will comapre the applications and pipelines in git and spinnaker and gives the additional pipelines data
      IFS=',' read -r -a spinnaker_app_array <<< "$spinnaker_app"
      IFS=',' read -r -a spinnaker_pipe_array <<< "$spinnaker_pipe"
      for (( m=0; m<${#spinnaker_app_array[@]}; m++ )); do
         sourceApp=${spinnaker_app_array[$m]}
         touch $projectdir/live_backup/$sourceApp/odd_pipeline_id.txt
         echo $projectdir
         echo $git_project_work_dir
         echo $sourceApp
         diff $projectdir/$git_project_work_dir/$sourceApp/pipelines_guid.list $projectdir/live_backup/$sourceApp/live_pipelines_guid.list | awk '{print $2}' | sed 1d > $projectdir/live_backup/$sourceApp/odd_pipeline_id.txt
         #list all existing spinnaker pipelines with app as reference
         spin -k pipeline list --application $sourceApp > $projectdir/live_backup/$sourceApp/$sourceApp-pipeline_list.json
         touch $projectdir/live_backup/$sourceApp/odd_pipeline.txt
         while IFS= read -r id; do
         #Extract the pipeline names using guids as reference
         cat $projectdir/live_backup/$sourceApp/$sourceApp-pipeline_list.json | jq '.[] | select (.id=="'$id'") | .name' -r >> $projectdir/live_backup/$sourceApp/odd_pipeline.txt
         done < $projectdir/live_backup/$sourceApp/odd_pipeline_id.txt
      done
    }

    syncup_spin() {
      echo "In Download function that updates the spinnaker instance with the contents in repo"
      #Backup of existing spinnaker pipelines with guids
      live_backup_spin
      #Compare guids of existing pipelines and pipelines in git and provide names of additional pipelines
      equate_pipelines_in_app
      #Delete the extra pipelines(pipelines in spinnaker and not in git)
      if [[ $delete_on_sync_spin == "true" ]]; then
        delete_odd_pipelines
      fi
      if [[ $repo_type = "s3" ]]; then
        projectdir=$tempdir/$root_folder
        echo "project dir at synup spin $projectdir"
      else
        projectdir=$tempdir/${git_repo}/$root_folder
      fi
      if [ -d "$projectdir" ]
      then
        echo "given git_project_work_dir is present"
      else
        echo "given git_project_work_dir is not present therefore creating it"
        mkdir -p "$projectdir/$git_project_work_dir"
      fi

      cd $projectdir
      spinnaker_app=$spinnaker_applications
      IFS=',' read -r -a spinnaker_app_array <<< "$spinnaker_app"

      spinnaker_pipe=$spinnaker_pipelines
      #IFS=',' read -r -a spinnaker_pipe_array <<< "k8s-deploy"
      IFS=',' read -r -a spinnaker_pipe_array <<< "$spinnaker_pipe"

      echo $projectdir
      for (( m=0; m<${#spinnaker_app_array[@]}; m++ )); do
         sourceApp=${spinnaker_app_array[$m]}
         echo -e "Processing application $sourceApp\n"
         cd $sourceApp              # Get into the correct directory
         if [ "$?" != "0" ]; then
           echo "ERROR: Unable to change to application directory: $sourceApp"
           return 1
         fi
         #Create the application by default, we can have flag to for this later
         spin -k application save -f $sourceApp.json
         retVal=$?
         if [[ "$retVal" != "0" && "$ignore_errors" == "false" ]]; then
           echo "ERROR: spin application save $sourceApp"
           return 1
         elif [[ "$retVal" != "0" && "$ignore_errors" == "true" ]]; then
           echo "ERROR: spin application save $sourceApp, continuing"
           cd ..
           continue
         fi
         #sleep 30 # Give a few seconds after application creation
         if [[ ${#spinnaker_pipe_array[@]} > 0 ]]; then
             for (( p=0; p<${#spinnaker_pipe_array[@]}; p++ )); do
                pipeLine=${spinnaker_pipe_array[$p]}
                echo -e "    Processing pipeline $pipeLine\n"
                # Check if pipeline file  exists
                if [ -f "$pipeLine.json" ]; then
                  #Update parameterConfig
                  if [[ "$pipelineconfig" == "true" ]]; then
                    mkdir -p temp
                    update_params "$pipeLine.json"
                    rm -rf temp
                  fi
                  spin -k pipeline save --file "$pipeLine.json"
                  retVal=$?
                  if [[ "$retVal" != "0" && "$ignore_errors" == "false" ]]; then
                    echo "ERROR: spin pipeline save --file $pipeLine.json"
                    return 1
                  elif [[ "$retVal" != "0" && "$ignore_errors" == "true" ]]; then
                    echo "ERROR: spin pipeline save --file $pipeLine.json, continuing"
                    continue
                  fi
                else
                   echo "WARNING: pipeline=${pipeLine} not found in application=$sourceApp ... skipping"
                fi
             done
         else # No pipelines defined, get all the pipelines
           while read -r line; do
             [[ -f "$line.json" ]] || continue
             pipeLine=$line
             echo -e "    Processing pipeline $pipeLine\n"
             #Update parameterConfig
             if [[ "$pipelineconfig" == "true" ]]; then
               echo "in pipelineconfig else"
               mkdir -p temp
               update_params "$pipeLine.json"
               #rm -rf temp
             fi
             echo `realpath $pipeLine.json`
             if test -f "$pipeLine.json"; then
               spin -k pipeline save --file "$pipeLine.json"
             fi
             retVal=$?
             if [[ "$retVal" != "0" && "$ignore_errors" == "false"  ]]; then
               echo "ERROR: spin pipeline save --file $pipeLine.json"
               return 1
             elif [[ "$retVal" != "0" && "$ignore_errors" == "true" ]]; then
               echo "ERROR: spin pipeline save --file $pipeLine.json, continuing"
               continue
             fi
             sleep 10 # Slow it down
           done < pipelines_in_application.list
         fi
         cd ..
      done
    }
    get_pipelines_data(){
      echo $1
      local  spinnaker_app=$1
      IFS=',' read -r -a spinnaker_app_array <<< "$spinnaker_app"
      spinnaker_pipe=$spinnaker_pipelines
      #IFS=',' read -r -a spinnaker_pipe_array <<< "k8s-deploy"
      IFS=',' read -r -a spinnaker_pipe_array <<< "$spinnaker_pipe"
      if [[ $root_folder == "" ]]; then
        root_folder="."
      fi
      for (( m=0; m<${#spinnaker_app_array[@]}; m++ )); do
        sourceApp=${spinnaker_app_array[$m]}
        echo -e "Processing application $sourceApp\n"
        echo "get pipelines data $root_folder"
        mkdir -p $tempdir/$git_repo/${root_folder}/$sourceApp ; cd $tempdir/$git_repo/${root_folder}/$sourceApp              # Get into the correct directory
        get_app_pipelines $sourceApp
        spin application get $sourceApp  > $sourceApp.json
        if [ "$?" != "0" ]; then
          echo "ERROR: spin application get $sourceApp"
          return 1
        fi
        if [[ ${#spinnaker_pipe_array[@]} > 0 ]]; then
          for (( p=0; p<${#spinnaker_pipe_array[@]}; p++ )); do
            pipeLine=${spinnaker_pipe_array[$p]}
            echo -e "    Processing pipeline $pipeLine\n"
            # Check if pipeline exists
            existingPipe=`grep \^${pipeLine}\$ pipelines_in_application.list`
            if [[ "$existingPipe" == "${pipeLine}" ]]; then
              spin pipeline get --application $sourceApp  --name "$pipeLine" > "$pipeLine.json"
              if [ "$?" != "0" ]; then
                 echo "ERROR: spin spin pipeline get --application $sourceApp  --name \"$pipeLine\""
                 return 1
              fi
            else
              echo "WARNING: pipeline=${pipeLine} not found in application=$sourceApp ... skipping"
            fi
          done
        else # No pipelines defined, get all the pipelines
          while read -r line; do
            echo -e "    Processing pipeline $line\n"
            spin pipeline get --application $sourceApp --name "$line" > "$line.json"
            if [ "$?" != "0" ]; then
               echo "ERROR: spin spin pipeline get --application $sourceApp  --name $line"
               return 1
            fi
          done < pipelines_in_application.list
        fi
        if [[ "$pipelinecreateconf" == "true" ]]; then
          create_default_params
        fi
        cd -
      done
    }

    download_spin() {
      echo "In Download function that updates the spinnaker instance with the contents in git"
      local user_root_folder=$root_folder
      if [ "$git_secret_sshkey" != "" ]; then
        git_clone_ssh_change $user_root_folder $git_repo $git_project
      elif [ "$git_secret_token" != "" ]; then
        git_clone_http $user_root_folder $git_repo $git_project
      else
        echo "git cloning requires either a git_secret_sshkey to be set or git_secret_token"
       exit 5
      fi
      projectdir=$HOME/$git_project
      cd $projectdir
      spinnaker_app=$spinnaker_applications
      IFS=',' read -r -a spinnaker_app_array <<< "$spinnaker_app"

      spinnaker_pipe=$spinnaker_pipelines
      #IFS=',' read -r -a spinnaker_pipe_array <<< "k8s-deploy"
      IFS=',' read -r -a spinnaker_pipe_array <<< "$spinnaker_pipe"

      for (( m=0; m<${#spinnaker_app_array[@]}; m++ )); do
        sourceApp=${spinnaker_app_array[$m]}
        echo -e "Processing application $sourceApp\n"
        cd $sourceApp              # Get into the correct directory
        if [ "$?" != "0" ]; then
          echo "ERROR: Unable to change to application directory: $sourceApp"
          return 1
        fi
        #Create the application by default, we can have flag to for this later
        spin application save -f $sourceApp.json
        retVal=$?
        if [[ "$retVal" != "0" && "$ignore_errors" == "false" ]]; then
          echo "ERROR: spin application save $sourceApp"
          return 1
        elif [[ "$retVal" != "0" && "$ignore_errors" == "true" ]]; then
          echo "ERROR: spin application save $sourceApp, continuing"
          cd ..
          continue
        fi
        sleep 30 # Give a few seconds after application creation
        if [[ ${#spinnaker_pipe_array[@]} > 0 ]]; then
          for (( p=0; p<${#spinnaker_pipe_array[@]}; p++ )); do
            pipeLine=${spinnaker_pipe_array[$p]}
            echo -e "    Processing pipeline $pipeLine\n"
            # Check if pipeline file  exists
            if [ -f "$pipeLine.json" ]; then
              #Update parameterConfig
              if [[ "$pipelineconfig" == "true" ]]; then
                 mkdir -p temp
                 update_params "$pipeLine.json"
                 rm -rf temp
              fi
              spin pipeline save --file "$pipeLine.json"
              retVal=$?
              if [[ "$retVal" != "0" && "$ignore_errors" == "false" ]]; then
                 echo "ERROR: spin pipeline save --file $pipeLine.json"
                 return 1
              elif [[ "$retVal" != "0" && "$ignore_errors" == "true" ]]; then
                 echo "ERROR: spin pipeline save --file $pipeLine.json, continuing"
                 continue
              fi
            else
              echo "WARNING: pipeline=${pipeLine} not found in application=$sourceApp ... skipping"
            fi
          done
         else # No pipelines defined, get all the pipelines
           while read -r line; do
             [[ -f "$line.json" ]] || continue
             pipeLine=$line
             echo -e "    Processing pipeline $pipeLine\n"
             #Update parameterConfig
             if [[ "$pipelineconfig" == "true" ]]; then
                mkdir -p temp
                update_params "$pipeLine.json"
                #rm -rf temp
             fi
             spin pipeline save --file "$pipeLine.json"
             retVal=$?
             if [[ "$retVal" != "0" && "$ignore_errors" == "false"  ]]; then
               echo "ERROR: spin pipeline save --file $pipeLine.json"
               return 1
             elif [[ "$retVal" != "0" && "$ignore_errors" == "true" ]]; then
               echo "ERROR: spin pipeline save --file $pipeLine.json, continuing"
               continue
             fi
             sleep 10 # Slow it down
           done < pipelines_in_application.list
         fi
         cd ..
      done
    }

    update_params() {
      confDir=${pipelineconfigdir}
      if [ ! -d "$confDir" ] ; then
        echo "Directory specified for configuratio ($confDir) not found in application directory"
        return
      fi
      if [ ! -f "$confDir/$json" ] ; then
        echo "INFO: No configuration found for $json in $confDir"
        return
      fi
      json="$1"
      echo "Processing pipeline ($json) and updating pipelines as per configuration in $confDir"
      #Extract .parameterConfig
      cat "$json" | jq '.parameterConfig' > temp/"config-$json"
      #Replace parameters
      cat temp/"config-$json" | jq -f /home/opsmx/scripts/replace-params.jq --argfile pp $confDir/"$json" > temp/"updated-config-$json"
      #Replace .parameterConfig
      cat "$json" | jq  '.parameterConfig=$uc' --argfile uc temp/"updated-config-$json" > temp/"$json"
      ########################################################################
      #Extract 1st trigger
      cat  temp/"$json"| jq '.triggers[0]' > temp/tmp-trig.json
      #Update first trigger
      cat temp/tmp-trig.json | jq 'if $pp.triggerValues != null then . * $pp.triggerValues else . end'  --argfile pp $confDir/"$json"  > temp/updated-tmp-trig.json
      #Update pipeline-json with updated trigger
      if [[ `cat temp/updated-tmp-trig.json | wc -c` -gt 5 ]]
      then
        cat temp/"$json" | jq '.triggers[0]=$pp' --argfile pp temp/updated-tmp-trig.json > temp/final-replaced.json
        cp temp/final-replaced.json "$json"
      else
        cp  temp/"$json" "$json"
      fi
      ########################################################################
    }
  stash.sh: |
    #!/bin/bash
    #this script funtions only work for self hosted bitbucketserver/stash central repository
    #env variables needed for this to work are as below
    #***git_url="example.bitbucket.com" make sure you dont add http/https or / in the url
    #****git_repo="pipelinepromotion" repo to be pushed/download pipeline json files from
    #***git_project="kes" project key is needed to clone/push/pull merge code
    #***git_user="tes.user" user is needed for cloning and pusing changes (stash does not support only access key)
    #git_password="adjoowddaw" make sure your password does not include special characters like # @*/. special characters cause git clone command to fail with https
    #***git_branch="testbranch" the branch to which the code should be merged with
    #***merge_branch=false if true then provide all the below env variables
    #   git_secret_token="dafjaljoahfoasjoijso" needed to create pull requests should be the git_users secret token
    #   git_pr_token="slkdfjaljoajfopaj" this is approver token to approve pull requests / you can also provide approver password here.
    #   git_approve_user="test.approver"  username of the pull request approver
    #
    # repo_type="stash" for selfhosted bitbucket server please use stash as repo type
    #***root_folder="path/to/pipeline-promotion/folder" folder to be selected in the repo to which the pipeline jobs to be pushed
    #***command=upload for running specific job -
    #                                         upload - to upload spinnaker pipeline json files to repo
    #                                         download - to download pipeline json file from repo and apply on spinnaker
    #***spinnaker_applications="testapp,sampleapp" application needed to collect the pipeline information
    #spinnaker_pipelines="" provide pipelines to be collected, if nothing given, all the pipelines of the application are collected
    #git_secret_sshkey="sshkey" ssh key if you want to clone repo with ssh protocol

    # note *** env variables are mandatory to work with the script
    source scripts/git.sh
    git_repo=$repo_name
    pr_id=0
    pr_version=0
    approve_pr_stash(){
      approve_req=$(curl -k -o -I -L -s -w "%{http_code}"  -X POST -H "Content-Type: application/json" -u $git_approve_user:$git_pr_token \
      https://$git_api_url/${git_project}/repos/${git_repo}/pull-requests/${pr_id}/approve)
      echo $approve_req
      if [[ $approve_req == "200" ]];then
        echo "merge request approved successfully"
      else
        echo "FAIL: failed to approve the request "
        exit 1
      fi
    }

    merge_pr_stash(){
      merge_req=$(curl -k -o -I -L -s -w "%{http_code}"  -X POST -H "Content-Type: application/json" -u $git_user:$git_secret_token   \
      https://$git_api_url/${git_project}/repos/${git_repo}/pull-requests/${pr_id}/merge?version=$pr_version)
      echo $merge_req
      if [ $merge_req == "200" ]; then
        echo "merged pr successfully"
      else
        echo "FAILED: failed to merge $merge_pr"
        exit 1
    fi
    }
    create_pr_stash(){
        local output=$(curl -k -X POST -H "Content-Type: application/json" -u $git_user:$git_secret_token   https://$git_api_url/${git_project}/repos/${git_repo}/pull-requests -d '{
        "title": "merging '"$git_branch"' to '"$target_branch"'",
        "description": "changes from spinnaker pipeline jobs are to be merged to master",
        "state": "OPEN",
        "open": true,
        "closed": false,
        "fromRef": {
            "id": "refs/heads/'"${git_branch}"'",
            "repository": {
                "slug": "'"${git_repo}"'",
                "name": null,
                "project": {
                    "key": "'"${git_project}"'"
                }
            }
        },
        "toRef": {
            "id": "refs/heads/'"$target_branch"'",
            "repository": {
                "slug": "'"${git_repo}"'",
                "name": null,
                "project": {
                    "key": "'"${git_project}"'"
                }
            }
        },
        "locked": false
    }')
      echo $output
      echo $output > pr_response.json
      grep  "is already up-to-date with branch" pr_response.json
      if [ "$?" = 0 ]
      then
        echo "master branch is already up-to-date"
        exit 0
      else
        pr_id=$(cat  pr_response.json| jq '(.id)' | sed 's/\"//g')
        pr_version=$(cat pr_response.json | jq '(.version)' | sed 's/\"//g')
        if [ $? = 0 ]; then
          echo "successfully created pull request "
          #rm -f pr_response.json
        else
          echo "ERROR: failed to raise pull request $output"
          exit 1
      fi
    fi
    }

    sync_spin_to_stash(){
      #setup git configuration using email and username
      setup_git
      #upload spinnaker configuration to git
      sync_spin_to_git
      #check if custom port is being used for repo
      if [[ $merge_branch == "true" && $target_branch != "" && ($git_branch != $target_branch)  ]];then
        if [[ $git_api_url_port != "" ]];then
          git_api_url=$git_api_url:$git_api_url_port
          create_pr_stash
          if [[ $auto_merge == "true" ]]; then
            approve_pr_stash
            merge_pr_stash
          fi
        else
          create_pr_stash
          if [[ $auto_merge == "true" ]]; then
            approve_pr_stash
            merge_pr_stash
          fi
        fi
      fi
    }
kind: ConfigMap
metadata:
  name: pipe-promot-scripts
---
# Source: oes/charts/minio/templates/pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
spec:
  accessModes:
    - "ReadWriteOnce"
  resources:
    requests:
      storage: "10Gi"
---
# Source: oes/charts/openldap/templates/pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: isd-openldap
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
spec:
  accessModes:
    - "ReadWriteOnce"
  resources:
    requests:
      storage: "5Gi"
---
# Source: oes/charts/minio/templates/post-install-prometheus-metrics-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: isd-minio-update-prometheus-secret
  labels:
    app: minio-update-prometheus-secret
    chart: minio-8.0.9
    release: isd
    heritage: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - secrets
    verbs:
      - get
      - create
      - update
      - patch
    resourceNames:
      - isd-minio-prometheus
  - apiGroups:
      - ""
    resources:
      - secrets
    verbs:
      - create
  - apiGroups:
      - monitoring.coreos.com
    resources:
      - servicemonitors
    verbs:
      - get
    resourceNames:
      - isd-minio
---
# Source: oes/charts/spinnaker/templates/rbac/spinnaker-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: spinnaker-role
rules:
  - apiGroups: ['']
    resources:
      [
        'namespaces',
        'events',
        'replicationcontrollers',
        'serviceaccounts',
        'pods/log',
      ]
    verbs: ['get', 'list']
  - apiGroups: ['']
    resources: ['pods', 'services', 'secrets', 'configmaps']
    verbs:
      [
        'create',
        'delete',
        'deletecollection',
        'get',
        'list',
        'patch',
        'update',
        'watch',
      ]
  - apiGroups: ['autoscaling']
    resources: ['horizontalpodautoscalers']
    verbs: ['list', 'get']
  - apiGroups: ['apps']
    resources: ['controllerrevisions', 'statefulsets']
    verbs: ['list']
  - apiGroups: ['extensions', 'apps']
    resources: ['deployments', 'replicasets', 'ingresses']
    verbs:
      [
        'create',
        'delete',
        'deletecollection',
        'get',
        'list',
        'patch',
        'update',
        'watch',
      ]
  # These permissions are necessary for halyard to operate. We use this role also to deploy Spinnaker itself.
  - apiGroups: ['']
    resources: ['services/proxy', 'pods/portforward']
    verbs:
      [
        'create',
        'delete',
        'deletecollection',
        'get',
        'list',
        'patch',
        'update',
        'watch',
      ]
  # These permissions are necessary for halyard to operate. We use this role also to deploy Spinnaker itself.
  - apiGroups: ['batch']
    resources: ['jobs']
    verbs:
      [
        'create',
        'delete',
        'get',
        'list',
        'update',
        'watch',
      ]
---
# Source: oes/templates/forwarder/create-controller-secret.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: create-controller-secret
rules:
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get","list","create","update","patch"]
---
# Source: oes/charts/minio/templates/post-install-prometheus-metrics-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: isd-minio-update-prometheus-secret
  labels:
    app: minio-update-prometheus-secret
    chart: minio-8.0.9
    release: isd
    heritage: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: isd-minio-update-prometheus-secret
subjects:
  - kind: ServiceAccount
    name: isd-minio-update-prometheus-secret
    namespace: "opsmx-isd"
---
# Source: oes/charts/spinnaker/templates/rbac/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: isd-spinnaker-halyard
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role                 # ClusterRole, if we have access to cluster resources
  name: spinnaker-role       # edit, if we have the access
subjects:
- namespace: opsmx-isd
  kind: ServiceAccount
  name: isd-spinnaker-halyard
---
# Source: oes/charts/spinnaker/templates/rbac/spinnaker-sa.yaml
# In the case of a local cluster Spinnaker needs
# to be able to deploy to all namespaces in the cluster.
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding  # ClusterRoleBinding, if we have access accross the cluster
metadata:
  name: isd-spinnaker-spinnaker
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role             # ClusteRoleBinding if we have access accross the cluster
  name: spinnaker-role   # cluster-admin if we have the access
subjects:
- namespace: opsmx-isd
  kind: ServiceAccount
  # Clouddriver does not currently allow config of its
  # service account.
  name: default
---
# Source: oes/templates/forwarder/create-controller-secret.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: create-controller-secret
subjects:
- kind: ServiceAccount
  name: create-controller-secret
roleRef:
  kind: Role
  name: create-controller-secret
  apiGroup: rbac.authorization.k8s.io
---
# Source: oes/templates/rbac/oes-init-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding # ClusterRole if you have cluster access
metadata:
  name: opsmx-isd-oes-access
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: view
subjects:
- namespace: opsmx-isd
  kind: ServiceAccount
  name: default
---
# Source: oes/charts/gitea/charts/memcached/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-memcached
  namespace: opsmx-isd
  labels:
    app.kubernetes.io/name: memcached
    helm.sh/chart: memcached-5.9.0
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
  annotations:
spec:
  type: ClusterIP
  ports:
    - name: memcache
      port: 11211
      targetPort: memcache
      nodePort: null
  selector:
    app.kubernetes.io/name: memcached
    app.kubernetes.io/instance: isd
---
# Source: oes/charts/gitea/charts/postgresql/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-postgresql-headless
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.17
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
  namespace: opsmx-isd
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: isd
---
# Source: oes/charts/gitea/charts/postgresql/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.17
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
  annotations:
  namespace: opsmx-isd
spec:
  type: ClusterIP
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: isd
    role: primary
---
# Source: oes/charts/gitea/templates/gitea/http-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-gitea-http
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
  annotations:
    null
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: http
    port: 3000
    targetPort: 3000
  selector:
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
---
# Source: oes/charts/gitea/templates/gitea/ssh-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-gitea-ssh
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
  annotations:
    null
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: ssh
    port: 22
    targetPort: 22
    protocol: TCP
  selector:
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
---
# Source: oes/charts/minio/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 9000
      protocol: TCP
      targetPort: 9000
  selector:
    app: minio
    release: isd
---
# Source: oes/charts/openldap/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-openldap
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
spec:
  ports:
    - name: ldap-port
      protocol: TCP
      port: 389
      targetPort: ldap-port
    - name: ssl-ldap-port
      protocol: TCP
      port: 636
      targetPort: ssl-ldap-port
  selector:
    app: openldap
    release: isd
  type: ClusterIP
---
# Source: oes/charts/redis/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-redis-headless
  labels:
    app: redis
    chart: redis-10.5.3
    release: isd
    heritage: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: redis
    port: 6379
    targetPort: redis
  selector:
    app: redis
    release: isd
---
# Source: oes/charts/redis/templates/redis-master-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-redis-master
  labels:
    app: redis
    chart: redis-10.5.3
    release: isd
    heritage: Helm
spec:
  type: ClusterIP
  ports:
  - name: redis
    port: 6379
    targetPort: redis
  selector:
    app: redis
    release: isd
    role: master
---
# Source: oes/charts/spinnaker/templates/services/halyard.yaml
apiVersion: v1
kind: Service
metadata:
  name: isd-spinnaker-halyard
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
    component: halyard
spec:
  ports:
  - port: 8064
    name: daemon
  clusterIP: None
  selector:
    app: isd-spinnaker
    component: halyard
---
# Source: oes/templates/forwarder/oes-forwarder-svc-agent.yaml
apiVersion: v1
kind: Service
metadata:
  name: opsmx-controller-controller1
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
spec:
  selector:
    app: opsmx-controller-controller1
  type: ClusterIP
  ports:
  - name: service-api
    port: 9002
    targetPort: service-api
  - name: control-api
    port: 9003
    targetPort: control-api
  - name: remote-command
    port: 9004
    targetPort: remote-command
---
# Source: oes/templates/forwarder/oes-forwarder-svc-agent.yaml
apiVersion: v1
kind: Service
metadata:
  name: agent-grpc
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
spec:
  selector:
    app: opsmx-controller-controller1
  type: LoadBalancer
  ports:
  - name: agent-grpc
    port: 9001
---
# Source: oes/templates/forwarder/oes-forwarder-svc-ipc.yaml
apiVersion: v1
kind: Service
metadata:
  name: opsmx-controller-controller1-interproc
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
spec:
  selector:
    app: opsmx-controller-controller1
  type: ClusterIP
  ports:
  - name: agent-grpc
    port: 9001
    targetPort: agent-grpc
---
# Source: oes/templates/sapor-gate/sapor-gate-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: spin
    component: sapor-gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: sapor-gate
spec:
  type: ClusterIP
  ports:
  - name: "sapor-gate-service"
    port: 8084
    protocol: TCP
    targetPort: 8084
  selector:
    app: oes
    component: sapor-gate
---
# Source: oes/templates/services/oes-auditclient-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: auditclient
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-audit-client
spec:
  ports:
  - name: auditclient
    port: 8098
    protocol: TCP
    targetPort: 8098
  selector:
    app: oes
    component: auditclient
  type: ClusterIP
---
# Source: oes/templates/services/oes-auditservice-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: auditservice
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-audit-service
spec:
  ports:
  - name: auditservice
    port: 8097
    protocol: TCP
    targetPort: 8097
  selector:
    app: oes
    component: auditservice
  type: ClusterIP
---
# Source: oes/templates/services/oes-autopilot-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: autopilot
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-autopilot
spec:
  type: ClusterIP
  ports:
  - name: "cas-service"
    port: 8090
    targetPort: 8090
  - name: "monitoring-service"
    port: 9090
    targetPort: 9090
  selector:
    app: oes
    component: autopilot
---
# Source: oes/templates/services/oes-dashboard-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: dashboard
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-dashboard
spec:
  type: ClusterIP
  ports:
  - name: dashboard
    protocol: TCP
    port: 8094
    targetPort: 8094
  selector:
    app: oes
    component: dashboard
---
# Source: oes/templates/services/oes-datascience-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: datascience
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-datascience
spec:
  ports:
  - name: datascience
    port: 5005
    protocol: TCP
    targetPort: 5005
  selector:
    app: oes
    component: datascience
  type: ClusterIP
---
# Source: oes/templates/services/oes-db-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: db
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-db
spec:
  type: ClusterIP
  ports:
  - name: db
    protocol: TCP
    port: 5432
    targetPort: 5432
  selector:
    app: oes
    component: db
---
# Source: oes/templates/services/oes-gate-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-gate
spec:
  type: ClusterIP
  ports:
  - name: "https"
    port: 443
    targetPort: 8084
  - name: "oes-gate-service"
    port: 8084
    protocol: TCP
    targetPort: 8084
  - name: "http"
    port: 80
    targetPort: 8084
  selector:
    app: oes
    component: gate
---
# Source: oes/templates/services/oes-platform-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: platform
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-platform
spec:
  type: ClusterIP
  ports:
  - name: oes-platform
    protocol: TCP
    port: 8095
    targetPort: 8095
  selector:
    app: oes
    component: platform
---
# Source: oes/templates/services/oes-rabbitmq-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: rabbitmq
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: rabbitmq-service
spec:
  ports:
  - name: rabbitmq
    port: 5672
    protocol: TCP
    targetPort: 5672
  - name: rabbitmq-mgmt
    port: 15672
    protocol: TCP
    targetPort: 15672
  selector:
    app: oes
    component: rabbitmq
  type: ClusterIP
---
# Source: oes/templates/services/oes-sapor-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: sapor
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-sapor
spec:
  type: ClusterIP
  ports:
  - name: "sapor"
    port: 8085
    targetPort: 8085
  selector:
    app: oes
    component: sapor
---
# Source: oes/templates/services/oes-ui-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: ui
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-ui
spec:
  type: ClusterIP
  ports:
  - name: "https"
    port: 443
    targetPort: 8080
  - name: "http"
    port: 8080
    targetPort: 8080
  selector:
    app: oes
    component: ui
---
# Source: oes/templates/services/oes-visibility-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: oes
    component: visibility
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-visibility
spec:
  type: ClusterIP
  ports:
  - name: visibility
    protocol: TCP
    port: 8096
    targetPort: 8096
  selector:
    app: oes
    component: visibility
---
# Source: oes/templates/services/opa-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: opa
  labels:
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
spec:
  selector:
    app: opa
  ports:
  - protocol: TCP
    port: 8181
    targetPort: 8181
  type: ClusterIP
---
# Source: oes/templates/spinnaker-extra/spinsvcs.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: spin
    stack: deck
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: spin-deck-lb
spec:
  type: ClusterIP
  ports:
   - name: "https"
     port: 443
     targetPort: 9000
   - name: "http"
     port: 80
     protocol: TCP
     targetPort: 9000
  selector:
    cluster: spin-deck
---
# Source: oes/templates/spinnaker-extra/spinsvcs.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: spin
    stack: gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: spin-gate-lb
spec:
  type: ClusterIP
  ports:
   - name: https
     port: 443
     targetPort: 8084
   - name: "http"
     port: 80
     protocol: TCP
     targetPort: 8084
  selector:
    cluster: spin-gate
---
# Source: oes/charts/gitea/charts/memcached/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: isd-memcached
  namespace: opsmx-isd
  labels:
    app.kubernetes.io/name: memcached
    helm.sh/chart: memcached-5.9.0
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: memcached
      app.kubernetes.io/instance: isd
  replicas: 1
  template:
    metadata:
      labels:
        app.kubernetes.io/name: memcached
        helm.sh/chart: memcached-5.9.0
        app.kubernetes.io/instance: isd
        app.kubernetes.io/managed-by: Helm
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: memcached
                    app.kubernetes.io/instance: isd
                namespaces:
                  - "opsmx-isd"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
      serviceAccountName: isd-memcached
      containers:
        - name: memcached
          image: docker.io/bitnami/memcached:1.6.9-debian-10-r114
          imagePullPolicy: "IfNotPresent"
          args:
            - /run.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
          ports:
            - name: memcache
              containerPort: 11211
          livenessProbe:
            tcpSocket:
              port: memcache
            initialDelaySeconds: 30
            timeoutSeconds: 5
            failureThreshold: 6
          readinessProbe:
            tcpSocket:
              port: memcache
            initialDelaySeconds: 5
            timeoutSeconds: 3
            periodSeconds: 5
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: tmp
              mountPath: /tmp
          securityContext:
            readOnlyRootFilesystem: false
      volumes:
        - name: tmp
          emptyDir: {}
---
# Source: oes/charts/minio/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: isd-minio
  labels:
    app: minio
    chart: minio-8.0.9
    release: isd
    heritage: Helm
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 100%
      maxUnavailable: 0
  selector:
    matchLabels:
      app: minio
      release: isd
  template:
    metadata:
      name: isd-minio
      labels:
        app: minio
        release: isd
      annotations:
        checksum/secrets: 0e7fab1c3058994997feaa92931063f8fc4c7f719d54fd3ef3459505a6a61533
        checksum/config: 7a7ac5513fcd53ca17fde80ebf50780809224b63001a3969ca32fcaf1caf5999
    spec:
      serviceAccountName: "isd-minio"
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
        - name: minio
          image: "minio/minio:RELEASE.2020-12-03T05-49-24Z"
          imagePullPolicy: IfNotPresent
          command:
            - "/bin/sh"
            - "-ce"
            - "/usr/bin/docker-entrypoint.sh minio -S /etc/minio/certs/ server /export"
          volumeMounts:
            - name: export
              mountPath: /export            
          ports:
            - name: http
              containerPort: 9000
          env:
            - name: MINIO_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: isd-minio
                  key: accesskey
            - name: MINIO_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: isd-minio
                  key: secretkey
          resources:
            requests:
              memory: 4Gi      
      volumes:
        - name: export
          persistentVolumeClaim:
            claimName: isd-minio
        - name: minio-user
          secret:
            secretName: isd-minio
---
# Source: oes/charts/openldap/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  name:  isd-openldap
  labels:
    app: openldap
    chart: openldap-1.2.3
    release: isd
    heritage: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: openldap
      release: isd
  template:
    metadata:
      annotations:
        checksum/configmap-env: da8e0c8da82ff9254423b65018fe528f67823beb164b9f81ba49b04afd696558
        checksum/configmap-customldif: 3bf9905ca1d307472278add416a8fff6618651f0ef01b0dcaab0009017d48376
        moniker.spinnaker.io/application: spin
      labels:
        app: openldap
        release: isd
    spec:
      initContainers:
      - name: openldap-init-ldif
        image: quay.io/opsmxpublic/busybox:1.28
        command: ['sh', '-c', 'cp /customldif/* /ldifworkingdir']
        imagePullPolicy: IfNotPresent
        volumeMounts:
        - name: customldif
          mountPath: /customldif
        - name: ldifworkingdir
          mountPath: /ldifworkingdir
        resources:
          {}
      containers:
        - name: openldap
          image: "osixia/openldap:1.2.4"
          lifecycle:
            postStart:
              exec:
                command:
                - /bin/sh
                - -c
                - until service slapd status; do sleep 10 ;done
          imagePullPolicy: IfNotPresent
          args: [--copy-service]
          ports:
            - name: ldap-port
              containerPort: 389
            - name: ssl-ldap-port
              containerPort: 636
          envFrom:
            - configMapRef:
                name: isd-openldap-env
            - secretRef:
                name: isd-openldap
          volumeMounts:
            - name: data
              mountPath: /var/lib/ldap
              subPath: data
            - name: data
              mountPath: /etc/ldap/slapd.d
              subPath: config-data
            - name: ldifworkingdir
              mountPath: /container/service/slapd/assets/config/bootstrap/ldif/custom
          env:
          livenessProbe:
            tcpSocket:
              port: ldap-port
            initialDelaySeconds: 20
            periodSeconds: 10
            failureThreshold: 10
          readinessProbe:
            tcpSocket:
              port: ldap-port
            initialDelaySeconds: 20
            periodSeconds: 10
            failureThreshold: 10
          resources:
            {}
      volumes:
        - name: customldif
          configMap:
            name: isd-openldap-customldif
        - name: ldifworkingdir
          emptyDir: {}
        - name: certs
          emptyDir:
            medium: Memory
        - name: data
          persistentVolumeClaim:
            claimName: isd-openldap
---
# Source: oes/templates/deployments/oes-audit-client.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: auditclient
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-audit-client
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: auditclient
  template:
    metadata:
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8098"
      labels:
        app: oes
        component: auditclient
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.10"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-audit-client:v4.0.3.1-rc1
        imagePullPolicy: IfNotPresent
        name: oes-audit-client
        ports:
        - containerPort: 8098
          name: backend
          protocol: TCP
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /mgmt/health
            port: 8098
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 1
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          tcpSocket:
            port: 8098
        volumeMounts:
        - mountPath: /opsmx/conf/audit-client-local.yml
          name: audit-config-volume
          subPath: audit-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
      volumes:
      - secret:
          items:
          - key: audit-local.yml
            path: audit-local.yml
          secretName: oes-audit-client-config
        name: audit-config-volume
      - name: bootstrap-config-volume
        secret:
          defaultMode: 420
          secretName: bootstrap
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-audit-service.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: auditservice
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-audit-service
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: auditservice
  template:
    metadata:
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "false"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8097"
      labels:
        app: oes
        component: auditservice
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.10"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-audit-service:v4.0.3.1-rc1
        imagePullPolicy: IfNotPresent
        name: oes-audit
        ports:
        - containerPort: 8097
          name: backend
          protocol: TCP
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /mgmt/health
            port: 8097
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 60
          successThreshold: 1
          timeoutSeconds: 1
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          tcpSocket:
            port: 8097
          timeoutSeconds: 1
        volumeMounts:
        - mountPath: /opsmx/conf/audit-service-local.yml
          name: audit-config-volume
          subPath: audit-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
      volumes:
      volumes:
      - secret:
          items:
          - key: audit-local.yml
            path: audit-local.yml
          secretName: oes-audit-service-config
        name: audit-config-volume
      - name: bootstrap-config-volume
        secret:
          defaultMode: 420
          secretName: bootstrap
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-autopilot-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  name: oes-autopilot
  labels:
    app: oes
    component: autopilot
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: autopilot
  template:
    metadata:
      labels:
        app: oes
        component: autopilot
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.10"
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8090"
    spec:
      volumes:
        - name: autopilot-config-volume
          secret:
            secretName: oes-autopilot-config
        - secret:
            items:
            - key: bootstrap.yml
              path: bootstrap.yml
            secretName: bootstrap
          name: bootstrap-config-volume
        - configMap:
            defaultMode: 420
            items:
            - key: standard-error-codes.csv
              path: standard-error-codes.csv
            name: standard-error-codes-config
          name: standard-error-conf
      initContainers:
      - name: db-check
        image: quay.io/opsmxpublic/postgres:9.6.5
        command: ['/bin/bash', '-c', "sleep 30;echo Waiting for oes-db to be up and running; pg_isready -h oes-db -p 5432 && echo PostgreSQL DB is ready to receive connections"]
      containers:
        - image: quay.io/opsmxpublic/ubi8-oes-autopilot:v4.0.3.1-rc1
          imagePullPolicy: IfNotPresent
          name: oes-autopilot
          resources:
            {}
          ports:
            - containerPort: 8090
              name: backend
              protocol: TCP
            - containerPort: 9090
              name: metricfetcher
              protocol: TCP
          volumeMounts:
          - name: autopilot-config-volume
            mountPath: /opsmx/conf/autopilot.properties
            subPath: autopilot.properties
          - mountPath: /opsmx/conf/bootstrap.yml
            name: bootstrap-config-volume
            subPath: bootstrap.yml
          - mountPath: /opsmx/conf/standard-error-code.csv
            name: standard-error-conf
            subPath: standard-error-codes.csv
          readinessProbe:
            tcpSocket:
              port: 8090
            initialDelaySeconds: 60
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /mgmt/health
              port: 8090
            initialDelaySeconds: 120
            periodSeconds: 60
---
# Source: oes/templates/deployments/oes-dashboard-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: dashboard
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-dashboard
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: dashboard
  strategy: {}
  template:
    metadata:
      annotations:
        configmap/checksum: bfdbbd95b11053a548502713f0ae6f99111cd8f853d814981ca6ecf1c31231be
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8094"
      labels:
        app: oes
        component: dashboard
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.10"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-dashboard:v4.0.3.1-rc1
        name: oes-dashboard
        ports:
        - containerPort: 8094
          protocol: TCP
        env:
        volumeMounts:
        - mountPath: /opsmx/conf/dashboard-local.yml
          name: dashboard-config
          subPath: dashboard-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
        resources:
            {}
        readinessProbe:
          tcpSocket:
            port: 8094
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8094
          initialDelaySeconds: 30
          periodSeconds: 60
      volumes:
      - name: dashboard-config
        configMap:
          name: oes-dashboard-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-datascience-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: datascience
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-datascience
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: datascience
  template:
    metadata:
      annotations:
        configmap/checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "false"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "5005"
      labels:
        app: oes
        component: datascience
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.10"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-datascience:v4.0.3.1-rc1
        imagePullPolicy: IfNotPresent
        name: oes-datascience
        ports:
        - containerPort: 5005
          name: backend
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          tcpSocket:
            port: 5005
          timeoutSeconds: 1
        volumeMounts:
        - mountPath: /home/ubuntu/.aws/credentials
          name: datascience-config-volume
          subPath: minio-credentials
        - mountPath: /home/ubuntu/datascience/app_config.yaml
          name: datascience-config-volume
          subPath: app-config.yml
      volumes:
      - secret:
          secretName: oes-datascience-config
        name: datascience-config-volume
---
# Source: oes/templates/deployments/oes-gate-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-gate
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: gate
  template:
    metadata:
      annotations:
        checksum/secret: d4920071ed2147dea386710774cb87ad4f4727ffe7f33895364cf75a007a5a80
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "false"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8084"
      labels:
        app: oes
        component: gate
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.10"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-gate:v4.0.3.1-rc1
        name: oes-gate
        env:
        - name: spring_profiles_active
          value: vault,local
        ports:
        - containerPort: 8084
          protocol: TCP
        resources:
            {}
        volumeMounts:
        - name: gate-volume
          mountPath: /opt/spinnaker/config/gate.yml
          subPath: gate.yml
        - mountPath: /opt/spinnaker/config/bootstrap.yml
          name: bootstrap-volume
          subPath: bootstrap.yml
        readinessProbe:
          tcpSocket:
            port: 8084
          initialDelaySeconds: 60
          periodSeconds: 30
        livenessProbe:
          httpGet:
            path: /health
            port: 8084
          initialDelaySeconds: 60
          periodSeconds: 60
      volumes:
      - name: gate-volume
        secret:
          secretName: oes-gate-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-volume
---
# Source: oes/templates/deployments/oes-platform-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: platform
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-platform
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: platform
  strategy: {}
  template:
    metadata:
      annotations:
        checksum/secret: 4f4f82026e7ecf0811b74948d22600bacccd47052e0bdfaec6367253f2f1a9dc
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8095"
      labels:
        app: oes
        component: platform
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.10"
    spec:
      initContainers:
      - name: db-check
        image: quay.io/opsmxpublic/pgchecker:v1
        command:
          - sh
          - -c
          - |
            echo 'Waiting for OES-DB to become ready...'
            until printf "." && nc -z -w 2 oes-db 5432; do
               sleep 2;
            done;
            echo 'OESDB OK ✓'
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-platform:v4.0.3.1-rc1
        name: oes-platform
        ports:
        - containerPort: 8095
          protocol: TCP
        env:
        resources:
            {}
        readinessProbe:
          tcpSocket:
            port: 8095
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8095
          initialDelaySeconds: 60
          periodSeconds: 60
        volumeMounts:
        - mountPath: /opsmx/conf/platform-local.yml
          name: platform-config-volume
          subPath: platform-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
        - mountPath: /opsmx/conf/feature.yml
          name: isd-feature-flag-conf
          subPath: feature.yml
      volumes:
      - name: platform-config-volume
        secret:
          secretName: oes-platform-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
      - configMap:
          defaultMode: 420
          items:
          - key: feature.yml
            path: feature.yml
          name: isd-feature-flag-config
        name: isd-feature-flag-conf
---
# Source: oes/templates/deployments/oes-rabbitmq-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: rabbitmq
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: rabbitmq
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: rabbitmq
  template:
    metadata:
      annotations:
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: rabbitmq
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.10"
    spec:
      containers:
      - image: quay.io/opsmxpublic/rabbitmq:3-management
        imagePullPolicy: IfNotPresent
        name: rabbitmq
        ports:
        - containerPort: 5672
          protocol: TCP
        resources: {}
      restartPolicy: Always
      securityContext:
        fsGroup: 1000
---
# Source: oes/templates/deployments/oes-sapor-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: sapor
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-sapor
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: sapor
  template:
    metadata:
      annotations:
        checksum/configmap: a951349e8aaea6764bc734b47d06b828c01527e53b96836f113d81a4638153f2
        checksum/configmap: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8085"
      labels:
        app: oes
        component: sapor
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.10"
    spec:
      initContainers:
      - name: db-check
        image: quay.io/opsmxpublic/postgres:9.6.5
        command: ['/bin/bash', '-c', "sleep 30;echo Waiting for oes-db to be up and running; pg_isready -h oes-db -p 5432 && echo PostgreSQL DB is ready to receive connections"]
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-sapor:v4.0.3.1-rc1
        name: oes-sapor
        env:
        ports:
        - containerPort: 8085
          protocol: TCP
        volumeMounts:
        - mountPath: /opt/opsmx/controller/ca.crt
          name: ca-certs-volume
          subPath: tls.crt
        - mountPath: /opt/opsmx/controller/cert/tls.crt
          name: certs-volume
          subPath: tls.crt
        - mountPath: /opt/opsmx/controller/cert/tls.key
          name: certs-volume
          subPath: tls.key
        - name: sapor-config-volume
          mountPath: /opt/opsmx/application.yml
          subPath: application.yml
        - mountPath: /opt/opsmx/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
        resources:
            {}
        readinessProbe:
          tcpSocket:
            port: 8085
          initialDelaySeconds: 60
          periodSeconds: 10
          failureThreshold: 10
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8085
          initialDelaySeconds: 60
          periodSeconds: 10
          failureThreshold: 10
      volumes:
      - secret:
          secretName: oes-control-secret
        name: certs-volume
      - secret:
          secretName: ca-secret
        name: ca-certs-volume
      - secret:
          secretName: oes-sapor-config
        name: sapor-config-volume
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: sapor-bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/oes-ui-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: ui
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-ui
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: ui
  template:
    metadata:
      annotations:
        checksum/configmap: ec1928c046c894ea0592049ca7ba025a7b4a3760cc5ec54f4bcffe0637d0d957
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: ui
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.10"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-ui:v4.0.3.1-rc1
        name: oes-ui
        ports:
        - containerPort: 8080
          protocol: TCP
        volumeMounts:
        - name: config-dir
          mountPath: /var/www/html/ui/assets/config/app-config.json
          subPath: app-config.json
        - name: config-dir
          mountPath: /var/www/html/ui/assets/config/help-text.json
          subPath: help-text.json
        - mountPath: /etc/nginx/nginx.conf
          name: nginx-config
          subPath: nginx.conf
        readinessProbe:
          tcpSocket:
            port: 8080
          initialDelaySeconds: 15
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /ui/indexl.html
            port: 8080
          initialDelaySeconds: 15
          periodSeconds: 5
      volumes:
      - configMap:
          defaultMode: 420
          name: oes-ui-config
        name: config-dir
      - configMap:
          defaultMode: 420
          name: oes-ui-nginxconf
        name: nginx-config
---
# Source: oes/templates/deployments/oes-visibility-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: visibility
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-visibility
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: visibility
  strategy: {}
  template:
    metadata:
      annotations:
        configmap/checksum: 2244eb95cf61ca11189e8574a63a09b119d41d512924506a87cd49a3da562124
        moniker.spinnaker.io/application: isd
        prometheus.io/scrape: "true"
        prometheus_io_path: /mgmt/prometheus
        prometheus_io_port: "8096"
      labels:
        app: oes
        component: visibility
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.10"
    spec:
      initContainers:
      - name: db-check
        image: quay.io/opsmxpublic/postgres:9.6.5
        command: ['/bin/bash', '-c', "sleep 30;echo Waiting for oes-db to be up and running; pg_isready -h oes-db -p 5432 && echo PostgreSQL DB is ready to receive connections"]
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-visibility:v4.0.3.1-rc1
        name: oes-visibility
        ports:
        - containerPort: 8096
          protocol: TCP
        env:
        env:
        volumeMounts:
        - mountPath: /opsmx/conf/visibility-local.yml
          name: visibility-config
          subPath: visibility-local.yml
        - mountPath: /opsmx/conf/bootstrap.yml
          name: bootstrap-config-volume
          subPath: bootstrap.yml
        - mountPath: /opsmx/conf/standard-error-code.csv
          name: standard-error-conf
          subPath: standard-error-codes.csv
        resources:
            {}
        readinessProbe:
          tcpSocket:
            port: 8096
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /mgmt/health
            port: 8096
          initialDelaySeconds: 30
          periodSeconds: 60
      volumes:
      - name: visibility-config
        secret:
          secretName: oes-visibility-config
      - secret:
          items:
          - key: bootstrap.yml
            path: bootstrap.yml
          secretName: bootstrap
        name: bootstrap-config-volume
      - configMap:
          defaultMode: 420
          items:
          - key: standard-error-codes.csv
            path: standard-error-codes.csv
          name: standard-error-codes-config
        name: standard-error-conf
---
# Source: oes/templates/deployments/opa-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: opa
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: opa
spec:
  replicas: 1
  selector:
    matchLabels:
      app: opa
  template:
    metadata:
      annotations:
        moniker.spinnaker.io/application: isd
      labels:
        app: opa
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.10"
      name: opa
    spec:
      containers:
        - name: opa
          image: quay.io/opsmxpublic/opa:v0.47.0
          args:
            - "run"
            - "--server"
        - name: opa-persist
          command:
          - /bin/bash
          - /tmp/config/opa-persist.sh
          envFrom:
          - secretRef:
              name: oes-gate-secret
          image: quay.io/opsmxpublic/customterraformstage:v1
          imagePullPolicy: IfNotPresent
          volumeMounts:
          - mountPath: /tmp/config
            name: opa-persist
      restartPolicy: Always
      volumes:
        - configMap:
            defaultMode: 420
            name: opa-persist
          name: opa-persist
---
# Source: oes/templates/forwarder/oes-forwarder-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  name: opsmx-controller-controller1
  labels:
    agent.opsmx.com/name: controller1
    agent.opsmx.com/role: controller
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: opsmx-controller-controller1
  template:
    metadata:
      labels:
        app: opsmx-controller-controller1
        agent.opsmx.com/name: controller1
        agent.opsmx.com/role: controller
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.10"
      annotations:
        pullversion: "16"
        checksum/configmap: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
    spec:
      containers:
      - name: opsmx-controller-controller1
        image: quay.io/opsmxpublic/forwarder-controller:v3.5.7
        ports:
          - containerPort: 9001
            name: agent-grpc
          - containerPort: 9002
            name: service-api
          - containerPort: 9003
            name: control-api
          - containerPort: 9004
            name: remote-command
          - containerPort: 9102
            name: metrics
        env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
        volumeMounts:
        - name: config
          mountPath: /app/config
          readOnly: true
        - name: ca-secret
          mountPath: /app/secrets/ca
          readOnly: true
        - name: jwt-secret
          mountPath: /app/secrets/serviceAuth
          readOnly: true
        resources:
          requests:
            memory: "64Mi"
            cpu: "100m"
          limits:
            memory: "128Mi"
            cpu: "250m"
      volumes:
      - name: ca-secret
        secret:
          secretName: ca-secret
      - name: jwt-secret
        secret:
          secretName: jwt-secret
      - name: config
        configMap:
          name: opsmx-controller-controller1
          items:
          - key: "configFile"
            path: "config.yaml"
---
# Source: oes/templates/sapor-gate/sapor-gate-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: sapor-gate
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: sapor-gate
spec:
  replicas: 1
  selector:
    matchLabels:
      app: oes
      component: sapor-gate
  template:
    metadata:
      annotations:
        checksum/secret: 68f74bcf539b143147ec93182922a9856aa8eeeaa1a0bf334cdb6b52608f954b
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: sapor-gate
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.10"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-spin-gate:v3.12.0-saporgate
        name: sapor-gate
        env:
        - name: JAVA_OPTS
          value: -XX:MaxRAMPercentage=100.0
        - name: SPRING_PROFILES_ACTIVE
          value: overrides,local
        ports:
        - containerPort: 8084
          protocol: TCP
        resources:
            {}
        volumeMounts:
        - mountPath: /opt/spinnaker/config
          name: sapor-gate-files
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /health
            port: 8084
            scheme: HTTP
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 1
      volumes:
      - name: sapor-gate-files
        secret:
          secretName: sapor-gate-files
---
# Source: oes/charts/gitea/charts/postgresql/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: isd-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.17
    app.kubernetes.io/instance: isd
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
  annotations:
  namespace: opsmx-isd
spec:
  serviceName: isd-postgresql-headless
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/instance: isd
      role: primary
  template:
    metadata:
      name: isd-postgresql
      labels:
        app.kubernetes.io/name: postgresql
        helm.sh/chart: postgresql-10.3.17
        app.kubernetes.io/instance: isd
        app.kubernetes.io/managed-by: Helm
        role: primary
        app.kubernetes.io/component: primary
    spec:      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/instance: isd
                    app.kubernetes.io/component: primary
                namespaces:
                  - "opsmx-isd"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      containers:
        - name: isd-postgresql
          image: docker.io/bitnami/postgresql:11.11.0-debian-10-r62
          imagePullPolicy: "IfNotPresent"
          resources:
            requests:
              cpu: 250m
              memory: 256Mi
          securityContext:
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: isd-postgresql
                  key: postgresql-postgres-password
            - name: POSTGRES_USER
              value: "gitea"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: isd-postgresql
                  key: postgresql-password
            - name: POSTGRES_DB
              value: "gitea"
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "gitea" -d "dbname=gitea" -h 127.0.0.1 -p 5432
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "gitea" -d "dbname=gitea" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
              subPath: 
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 1Gi
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "10Gi"
---
# Source: oes/charts/gitea/templates/gitea/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: isd-gitea
  labels:
    helm.sh/chart: gitea-5.0.1
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: isd
    app.kubernetes.io/version: "1.15.10"
    version: "1.15.10"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: gitea
      app.kubernetes.io/instance: isd
  serviceName: isd-gitea
  template:
    metadata:
      annotations:
        checksum/config: 9d002fd7ae2d1eb91f8238f5d0f2896011847d3d71b8dc12d45add370e19de9c
      labels:
        helm.sh/chart: gitea-5.0.1
        app: gitea
        app.kubernetes.io/name: gitea
        app.kubernetes.io/instance: isd
        app.kubernetes.io/version: "1.15.10"
        version: "1.15.10"
        app.kubernetes.io/managed-by: Helm
    spec:
      securityContext:
        fsGroup: 1000
      initContainers:
        - name: init-directories
          image: "gitea/gitea:1.15.10"
          command: ["/usr/sbin/init_directory_structure.sh"]
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
          volumeMounts:
            - name: init
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
          securityContext:
            {}
        - name: init-app-ini
          image: "gitea/gitea:1.15.10"
          command: ["/usr/sbin/config_environment.sh"]
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
          volumeMounts:
            - name: config
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
            - name: inline-config-sources
              mountPath: /env-to-ini-mounts/inlines/
          securityContext:
            {}
        - name: configure-gitea
          image: "gitea/gitea:1.15.10"
          command: ["/usr/sbin/configure_gitea.sh"]
          securityContext:
            runAsUser: 1000
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
            - name: GITEA_ADMIN_USERNAME
              valueFrom:
                secretKeyRef:
                  key:  username
                  name: gitea-secret
            - name: GITEA_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  key:  password
                  name: gitea-secret
          volumeMounts:
            - name: init
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
      terminationGracePeriodSeconds: 60
      containers:
        - name: gitea
          image: "gitea/gitea:1.15.10"
          imagePullPolicy: Always
          env:
            # SSH Port values have to be set here as well for openssh configuration
            - name: SSH_LISTEN_PORT
              value: "22"
            - name: SSH_PORT
              value: "22"
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
            - name: TMPDIR
              value: /tmp/gitea
          ports:
            - name: ssh
              containerPort: 22
            - name: http
              containerPort: 3000
          livenessProbe:
            failureThreshold: 10
            initialDelaySeconds: 200
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: http
            timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: http
            timeoutSeconds: 1
          resources:
            {}
          securityContext:
            {}
          volumeMounts:
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
      volumes:
        - name: init
          secret:
            secretName: isd-gitea-init
            defaultMode: 110
        - name: config
          secret:
            secretName: isd-gitea
            defaultMode: 110
        - name: inline-config-sources
          secret:
            secretName: isd-gitea-inline-config
        - name: temp
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
            - "ReadWriteOnce"
        resources:
          requests:
            storage: "10Gi"
---
# Source: oes/charts/redis/templates/redis-master-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  name: isd-redis-master
  labels:
    app: redis
    chart: redis-10.5.3
    release: isd
    heritage: Helm
spec:
  selector:
    matchLabels:
      app: redis
      release: isd
      role: master
  serviceName: isd-redis-headless
  template:
    metadata:
      labels:
        app: redis
        chart: redis-10.5.3
        release: isd
        role: master
      annotations:
        checksum/health: 36567aac6587929dc97be63c28c0aa1ec58d167572f3e5f191536195dc588d15
        checksum/configmap: 42a460f87c190197092321f0ae70720d271a2f6738150858f02b13ca057dae95
        checksum/secret: 92c3542fca96bee16e081be3a51ac49fa2ad66360cd283b768155ca7bae80c9e
        moniker.spinnaker.io/application: spin
    spec:      
      securityContext:
        fsGroup: 1001
      serviceAccountName: "default"
      containers:
      - name: isd-redis
        image: "quay.io/opsmxpublic/bitnami-redis:5.0.7-debian-10-r0"
        imagePullPolicy: "IfNotPresent"
        securityContext:
          runAsUser: 1001
        command:
        - /bin/bash
        - -c
        - |
          if [[ -n $REDIS_PASSWORD_FILE ]]; then
            password_aux=`cat ${REDIS_PASSWORD_FILE}`
            export REDIS_PASSWORD=$password_aux
          fi
          if [[ ! -f /opt/bitnami/redis/etc/master.conf ]];then
            cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
          fi
          if [[ ! -f /opt/bitnami/redis/etc/redis.conf ]];then
            cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
          fi
          ARGS=("--port" "${REDIS_PORT}")
          ARGS+=("--requirepass" "${REDIS_PASSWORD}")
          ARGS+=("--masterauth" "${REDIS_PASSWORD}")
          ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
          ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
          /run.sh ${ARGS[@]}
        env:
        - name: REDIS_REPLICATION_MODE
          value: master
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: isd-redis
              key: redis-password
        - name: REDIS_PORT
          value: "6379"
        ports:
        - name: redis
          containerPort: 6379
        livenessProbe:
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 5
          exec:
            command:
            - sh
            - -c
            - /health/ping_liveness_local.sh 5
        readinessProbe:
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 1
          successThreshold: 1
          failureThreshold: 5
          exec:
            command:
            - sh
            - -c
            - /health/ping_readiness_local.sh 5
        resources:
          null
        volumeMounts:
        - name: health
          mountPath: /health
        - name: redis-data
          mountPath: /data
          subPath: 
        - name: config
          mountPath: /opt/bitnami/redis/mounted-etc
        - name: redis-tmp-conf
          mountPath: /opt/bitnami/redis/etc/
      volumes:
      - name: health
        configMap:
          name: isd-redis-health
          defaultMode: 0755
      - name: config
        configMap:
          name: isd-redis
      - name: redis-tmp-conf
        emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: redis-data
        labels:
          app: redis
          release: isd
          heritage: Helm
          component: master
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
        
        selector:
  updateStrategy:
    type: RollingUpdate
---
# Source: oes/charts/spinnaker/templates/statefulsets/halyard.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    moniker.spinnaker.io/application: spin
  name: isd-spinnaker-halyard
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
spec:
  serviceName: isd-spinnaker-halyard
  replicas: 1
  selector:
    matchLabels:
      app: "isd-spinnaker"
      release: "isd"
      component: halyard
  template:
    metadata:
      annotations:
        checksum/configmap: ae73ae13b63a637c8d664be45036c860e24f8c42846aae9a1e49681f0fe853ac
        moniker.spinnaker.io/application: spin
      labels:
        app: "isd-spinnaker"
        heritage: "Helm"
        release: "isd"
        chart: "spinnaker-2.2.3"
        component: halyard
    spec:
      serviceAccountName: isd-spinnaker-halyard
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      initContainers:
      - name: "create-halyard-local"
        image: quay.io/opsmxpublic/awsgit:v3-js
        command:
        - sh
        - /tmp/initscript/init.sh
        env:
        - name: SPINNAKER_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: GITEA_USER
          valueFrom:
            secretKeyRef:
              name: gitea-secret
              key: username
        - name: GITEA_PASS
          valueFrom:
            secretKeyRef:
              name: gitea-secret
              key: password
        volumeMounts:
        - name: halyard-config
          mountPath: /tmp/config
        - name: service-settings
          mountPath: /tmp/service-settings
        - name: halyard-home
          mountPath: /tmp/spinnaker
        - name: additional-profile-config-maps
          mountPath: /tmp/additionalProfileConfigMaps
        - name: halyard-initscript
          mountPath: /tmp/initscript
      - name: "halyardconfig-update"
        command:
        - sh
        - /tmp/akv2k8s/run.sh
        image: quay.io/opsmxpublic/k8s-decoder:hal
        imagePullPolicy: IfNotPresent
        resources: {}
        volumeMounts:
        - name: halyard-home
          mountPath: /tmp/spinnaker
        - name: secret-decoder
          mountPath: /tmp/akv2k8s
      - name: "halyard-overrideurl"
        command:
        - sh
        - /tmp/autoconfig/call_overrides.sh
        env:
        - name: NODE_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.hostIP
        image: quay.io/opsmxpublic/bitnami-kubectl:1.18.5
        imagePullPolicy: IfNotPresent
        resources: {}
        volumeMounts:
        - name: halyard-config
          mountPath: /tmp/config
        - name: service-settings
          mountPath: /tmp/service-settings
        - name: halyard-home
          mountPath: /tmp/spinnaker
        - name: additional-profile-config-maps
          mountPath: /tmp/additionalProfileConfigMaps
        - name: halyard-initscript
          mountPath: /tmp/initscript
        - mountPath: /tmp/autoconfig
          name: halyard-overrideurl
      volumes:
      - name: halyard-home
        emptyDir: {}
      - name: halyard-overrideurl
        configMap:
          name: isd-spinnaker-halyard-overrideurl
      - name: secret-decoder
        configMap:
          name: isd-spinnaker-spin-secret-decoder
      - name: reg-secrets
        secret:
          secretName: isd-spinnaker-registry
      - name: additional-profile-config-maps
        configMap:
          name: isd-spinnaker-additional-profile-config-maps
      - name: halyard-config
        emptyDir: {}
      - name: service-settings
        configMap:
          name: isd-spinnaker-service-settings
      - name: halyard-initscript
        configMap:
          name: isd-spinnaker-halyard-init-script
      containers:
      - name: halyard
        image: quay.io/opsmxpublic/ubi8-spin-halyard:1.28.1-v4.0.2
        lifecycle:
          postStart:
            exec:
              command: ["/bin/sh", "-c", "until curl http://localhost:8064/health; do sleep 10 ;done;hal deploy apply"]
        ports:
        - containerPort: 8064
          name: daemon
        volumeMounts:
        - name: halyard-home
          mountPath: /home/spinnaker
        - name: halyard-config
          mountPath: /opt/halyard/config
        - name: reg-secrets
          mountPath: /opt/registry/passwords
---
# Source: oes/templates/statefulsets/oes-db-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
  labels:
    app: oes
    component: db
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-db
spec:
  podManagementPolicy: OrderedReady
  replicas: 1
  serviceName: oes-db
  selector:
    matchLabels:
      app: oes
      component: db
  template:
    metadata:
      annotations:
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: db
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.10"
    spec:
      containers:
      - image: quay.io/opsmxpublic/ubi8-oes-db:v3.0.0
        imagePullPolicy: IfNotPresent
        name: oes-db
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - /opt/opsmx/bin/stop.sh
        ports:
        - containerPort: 5432
          protocol: TCP
        volumeMounts:
        - mountPath: "/var/lib/pgsql-pv"
          name: oes-db-postgresql
        readinessProbe:
          tcpSocket:
            port: 5432
          initialDelaySeconds: 10
          periodSeconds: 5
      securityContext:
        fsGroup: 1000
  volumeClaimTemplates:
  - metadata:
      creationTimestamp: null
      labels:
        app: oes
        component: db
      name: oes-db-postgresql
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 8Gi
      volumeMode: Filesystem
---
# Source: oes/charts/spinnaker/templates/deployments/create-sample-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: isd-create-sample-app
spec:
  template:
    spec:
      serviceAccountName: isd-spinnaker-halyard
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      restartPolicy: OnFailure
      volumes:
      - secret:
          secretName: isd-spinnaker-spin-config
        name: spin-config
      - configMap:
          defaultMode: 420
          name: isd-spinnaker-spin-pipeline-import
        name: spin-pipeline-import
      - name: spin-pipeline-config
        emptyDir: {}
      containers:
      - command:  
        - bash
        - /tmp/config/spin-pipeline-import.sh
        name: sample-pipeline-install
        image: quay.io/opsmxpublic/spin-sample-pipeline:1.0
        volumeMounts:         
        - name: spin-pipeline-config
          mountPath: /tmp/config/git
        - mountPath: /tmp/config
          name: spin-pipeline-import
        - mountPath: /tmp/config/spin
          name: spin-config
---
# Source: oes/templates/forwarder/create-controller-secret.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: create-controller-secret
spec:
 template:
    spec:
       containers:
       - name: create-secret-container
         image: quay.io/opsmxpublic/create-secret:v4.0.3.1
         env:
         - name: NAMESPACE
           valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
         args:
         - "$(NAMESPACE)"
       restartPolicy: Never
       serviceAccount: create-controller-secret
---
# Source: oes/charts/minio/templates/post-install-create-bucket-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: isd-minio-make-bucket-job
  labels:
    app: minio-make-bucket-job
    chart: minio-8.0.9
    release: isd
    heritage: Helm
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
spec:
  template:
    metadata:
      labels:
        app: minio-job
        release: isd
    spec:
      restartPolicy: OnFailure      
      volumes:
        - name: minio-configuration
          projected:
            sources:
            - configMap:
                name: isd-minio
            - secret:
                name: isd-minio
      serviceAccountName: "isd-minio"
      containers:
      - name: minio-mc
        image: "minio/mc:RELEASE.2020-11-25T23-04-07Z"
        imagePullPolicy: IfNotPresent
        command: ["/bin/sh", "/config/initialize"]
        env:
          - name: MINIO_ENDPOINT
            value: isd-minio
          - name: MINIO_PORT
            value: "9000"
        volumeMounts:
          - name: minio-configuration
            mountPath: /config
        resources:
          requests:
            memory: 128Mi
---
# Source: oes/charts/spinnaker/templates/hooks/install-using-hal.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: "isd-install-using-hal"
  labels:
    app: "isd-spinnaker"
    heritage: "Helm"
    release: "isd"
    chart: "spinnaker-2.2.3"
  annotations:
    "helm.sh/hook": "post-install,post-upgrade"
    "helm.sh/hook-delete-policy": "before-hook-creation"
    "helm.sh/hook-weight": "0"
spec:
  template:
    metadata:
      annotations:
        checksum/config: ff6be181e74b269c22441fb715c7df79aa64d83ab59a3b85d3dd7b7c0cfe2008
        moniker.spinnaker.io/application: spin
      labels:
        app: "isd-spinnaker"
        heritage: "Helm"
        release: "isd"
        chart: "spinnaker-2.2.3"
    spec:
      serviceAccountName: isd-spinnaker-halyard
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      restartPolicy: OnFailure
      volumes:
      - name: halyard-config
        configMap:
          name: isd-spinnaker-halyard-config
      containers:
      - name: halyard-install
        image: quay.io/opsmxpublic/ubi8-spin-halyard:1.28.1-v4.0.2
        volumeMounts:
        - name: halyard-config
          mountPath: /opt/halyard/scripts
        command:
        - bash
        - -xe
        - "/opt/halyard/scripts/install.sh"
        env:
        - name: NODE_IP
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: status.hostIP
---
# Source: oes/templates/hooks/oes-config-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  annotations:
    moniker.spinnaker.io/application: isd
    "helm.sh/hook": "post-install,post-upgrade"
    "helm.sh/hook-delete-policy": "before-hook-creation"
    "helm.sh/hook-weight": "5"
  labels:
    app: oes
    component: oes-config
    heritage: "Helm"
    release: "isd"
    chart: "oes-4.0.10"
  name: oes-config
spec:
  template:
    metadata:
      annotations:
        checksum/configmap: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        moniker.spinnaker.io/application: isd
      labels:
        app: oes
        component: oes-config
        heritage: "Helm"
        release: "isd"
        chart: "oes-4.0.10"
    spec:
      containers:
      - command: ["bash", "/tmp/config/datasource-api.sh" ]
        name: datasource-creation-api
        image: quay.io/opsmxpublic/oes-pre-configure:v2
        volumeMounts:
        - mountPath: /tmp/config
          name: datasource-creation
      restartPolicy: OnFailure
      volumes:
      - configMap:
          defaultMode: 420
          name: isd-oes-datasource-creation
        name: datasource-creation
